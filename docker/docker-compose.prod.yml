# Docker Compose for AM-QADF Framework
# Production environment with external services

version: '3.8'

services:
  # Note: In production, MongoDB and Spark are typically managed externally
  # This file is kept for reference and local production-like testing
  
  # MongoDB for Document Storage (AM-QADF Primary Database)
  # In production, use external MongoDB service
  mongodb:
    image: mongo:7.0
    container_name: am-qadf-mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE:-am_qadf_data}
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - am-qadf-network
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Redis for Caching (Query Result Caching)
  # In production, consider using external Redis service (AWS ElastiCache, Azure Cache, etc.)
  redis:
    image: redis:7-alpine
    container_name: am-qadf-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory ${REDIS_MAX_MEMORY:-2gb} --maxmemory-policy allkeys-lru
    networks:
      - am-qadf-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${REDIS_MAX_MEMORY:-2gb}
        reservations:
          memory: 256mb

  # Kafka for Messaging & Streaming (KRaft mode, no Zookeeper)
  # In production, consider using external Kafka (Confluent Cloud, MSK, etc.)
  kafka:
    image: bitnami/kafka:3.7
    container_name: am-qadf-kafka
    environment:
      KAFKA_CFG_NODE_ID: 0
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
    ports:
      - "${KAFKA_PORT:-9092}:9092"
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - am-qadf-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # AM-QADF Framework (Python app; build from repo root)
  am-qadf:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: am-qadf:prod
    container_name: am-qadf-app
    environment:
      PYTHONPATH: /workspace/build/src/am_qadf_native:/workspace/build/src/am_qadf_native/Debug:/workspace/build/src/am_qadf_native/Release:/workspace/src:/workspace
      MONGODB_URL: mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@mongodb:27017/${MONGO_DATABASE:-am_qadf_data}?authSource=admin
      REDIS_URL: redis://redis:6379/0
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      API_HOST: 0.0.0.0
      API_PORT: 8000
    volumes:
      - ..:/workspace
    ports:
      - "${API_PORT:-8000}:8000"
    networks:
      - am-qadf-network
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: ["/bin/bash", "-c", "sleep infinity"]
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 1G

# Volumes
volumes:
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  kafka_data:
    driver: local

# Networks
networks:
  am-qadf-network:
    driver: bridge
    external: false
