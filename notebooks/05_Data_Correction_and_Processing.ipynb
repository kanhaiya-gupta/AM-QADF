{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Correction and Processing\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook teaches you how to correct geometric distortions and process signals in voxel grids. You'll learn to apply calibration data, reduce noise, filter signals, and generate derived signals with interactive widgets.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Correct geometric distortions (scaling, rotation, warping)\n",
    "- ‚úÖ Apply calibration data for correction\n",
    "- ‚úÖ Reduce noise in signals\n",
    "- ‚úÖ Filter and smooth signals\n",
    "- ‚úÖ Generate derived signals (thermal, density, stress)\n",
    "\n",
    "## Estimated Duration\n",
    "\n",
    "45-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Data correction and processing are essential for improving data quality in AM-QADF. The framework provides:\n",
    "\n",
    "- üîß **Geometric Correction**: Correct scaling, rotation, and warping distortions\n",
    "- üìè **Calibration**: Use calibration data for accurate corrections\n",
    "- üîá **Noise Reduction**: Remove noise using various filtering techniques\n",
    "- üìä **Signal Processing**: Smooth and filter signals\n",
    "- üßÆ **Derived Signals**: Generate thermal, density, and stress signals\n",
    "\n",
    "Use the interactive widgets below to explore correction and processing - no coding required!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded from development.env\n",
      "‚úÖ Correction classes available\n",
      "‚úÖ Processing classes available\n",
      "‚úÖ Connected to MongoDB: am_qadf_data\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory and src directory to path for imports\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent\n",
    "src_dir = project_root / 'src'\n",
    "\n",
    "# Add project root to path (for src.infrastructure imports)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Add src directory to path (for am_qadf imports)\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Core imports\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    VBox, HBox, Accordion, Tab, Dropdown, RadioButtons, \n",
    "    Checkbox, Button, Output, Text, IntSlider, FloatSlider,\n",
    "    Layout, Box, Label, FloatText, IntText,\n",
    "    HTML as WidgetHTML\n",
    ")\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "from scipy import signal as scipy_signal\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "\n",
    "# Load environment variables from development.env\n",
    "import os\n",
    "env_file = project_root / 'development.env'\n",
    "if env_file.exists():\n",
    "    with open(env_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                value = value.strip('\"\\'')\n",
    "                os.environ[key] = value\n",
    "    print(\"‚úÖ Environment variables loaded from development.env\")\n",
    "\n",
    "# Try to import correction and processing classes\n",
    "CORRECTION_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.correction.geometric_distortion import DistortionModel, ScalingModel, RotationModel, WarpingModel, CombinedDistortionModel\n",
    "    CORRECTION_AVAILABLE = True\n",
    "    print(\"‚úÖ Correction classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Correction classes not available: {e} - using demo mode\")\n",
    "\n",
    "# Try to import processing classes\n",
    "PROCESSING_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.processing.noise_reduction import OutlierDetector, SignalSmoother, NoiseReductionPipeline\n",
    "    from am_qadf.processing.signal_generation import ThermalFieldGenerator, DensityFieldEstimator, StressFieldGenerator\n",
    "    PROCESSING_AVAILABLE = True\n",
    "    print(\"‚úÖ Processing classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Processing classes not available: {e} - using demo mode\")\n",
    "\n",
    "# MongoDB connection setup\n",
    "INFRASTRUCTURE_AVAILABLE = False\n",
    "mongo_client = None\n",
    "voxel_storage = None\n",
    "stl_client = None\n",
    "\n",
    "try:\n",
    "    from src.infrastructure.config import MongoDBConfig\n",
    "    from src.infrastructure.database import MongoDBClient\n",
    "    from am_qadf.voxel_domain import VoxelGridStorage\n",
    "    from am_qadf.query import STLModelClient\n",
    "    \n",
    "    # Initialize MongoDB connection\n",
    "    config = MongoDBConfig.from_env()\n",
    "    if not config.username:\n",
    "        config.username = os.getenv('MONGO_ROOT_USERNAME', 'admin')\n",
    "    if not config.password:\n",
    "        config.password = os.getenv('MONGO_ROOT_PASSWORD', 'password')\n",
    "    \n",
    "    mongo_client = MongoDBClient(config=config)\n",
    "    if mongo_client.is_connected():\n",
    "        voxel_storage = VoxelGridStorage(mongo_client=mongo_client)\n",
    "        stl_client = STLModelClient(mongo_client=mongo_client)\n",
    "        INFRASTRUCTURE_AVAILABLE = True\n",
    "        print(f\"‚úÖ Connected to MongoDB: {config.database}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è MongoDB connection failed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MongoDB not available: {e} - using demo mode\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Correction and Processing Interface\n",
    "\n",
    "Use the widgets below to correct geometric distortions and process signals. Select processing mode, configure corrections, and visualize results interactively!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683e541225d14735830ffec9caf1cff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b>Processing Mode:</b>'), RadioButtons(description='‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Interactive Correction and Processing Interface\n",
    "\n",
    "# Global state\n",
    "original_data = None\n",
    "corrected_data = None\n",
    "processed_signals = None\n",
    "processing_results = {}\n",
    "current_model_id = None\n",
    "current_grid_id = None\n",
    "current_grid = None\n",
    "loaded_grid_data = None\n",
    "signal_arrays = {}\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions for Demo Data\n",
    "# ============================================\n",
    "\n",
    "def generate_sample_data_with_distortion():\n",
    "    \"\"\"Generate sample voxel grid data with known distortions.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create a simple 3D grid\n",
    "    x = np.linspace(-50, 50, 50)\n",
    "    y = np.linspace(-50, 50, 50)\n",
    "    z = np.linspace(0, 100, 50)\n",
    "    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "    \n",
    "    # Create signal with distortion\n",
    "    signal = 100 + 50 * np.sin(2 * np.pi * X / 20) * np.cos(2 * np.pi * Y / 20)\n",
    "    signal += 20 * np.sin(2 * np.pi * Z / 10)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 5, signal.shape)\n",
    "    signal += noise\n",
    "    \n",
    "    # Add outliers\n",
    "    outlier_mask = np.random.random(signal.shape) < 0.01\n",
    "    signal[outlier_mask] += np.random.normal(0, 50, np.sum(outlier_mask))\n",
    "    \n",
    "    return {\n",
    "        'points': np.column_stack([X.flatten(), Y.flatten(), Z.flatten()]),\n",
    "        'signal': signal.flatten(),\n",
    "        'grid_shape': signal.shape\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# Top Panel: Processing Mode and Actions\n",
    "# ============================================\n",
    "\n",
    "mode_label = widgets.HTML(\"<b>Processing Mode:</b>\")\n",
    "processing_mode = RadioButtons(\n",
    "    options=[('Correction', 'correction'), ('Signal Processing', 'processing'), ('Both', 'both')],\n",
    "    value='correction',\n",
    "    description='Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Data Source Selection (Checkboxes - all selected by default, arranged in 2x2 grid)\n",
    "data_source_label = widgets.HTML(\"<b>Data Source:</b>\")\n",
    "source_laser = Checkbox(value=True, description='Laser', style={'description_width': 'initial'})\n",
    "source_ct = Checkbox(value=True, description='CT', style={'description_width': 'initial'})\n",
    "source_ispm = Checkbox(value=True, description='ISPM', style={'description_width': 'initial'})\n",
    "source_hatching = Checkbox(value=True, description='Hatching', style={'description_width': 'initial'})\n",
    "\n",
    "# Store checkboxes in a list for easy access\n",
    "source_checkboxes = [source_laser, source_ct, source_ispm, source_hatching]\n",
    "source_mapping = {\n",
    "    source_laser: 'laser',\n",
    "    source_ct: 'ct',\n",
    "    source_ispm: 'ispm',\n",
    "    source_hatching: 'hatching'\n",
    "}\n",
    "\n",
    "# Helper function to get selected sources\n",
    "def get_selected_sources():\n",
    "    \"\"\"Get list of selected data sources.\"\"\"\n",
    "    selected = []\n",
    "    for checkbox, source in source_mapping.items():\n",
    "        if checkbox.value:\n",
    "            selected.append(source)\n",
    "    return selected\n",
    "\n",
    "# Source selection container - 2x2 grid layout\n",
    "source_selection = VBox([\n",
    "    HBox([source_laser, source_ct], layout=Layout(padding='2px')),\n",
    "    HBox([source_ispm, source_hatching], layout=Layout(padding='2px'))\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "\n",
    "# Model selection (MongoDB mode)\n",
    "model_label = widgets.HTML(\"<b>Model:</b>\")\n",
    "model_options = [(\"‚îÅ‚îÅ‚îÅ Select Model ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "if INFRASTRUCTURE_AVAILABLE and stl_client:\n",
    "    try:\n",
    "        models = stl_client.list_models(limit=100)\n",
    "        model_options.extend([\n",
    "            (f\"{m.get('filename', m.get('original_stem', m.get('model_name', 'Unknown')))} ({m.get('model_id', '')[:8]}...)\", m.get('model_id'))\n",
    "            for m in models\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error loading models: {e}\")\n",
    "\n",
    "model_dropdown = Dropdown(\n",
    "    options=model_options,\n",
    "    value=None,\n",
    "    description='Model:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='300px', display='flex' if INFRASTRUCTURE_AVAILABLE else 'none')\n",
    ")\n",
    "\n",
    "# Grid selection (populated when model is selected)\n",
    "grid_options = [(\"‚îÅ‚îÅ‚îÅ Select Grid ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "grid_dropdown = Dropdown(\n",
    "    options=grid_options,\n",
    "    value=None,\n",
    "    description='Grid:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='300px', display='flex' if INFRASTRUCTURE_AVAILABLE else 'none')\n",
    ")\n",
    "\n",
    "# Signal selection (populated when grid is loaded)\n",
    "signal_options = [(\"‚îÅ‚îÅ‚îÅ Select Signal ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "signal_dropdown = Dropdown(\n",
    "    options=signal_options,\n",
    "    value=None,\n",
    "    description='Signal:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='250px', display='none')\n",
    ")\n",
    "\n",
    "load_data_button = Button(\n",
    "    description='Load Grid',\n",
    "    button_style='info',\n",
    "    icon='folder-open',\n",
    "    layout=Layout(width='120px', display='flex' if INFRASTRUCTURE_AVAILABLE else 'none')\n",
    ")\n",
    "\n",
    "execute_button = Button(\n",
    "    description='Execute',\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    layout=Layout(width='120px')\n",
    ")\n",
    "\n",
    "# Unified Save button (will show/hide based on mode and results)\n",
    "save_button = Button(\n",
    "    description='Save',\n",
    "    button_style='info',\n",
    "    icon='save',\n",
    "    layout=Layout(width='120px')  # Hidden by default, shown after execution\n",
    ")\n",
    "\n",
    "reset_button = Button(\n",
    "    description='Reset',\n",
    "    button_style='',\n",
    "    icon='refresh',\n",
    "    layout=Layout(width='100px')\n",
    ")\n",
    "\n",
    "# Actions section\n",
    "actions_label = widgets.HTML(\"<b>Actions:</b>\")\n",
    "actions_section = HBox([\n",
    "    load_data_button,\n",
    "    execute_button,\n",
    "    save_button,\n",
    "    reset_button\n",
    "], layout=Layout(justify_content='flex-start', gap='10px', padding='5px'))\n",
    "\n",
    "top_panel = VBox([\n",
    "    HBox([mode_label, processing_mode, data_source_label, source_selection], layout=Layout(justify_content='flex-start', gap='20px')),\n",
    "    HBox([model_label, model_dropdown, grid_dropdown, signal_dropdown]),\n",
    "    HBox([actions_label, actions_section])\n",
    "], layout=Layout(padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Left Panel: Configuration\n",
    "# ============================================\n",
    "\n",
    "# Geometric Correction Section\n",
    "correction_label = widgets.HTML(\"<b>Geometric Correction:</b>\")\n",
    "distortion_type = RadioButtons(\n",
    "    options=[('Scaling', 'scaling'), ('Rotation', 'rotation'), ('Warping', 'warping'), ('Combined', 'combined')],\n",
    "    value='scaling',\n",
    "    description='Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scale_x = FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Scale X:', style={'description_width': 'initial'})\n",
    "scale_y = FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Scale Y:', style={'description_width': 'initial'})\n",
    "scale_z = FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Scale Z:', style={'description_width': 'initial'})\n",
    "uniform_scale = Checkbox(value=False, description='Uniform Scale', style={'description_width': 'initial'})\n",
    "\n",
    "scaling_section = VBox([\n",
    "    uniform_scale, scale_x, scale_y, scale_z\n",
    "], layout=Layout(display='flex'))\n",
    "\n",
    "# Rotation\n",
    "rot_x = FloatSlider(value=0.0, min=-180.0, max=180.0, step=1.0, description='Rot X (deg):', style={'description_width': 'initial'})\n",
    "rot_y = FloatSlider(value=0.0, min=-180.0, max=180.0, step=1.0, description='Rot Y (deg):', style={'description_width': 'initial'})\n",
    "rot_z = FloatSlider(value=0.0, min=-180.0, max=180.0, step=1.0, description='Rot Z (deg):', style={'description_width': 'initial'})\n",
    "rot_center_x = FloatSlider(value=0.0, min=-100.0, max=100.0, step=1.0, description='Center X:', style={'description_width': 'initial'})\n",
    "rot_center_y = FloatSlider(value=0.0, min=-100.0, max=100.0, step=1.0, description='Center Y:', style={'description_width': 'initial'})\n",
    "rot_center_z = FloatSlider(value=0.0, min=-100.0, max=100.0, step=1.0, description='Center Z:', style={'description_width': 'initial'})\n",
    "\n",
    "rotation_section = VBox([\n",
    "    rot_x, rot_y, rot_z,\n",
    "    rot_center_x, rot_center_y, rot_center_z\n",
    "], layout=Layout(display='none'))\n",
    "\n",
    "# Warping\n",
    "warp_type = Dropdown(\n",
    "    options=[('Polynomial', 'polynomial'), ('Spline', 'spline'), ('Custom', 'custom')],\n",
    "    value='polynomial',\n",
    "    description='Warp Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "warp_degree = IntSlider(value=2, min=1, max=5, step=1, description='Degree:', style={'description_width': 'initial'})\n",
    "\n",
    "warping_section = VBox([\n",
    "    warp_type, warp_degree\n",
    "], layout=Layout(display='none'))\n",
    "\n",
    "def update_distortion_controls(change):\n",
    "    \"\"\"Show/hide distortion controls based on type.\"\"\"\n",
    "    dist_type = change['new']\n",
    "    scaling_section.layout.display = 'none'\n",
    "    rotation_section.layout.display = 'none'\n",
    "    warping_section.layout.display = 'none'\n",
    "    \n",
    "    if dist_type == 'scaling' or dist_type == 'combined':\n",
    "        scaling_section.layout.display = 'flex'\n",
    "    if dist_type == 'rotation' or dist_type == 'combined':\n",
    "        rotation_section.layout.display = 'flex'\n",
    "    if dist_type == 'warping' or dist_type == 'combined':\n",
    "        warping_section.layout.display = 'flex'\n",
    "\n",
    "distortion_type.observe(update_distortion_controls, names='value')\n",
    "update_distortion_controls({'new': distortion_type.value})\n",
    "\n",
    "# Calibration\n",
    "use_calibration = Checkbox(value=False, description='Use Calibration', style={'description_width': 'initial'})\n",
    "calibration_selector = Dropdown(\n",
    "    options=[('Calibration 1', 'cal1'), ('Calibration 2', 'cal2'), ('Calibration 3', 'cal3')],\n",
    "    value='cal1',\n",
    "    description='Calibration:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "load_calibration_button = Button(description='Load Calibration', button_style='', layout=Layout(width='150px'))\n",
    "\n",
    "calibration_section = VBox([\n",
    "    use_calibration,\n",
    "    calibration_selector,\n",
    "    load_calibration_button\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "preview_correction_button = Button(description='Preview Correction', button_style='', layout=Layout(width='150px'))\n",
    "\n",
    "correction_section = VBox([\n",
    "    correction_label,\n",
    "    distortion_type,\n",
    "    scaling_section,\n",
    "    rotation_section,\n",
    "    warping_section,\n",
    "    calibration_section,\n",
    "    preview_correction_button\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "# Signal Processing Section\n",
    "processing_label = widgets.HTML(\"<b>Signal Processing:</b>\")\n",
    "\n",
    "# Outlier Detection\n",
    "outlier_method = Dropdown(\n",
    "    options=[('IQR', 'iqr'), ('Z-Score', 'zscore'), ('Modified Z-Score', 'modified_zscore')],\n",
    "    value='iqr',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "outlier_threshold = FloatSlider(value=3.0, min=1.0, max=5.0, step=0.1, description='Threshold:', style={'description_width': 'initial'})\n",
    "remove_outliers = Checkbox(value=True, description='Remove Outliers', style={'description_width': 'initial'})\n",
    "\n",
    "outlier_section = VBox([\n",
    "    outlier_method,\n",
    "    outlier_threshold,\n",
    "    remove_outliers\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Signal Smoothing\n",
    "smooth_method = Dropdown(\n",
    "    options=[('Savitzky-Golay', 'savgol'), ('Moving Average', 'moving'), ('Gaussian', 'gaussian')],\n",
    "    value='savgol',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "window_length = IntSlider(value=11, min=3, max=51, step=2, description='Window Length:', style={'description_width': 'initial'})\n",
    "poly_order = IntSlider(value=3, min=1, max=5, step=1, description='Poly Order:', style={'description_width': 'initial'})\n",
    "\n",
    "smoothing_section = VBox([\n",
    "    smooth_method,\n",
    "    window_length,\n",
    "    poly_order\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Noise Reduction\n",
    "noise_method = Dropdown(\n",
    "    options=[('Median', 'median'), ('Gaussian', 'gaussian'), ('Wiener', 'wiener')],\n",
    "    value='median',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "kernel_size = IntSlider(value=3, min=3, max=15, step=2, description='Kernel Size:', style={'description_width': 'initial'})\n",
    "\n",
    "noise_section = VBox([\n",
    "    noise_method,\n",
    "    kernel_size\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Derived Signal Generation\n",
    "derived_label = widgets.HTML(\"<b>Derived Signals:</b>\")\n",
    "derived_signal_type = RadioButtons(\n",
    "    options=[('None', 'none'), ('Thermal', 'thermal'), ('Density', 'density'), ('Stress', 'stress')],\n",
    "    value='none',\n",
    "    description='Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Thermal parameters (collapsible)\n",
    "thermal_expand = Checkbox(value=False, description='Show Thermal Params', style={'description_width': 'initial'})\n",
    "thermal_coeff = FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Coefficient:', style={'description_width': 'initial'})\n",
    "thermal_params = VBox([\n",
    "    thermal_expand,\n",
    "    thermal_coeff\n",
    "], layout=Layout(display='none'))\n",
    "\n",
    "# Density parameters (collapsible)\n",
    "density_expand = Checkbox(value=False, description='Show Density Params', style={'description_width': 'initial'})\n",
    "density_coeff = FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Coefficient:', style={'description_width': 'initial'})\n",
    "density_params = VBox([\n",
    "    density_expand,\n",
    "    density_coeff\n",
    "], layout=Layout(display='none'))\n",
    "\n",
    "def update_derived_params(change):\n",
    "    \"\"\"Show/hide derived signal parameters.\"\"\"\n",
    "    signal_type = change['new']\n",
    "    thermal_params.layout.display = 'none'\n",
    "    density_params.layout.display = 'none'\n",
    "    \n",
    "    if signal_type == 'thermal':\n",
    "        thermal_params.layout.display = 'flex' if thermal_expand.value else 'none'\n",
    "    elif signal_type == 'density':\n",
    "        density_params.layout.display = 'flex' if density_expand.value else 'none'\n",
    "\n",
    "derived_signal_type.observe(update_derived_params, names='value')\n",
    "thermal_expand.observe(update_derived_params, names='value')\n",
    "density_expand.observe(update_derived_params, names='value')\n",
    "\n",
    "derived_section = VBox([\n",
    "    derived_label,\n",
    "    derived_signal_type,\n",
    "    thermal_params,\n",
    "    density_params\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Create accordion for processing pipeline\n",
    "processing_accordion = Accordion(children=[\n",
    "    outlier_section,\n",
    "    smoothing_section,\n",
    "    noise_section,\n",
    "    derived_section\n",
    "])\n",
    "processing_accordion.set_title(0, 'Outlier Detection')\n",
    "processing_accordion.set_title(1, 'Signal Smoothing')\n",
    "processing_accordion.set_title(2, 'Noise Reduction')\n",
    "processing_accordion.set_title(3, 'Derived Signals')\n",
    "\n",
    "processing_section = VBox([\n",
    "    processing_label,\n",
    "    processing_accordion\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "# Show/hide sections based on processing mode\n",
    "def update_processing_sections(change):\n",
    "    \"\"\"Show/hide processing sections and signal dropdown based on mode.\"\"\"\n",
    "    mode = change['new']\n",
    "    if mode == 'correction':\n",
    "        correction_section.layout.display = 'flex'\n",
    "        processing_section.layout.display = 'none'\n",
    "        # Hide signal dropdown - correction applies to all points, not specific signals\n",
    "        signal_dropdown.layout.display = 'none'\n",
    "    elif mode == 'processing':\n",
    "        correction_section.layout.display = 'none'\n",
    "        processing_section.layout.display = 'flex'\n",
    "        # Show signal dropdown - processing needs signal selection\n",
    "        if signal_dropdown.options and len(signal_dropdown.options) > 1:\n",
    "            signal_dropdown.layout.display = 'flex'\n",
    "    else:  # both\n",
    "        correction_section.layout.display = 'flex'\n",
    "        processing_section.layout.display = 'flex'\n",
    "        # Show signal dropdown - both modes need signal selection for processing part\n",
    "        if signal_dropdown.options and len(signal_dropdown.options) > 1:\n",
    "            signal_dropdown.layout.display = 'flex'\n",
    "\n",
    "processing_mode.observe(update_processing_sections, names='value')\n",
    "update_processing_sections({'new': processing_mode.value})\n",
    "\n",
    "left_panel = VBox([\n",
    "    correction_section,\n",
    "    processing_section\n",
    "], layout=Layout(width='300px', padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Center Panel: Visualization\n",
    "# ============================================\n",
    "\n",
    "viz_mode = RadioButtons(\n",
    "    options=[('Before/After', 'before_after'), ('Difference', 'difference'), ('Quality', 'quality')],\n",
    "    value='before_after',\n",
    "    description='View:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "viz_output = Output(layout=Layout(height='500px', overflow='auto'))\n",
    "\n",
    "center_panel = VBox([\n",
    "    widgets.HTML(\"<h3>Processing Visualization</h3>\"),\n",
    "    viz_mode,\n",
    "    viz_output\n",
    "], layout=Layout(flex='1 1 auto', padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Right Panel: Results and Metrics\n",
    "# ============================================\n",
    "\n",
    "# Correction Metrics\n",
    "correction_metrics_label = widgets.HTML(\"<b>Correction Metrics:</b>\")\n",
    "correction_metrics_display = widgets.HTML(\"No correction performed yet\")\n",
    "correction_metrics_section = VBox([\n",
    "    correction_metrics_label,\n",
    "    correction_metrics_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Processing Metrics\n",
    "processing_metrics_label = widgets.HTML(\"<b>Processing Metrics:</b>\")\n",
    "processing_metrics_display = widgets.HTML(\"No processing performed yet\")\n",
    "processing_metrics_section = VBox([\n",
    "    processing_metrics_label,\n",
    "    processing_metrics_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Signal Statistics\n",
    "signal_stats_label = widgets.HTML(\"<b>Signal Statistics:</b>\")\n",
    "signal_stats_display = widgets.HTML(\"No statistics available\")\n",
    "signal_stats_section = VBox([\n",
    "    signal_stats_label,\n",
    "    signal_stats_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Validation Status\n",
    "validation_label = widgets.HTML(\"<b>Validation:</b>\")\n",
    "validation_display = widgets.HTML(\"Not validated\")\n",
    "validation_section = VBox([\n",
    "    validation_label,\n",
    "    validation_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Export Options\n",
    "export_label = widgets.HTML(\"<b>Save/Export:</b>\")\n",
    "save_corrected_button = Button(description='Save Corrected Grid', button_style='info', layout=Layout(width='160px', display='none'))\n",
    "save_processed_button = Button(description='Save Processed Grid', button_style='info', layout=Layout(width='160px', display='none'))\n",
    "export_corrected_button = Button(description='Export Corrected', button_style='', layout=Layout(width='150px'))\n",
    "export_processed_button = Button(description='Export Processed', button_style='', layout=Layout(width='150px'))\n",
    "save_config_button = Button(description='Save Config', button_style='', layout=Layout(width='150px'))\n",
    "\n",
    "export_section = VBox([\n",
    "    export_label,\n",
    "    save_corrected_button,\n",
    "    save_processed_button,\n",
    "    export_corrected_button,\n",
    "    export_processed_button,\n",
    "    save_config_button\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "right_panel = VBox([\n",
    "    correction_metrics_section,\n",
    "    processing_metrics_section,\n",
    "    signal_stats_section,\n",
    "    validation_section,\n",
    "    export_section\n",
    "], layout=Layout(width='250px', padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Bottom Panel: Status and Progress\n",
    "# ============================================\n",
    "\n",
    "# Status display widget\n",
    "current_operation = WidgetHTML(value='<b>Status:</b> Ready to process data')\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Processing logs output\n",
    "processing_logs = Output(layout=Layout(height='200px', border='1px solid #ccc', overflow_y='auto'))\n",
    "\n",
    "# Initialize logs\n",
    "with processing_logs:\n",
    "    display(HTML(\"<p><i>Processing logs will appear here...</i></p>\"))\n",
    "\n",
    "# Bottom status bar (shows Status | Progress | Time)\n",
    "bottom_status = WidgetHTML(value='<b>Status:</b> Ready | <b>Progress:</b> 0% | <b>Time:</b> 0:00')\n",
    "bottom_progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Overall:',\n",
    "    bar_style='info',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Error display\n",
    "error_display = widgets.HTML(\"\")\n",
    "\n",
    "# Keep old status_display for backward compatibility (will be updated by logging functions)\n",
    "status_display = current_operation\n",
    "\n",
    "# Global time tracking\n",
    "operation_start_time = None\n",
    "\n",
    "# Enhanced bottom panel\n",
    "bottom_panel = VBox([\n",
    "    current_operation,\n",
    "    progress_bar,\n",
    "    WidgetHTML(\"<b>Processing Logs:</b>\"),\n",
    "    processing_logs,\n",
    "    WidgetHTML(\"<hr>\"),\n",
    "    bottom_status,\n",
    "    bottom_progress,\n",
    "    error_display\n",
    "], layout=Layout(padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Logging Functions\n",
    "# ============================================\n",
    "\n",
    "def log_message(message: str, level: str = 'info'):\n",
    "    \"\"\"Log a message to the processing logs with timestamp and emoji.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    icons = {'info': '‚ÑπÔ∏è', 'success': '‚úÖ', 'warning': '‚ö†Ô∏è', 'error': '‚ùå'}\n",
    "    icon = icons.get(level, '‚ÑπÔ∏è')\n",
    "    with processing_logs:\n",
    "        print(f\"[{timestamp}] {icon} {message}\")\n",
    "\n",
    "def update_status(operation: str, progress: int = None):\n",
    "    \"\"\"Update the status display and progress.\"\"\"\n",
    "    global operation_start_time\n",
    "    current_operation.value = f'<b>Status:</b> {operation}'\n",
    "    if progress is not None:\n",
    "        progress_bar.value = progress\n",
    "        bottom_progress.value = progress\n",
    "        if operation_start_time:\n",
    "            elapsed = time.time() - operation_start_time\n",
    "            bottom_status.value = f'<b>Status:</b> {operation} | <b>Progress:</b> {progress}% | <b>Time:</b> {time.strftime(\"%M:%S\", time.gmtime(elapsed))}'\n",
    "        else:\n",
    "            bottom_status.value = f'<b>Status:</b> {operation} | <b>Progress:</b> {progress}% | <b>Time:</b> 0:00'\n",
    "\n",
    "# ============================================\n",
    "# Data Loading Functions\n",
    "# ============================================\n",
    "\n",
    "def update_grid_dropdown(change):\n",
    "    \"\"\"Update grid dropdown when model is selected - filter by processing mode and selected data sources.\"\"\"\n",
    "    global grid_options\n",
    "    \n",
    "    model_id = change['new']\n",
    "    grid_options = [(\"‚îÅ‚îÅ‚îÅ Select Grid ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "    \n",
    "    if model_id and voxel_storage:\n",
    "        try:\n",
    "            # Get selected data sources from checkboxes\n",
    "            selected_sources = get_selected_sources()\n",
    "            if not selected_sources:\n",
    "                grid_options.append((\"No data sources selected\", None))\n",
    "                grid_dropdown.options = grid_options\n",
    "                grid_dropdown.value = None\n",
    "                return\n",
    "            \n",
    "            # Get current processing mode\n",
    "            current_mode = processing_mode.value\n",
    "            \n",
    "            # Determine which grid type to show based on mode\n",
    "            # Processing mode: show corrected grids\n",
    "            # Correction/Both mode: show aligned grids\n",
    "            show_corrected = (current_mode == 'processing')\n",
    "            show_aligned = (current_mode == 'correction' or current_mode == 'both')\n",
    "            \n",
    "            # Get all grids for the model\n",
    "            available_grids = voxel_storage.list_grids(model_id=model_id, limit=100)\n",
    "            \n",
    "            # Filter grids based on mode and selected data sources\n",
    "            filtered_grids = []\n",
    "            for g in available_grids:\n",
    "                grid_name = g.get('grid_name', '')\n",
    "                metadata = g.get('metadata', {})\n",
    "                config_metadata = metadata.get('configuration_metadata', {})\n",
    "                available_signals = g.get('available_signals', [])\n",
    "                n_signals = len(available_signals) if available_signals else 0\n",
    "                \n",
    "                # Get source from metadata or grid name\n",
    "                source = config_metadata.get('source', '').lower()\n",
    "                if not source and grid_name:\n",
    "                    # Try to extract source from grid name (format: source_gridtype_resolution_...)\n",
    "                    name_parts = grid_name.split('_')\n",
    "                    if name_parts:\n",
    "                        potential_source = name_parts[0].lower()\n",
    "                        if potential_source in ['laser', 'ct', 'ispm', 'hatching']:\n",
    "                            source = potential_source\n",
    "                \n",
    "                # Filter by selected sources\n",
    "                if source not in selected_sources:\n",
    "                    continue\n",
    "                \n",
    "                # Check grid type based on mode\n",
    "                is_corrected = False\n",
    "                is_aligned = False\n",
    "                \n",
    "                if show_corrected:\n",
    "                    # Check if it's a corrected grid\n",
    "                    if grid_name and '_corrected_' in grid_name:\n",
    "                        is_corrected = True\n",
    "                    elif config_metadata.get('correction_applied', False):\n",
    "                        is_corrected = True\n",
    "                    \n",
    "                    # Only include corrected grids that have signals\n",
    "                    if is_corrected and n_signals > 0:\n",
    "                        filtered_grids.append(g)\n",
    "                \n",
    "                elif show_aligned:\n",
    "                    # Check if it's an aligned grid\n",
    "                    if grid_name and '_aligned_' in grid_name:\n",
    "                        is_aligned = True\n",
    "                    elif config_metadata.get('alignment_applied', False):\n",
    "                        is_aligned = True\n",
    "                    \n",
    "                    # Only include aligned grids that have signals\n",
    "                    if is_aligned and n_signals > 0:\n",
    "                        filtered_grids.append(g)\n",
    "            \n",
    "            # Build dropdown options\n",
    "            for g in filtered_grids:\n",
    "                grid_id = g.get('grid_id', '')\n",
    "                grid_name = g.get('grid_name', 'Unknown')\n",
    "                metadata = g.get('metadata', {})\n",
    "                config_metadata = metadata.get('configuration_metadata', {})\n",
    "                available_signals = g.get('available_signals', [])\n",
    "                \n",
    "                # Extract grid type and key info\n",
    "                grid_type = config_metadata.get('grid_type', metadata.get('grid_type', 'uniform'))\n",
    "                resolution = metadata.get('resolution', 'N/A')\n",
    "                n_signals = len(available_signals) if available_signals else 0\n",
    "                source = config_metadata.get('source', 'unknown')\n",
    "                \n",
    "                # Build descriptive label\n",
    "                label_parts = [grid_name]\n",
    "                \n",
    "                # Add type info\n",
    "                if grid_type != 'uniform':\n",
    "                    label_parts.append(f\"[{grid_type}]\")\n",
    "                \n",
    "                # Add resolution\n",
    "                if isinstance(resolution, (int, float)):\n",
    "                    label_parts.append(f\"res:{resolution:.1f}mm\")\n",
    "                \n",
    "                # Add signal count\n",
    "                label_parts.append(f\"{n_signals} signal(s)\")\n",
    "                \n",
    "                # Add status info based on mode\n",
    "                if show_corrected:\n",
    "                    correction_type = config_metadata.get('correction_type', 'unknown')\n",
    "                    if correction_type != 'unknown':\n",
    "                        label_parts.append(f\"({correction_type})\")\n",
    "                elif show_aligned:\n",
    "                    alignment_mode = config_metadata.get('alignment_mode', 'unknown')\n",
    "                    if alignment_mode != 'unknown':\n",
    "                        label_parts.append(f\"({alignment_mode})\")\n",
    "                \n",
    "                # Add source\n",
    "                if source != 'unknown':\n",
    "                    label_parts.append(f\"[{source.upper()}]\")\n",
    "                \n",
    "                # Add grid ID (shortened)\n",
    "                label_parts.append(f\"({grid_id[:8]}...)\")\n",
    "                \n",
    "                label = \" \".join(label_parts)\n",
    "                grid_options.append((label, grid_id))\n",
    "            \n",
    "            # Set appropriate message based on mode\n",
    "            if len(grid_options) == 1:\n",
    "                if show_corrected:\n",
    "                    grid_options.append((\"No corrected grids available for selected sources\", None))\n",
    "                else:\n",
    "                    grid_options.append((\"No aligned grids available for selected sources\", None))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading grids: {e}\")\n",
    "            grid_options.append((\"Error loading grids\", None))\n",
    "    \n",
    "    grid_dropdown.options = grid_options\n",
    "    grid_dropdown.value = None\n",
    "    \n",
    "model_dropdown.observe(update_grid_dropdown, names='value')\n",
    "\n",
    "# Update grid dropdown when source checkboxes change\n",
    "for checkbox in source_checkboxes:\n",
    "    checkbox.observe(lambda change: update_grid_dropdown({'new': model_dropdown.value}), names='value')\n",
    "\n",
    "# Update grid dropdown when processing mode changes\n",
    "processing_mode.observe(lambda change: update_grid_dropdown({'new': model_dropdown.value}), names='value')\n",
    "\n",
    "_loading_in_progress = False\n",
    "\n",
    "def auto_load_data(change):\n",
    "    \"\"\"Auto-load data when both model and grid are selected.\"\"\"\n",
    "    global _loading_in_progress\n",
    "    \n",
    "    model_id = model_dropdown.value\n",
    "    grid_id = grid_dropdown.value\n",
    "    \n",
    "    # Auto-load if both are selected, MongoDB is available, and not already loading\n",
    "    if INFRASTRUCTURE_AVAILABLE and model_id and grid_id and not _loading_in_progress:\n",
    "        load_grid_from_mongodb(None)\n",
    "\n",
    "grid_dropdown.observe(auto_load_data, names='value')\n",
    "\n",
    "def load_grid_from_mongodb(button):\n",
    "    \"\"\"Load a mapped grid from MongoDB. Can be called manually or auto-triggered.\"\"\"\n",
    "    global original_data, current_model_id, current_grid_id, current_grid, loaded_grid_data, signal_arrays, _loading_in_progress, operation_start_time\n",
    "    \n",
    "    # Prevent multiple simultaneous loads\n",
    "    if _loading_in_progress:\n",
    "        return\n",
    "    \n",
    "    # Initialize timing\n",
    "    operation_start_time = time.time()\n",
    "    \n",
    "    # Clear logs\n",
    "    with processing_logs:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    log_message(\"Starting grid load from MongoDB...\", 'info')\n",
    "    update_status(\"Initializing grid load...\", 0)\n",
    "    \n",
    "    if not voxel_storage or not mongo_client:\n",
    "        log_message(\"MongoDB not available. Cannot load grid.\", 'error')\n",
    "        error_display.value = \"<span style='color: red;'>‚ùå MongoDB not available</span>\"\n",
    "        update_status(\"MongoDB unavailable\", 0)\n",
    "        return\n",
    "    \n",
    "    model_id = model_dropdown.value\n",
    "    grid_id = grid_dropdown.value\n",
    "    \n",
    "    if not model_id:\n",
    "        log_message(\"Please select a model from the dropdown\", 'warning')\n",
    "        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è Please select a model</span>\"\n",
    "        update_status(\"No model selected\", 0)\n",
    "        return\n",
    "    \n",
    "    if not grid_id:\n",
    "        log_message(\"Please select a grid from the dropdown\", 'warning')\n",
    "        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è Please select a grid</span>\"\n",
    "        update_status(\"No grid selected\", 0)\n",
    "        return\n",
    "    \n",
    "    _loading_in_progress = True\n",
    "    \n",
    "    log_message(f\"Loading grid {grid_id[:8]}... from MongoDB...\", 'info')\n",
    "    error_display.value = \"\"\n",
    "    \n",
    "    try:\n",
    "        current_model_id = model_id\n",
    "        current_grid_id = grid_id\n",
    "        \n",
    "        # Load grid\n",
    "        log_message(\"Loading grid data from storage...\", 'info')\n",
    "        update_status(\"Loading grid from MongoDB...\", 30)\n",
    "        loaded_grid_data = voxel_storage.load_voxel_grid(grid_id)\n",
    "        \n",
    "        if not loaded_grid_data:\n",
    "            log_message(f\"Failed to load grid {grid_id[:8]}...\", 'error')\n",
    "            error_display.value = f\"<span style='color: red;'>‚ùå Failed to load grid</span>\"\n",
    "            update_status(\"Error loading grid\", 0)\n",
    "            return\n",
    "        \n",
    "        log_message(\"Grid loaded successfully\", 'success')\n",
    "        \n",
    "        # Extract grid metadata\n",
    "        log_message(\"Extracting grid metadata...\", 'info')\n",
    "        update_status(\"Extracting metadata...\", 40)\n",
    "        metadata = loaded_grid_data.get('metadata', {})\n",
    "        bbox_min = np.array(metadata.get('bbox_min', [-50, -50, 0]))\n",
    "        bbox_max = np.array(metadata.get('bbox_max', [50, 50, 100]))\n",
    "        resolution = metadata.get('resolution', 2.0)\n",
    "        dims = metadata.get('dims', [50, 50, 50])\n",
    "        \n",
    "        # Load signal arrays\n",
    "        log_message(\"Loading signal arrays...\", 'info')\n",
    "        update_status(\"Loading signal arrays...\", 50)\n",
    "        signal_arrays = loaded_grid_data.get('signal_arrays', {})\n",
    "        available_signals_meta = loaded_grid_data.get('available_signals', [])\n",
    "        \n",
    "        # If signal_arrays is empty but we have signal_references, try to load manually\n",
    "        # (Similar to how check_signal_mapped_data.py does it)\n",
    "        if not signal_arrays:\n",
    "            # Get the grid document directly to check signal_references\n",
    "            try:\n",
    "                from bson import ObjectId\n",
    "                collection = mongo_client.get_collection('voxel_grids')\n",
    "                grid_doc = collection.find_one({'_id': ObjectId(grid_id)})\n",
    "                \n",
    "                if grid_doc:\n",
    "                    signal_references = grid_doc.get('signal_references', {})\n",
    "                    \n",
    "                    if signal_references:\n",
    "                        # Try to load signals manually from GridFS\n",
    "                        from gridfs import GridFS\n",
    "                        import gzip\n",
    "                        import io\n",
    "                        import pickle\n",
    "                        \n",
    "                        loaded_count = 0\n",
    "                        for signal_name, file_id in signal_references.items():\n",
    "                            try:\n",
    "                                # Try default bucket first (where MongoDBClient actually stores files)\n",
    "                                fs = GridFS(mongo_client.database, collection='fs')\n",
    "                                grid_file = fs.get(ObjectId(file_id))\n",
    "                                file_data = grid_file.read()\n",
    "                                \n",
    "                                # Decompress and load\n",
    "                                decompressed = gzip.decompress(file_data)\n",
    "                                signal_data = np.load(io.BytesIO(decompressed), allow_pickle=True)\n",
    "                                \n",
    "                                # Extract signal array from npz\n",
    "                                if hasattr(signal_data, 'files'):\n",
    "                                    if 'format' in signal_data.files and signal_data['format'] == 'sparse':\n",
    "                                        # Sparse format - reconstruct\n",
    "                                        dims = signal_data['dims']\n",
    "                                        values = signal_data['values']\n",
    "                                        indices = signal_data['indices']\n",
    "                                        \n",
    "                                        # Reconstruct sparse array\n",
    "                                        signal_array = np.zeros(tuple(dims), dtype=values.dtype)\n",
    "                                        if len(indices.shape) == 2:\n",
    "                                            # Flatten indices\n",
    "                                            flat_indices = np.ravel_multi_index(indices.T, dims)\n",
    "                                            signal_array.flat[flat_indices] = values\n",
    "                                        else:\n",
    "                                            signal_array.flat[indices] = values\n",
    "                                        \n",
    "                                        signal_arrays[signal_name] = signal_array\n",
    "                                    else:\n",
    "                                        # Dense format - get first array\n",
    "                                        if len(signal_data.files) > 0:\n",
    "                                            first_key = signal_data.files[0]\n",
    "                                            signal_arrays[signal_name] = signal_data[first_key]\n",
    "                                else:\n",
    "                                    signal_arrays[signal_name] = signal_data\n",
    "                                \n",
    "                                loaded_count += 1\n",
    "                            except Exception as e:\n",
    "                                print(f\"‚ö†Ô∏è Failed to load signal {signal_name} from GridFS: {e}\")\n",
    "                                continue\n",
    "                        \n",
    "                        if loaded_count > 0:\n",
    "                            log_message(f\"Loaded {loaded_count} signal(s) from GridFS\", 'success')\n",
    "                            update_status(f\"Loaded {loaded_count} signal(s) from GridFS\", 60)\n",
    "            except Exception as e:\n",
    "                # If manual loading fails, continue to check if signals exist in metadata\n",
    "                print(f\"‚ö†Ô∏è Failed to manually load signals from GridFS: {e}\")\n",
    "        \n",
    "        # Check if signals should exist but failed to load\n",
    "        if not signal_arrays:\n",
    "            if available_signals_meta and len(available_signals_meta) > 0:\n",
    "                # Signals are listed in metadata but failed to load from GridFS\n",
    "                log_message(f\"Signals listed in metadata but failed to load from GridFS. Expected: {', '.join(available_signals_meta)}\", 'error')\n",
    "                error_display.value = f\"\"\"\n",
    "                <span style='color: red;'>\n",
    "                <b>‚ùå Signals listed in grid metadata but failed to load from GridFS.</b><br>\n",
    "                <b>Expected signals:</b> {', '.join(available_signals_meta)}<br>\n",
    "                <b>Action:</b> This may indicate corrupted data. Try re-mapping signals in Notebook 04.\n",
    "                </span>\n",
    "                \"\"\"\n",
    "                update_status(\"Error: Signals failed to load\", 0)\n",
    "            else:\n",
    "                # No signals mapped - expected case\n",
    "                log_message(\"No signals found in grid. Grid needs signals mapped first.\", 'warning')\n",
    "                error_display.value = f\"\"\"\n",
    "                <span style='color: orange;'>\n",
    "                <b>‚ö†Ô∏è No signals found in grid.</b><br>\n",
    "                <b>Grid:</b> {loaded_grid_data.get('grid_name', 'Unknown')}<br>\n",
    "                <b>Action Required:</b> This grid needs signals mapped first.<br><br>\n",
    "                <b>Next Steps:</b><br>\n",
    "                1. Go to <b>Notebook 04 (Signal Mapping Fundamentals)</b><br>\n",
    "                2. Select this model and grid<br>\n",
    "                3. Click \"Map All Signals\" to map signals to the grid<br>\n",
    "                4. Click \"Save Mapped Grid\" to save<br>\n",
    "                5. Return here to correct/process the signals\n",
    "                </span>\n",
    "                \"\"\"\n",
    "                update_status(\"Grid loaded but no signals available - map signals first\", 0)\n",
    "            _loading_in_progress = False\n",
    "            return\n",
    "        \n",
    "        # Update signal dropdown with \"All Signals\" as default\n",
    "        signal_options = [(\"‚îÅ‚îÅ‚îÅ All Signals ‚îÅ‚îÅ‚îÅ\", 'all')]\n",
    "        signal_options.extend([\n",
    "            (f\"{sig_name.replace('_', ' ').title()}\", sig_name)\n",
    "            for sig_name in sorted(signal_arrays.keys())\n",
    "        ])\n",
    "        signal_dropdown.options = signal_options\n",
    "        signal_dropdown.value = 'all'  # Default to all signals\n",
    "        # Only show signal dropdown if mode is 'processing' or 'both' (not 'correction')\n",
    "        current_mode = processing_mode.value\n",
    "        if current_mode in ['processing', 'both']:\n",
    "            signal_dropdown.layout.display = 'flex'\n",
    "        else:\n",
    "            signal_dropdown.layout.display = 'none'\n",
    "\n",
    "        # Use utility function to ensure all signals are 3D\n",
    "        from am_qadf.voxel_domain import prepare_signal_arrays_for_processing\n",
    "        \n",
    "        expected_shape = tuple(dims)\n",
    "        signal_arrays = prepare_signal_arrays_for_processing(\n",
    "            loaded_grid_data,\n",
    "            expected_shape,\n",
    "            default_value=0.0\n",
    "        )\n",
    "        \n",
    "        if not signal_arrays:\n",
    "            log_message(\"No signal arrays could be reconstructed\", 'warning')\n",
    "        else:\n",
    "            log_message(f\"Reconstructed {len(signal_arrays)} signal(s) to 3D format\", 'info')\n",
    "            \n",
    "        # Prepare original_data structure for processing\n",
    "        # Create grid coordinates\n",
    "        x = np.linspace(bbox_min[0], bbox_max[0], dims[0])\n",
    "        y = np.linspace(bbox_min[1], bbox_max[1], dims[1])\n",
    "        z = np.linspace(bbox_min[2], bbox_max[2], dims[2])\n",
    "        X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "        \n",
    "        # Get first signal for initial display\n",
    "        first_signal_name = sorted(signal_arrays.keys())[0] if signal_arrays else None\n",
    "        if first_signal_name:\n",
    "            signal_array = signal_arrays[first_signal_name]\n",
    "            # Ensure signal_array is 3D\n",
    "            if signal_array.ndim == 1 and signal_array.size == np.prod(expected_shape):\n",
    "                signal_array = signal_array.reshape(expected_shape)\n",
    "            \n",
    "            original_data = {\n",
    "                'points': np.column_stack([X.flatten(), Y.flatten(), Z.flatten()]),\n",
    "                'signal': signal_array.flatten(),  # Flatten for storage, but grid_shape will be 3D\n",
    "                'grid_shape': expected_shape,  # Always use 3D dimensions from metadata\n",
    "                'all_signals': signal_arrays,\n",
    "                'selected_signal_mode': signal_dropdown.value if signal_dropdown.value else 'all'  # Set signal mode from dropdown\n",
    "            }\n",
    "        log_message(f\"Prepared data structure with grid shape: {expected_shape}\", 'info')\n",
    "        log_message(f\"Grid loaded: {len(signal_arrays)} signal(s) available\", 'success')\n",
    "        update_status(\"Preparing data structure...\", 90)\n",
    "        \n",
    "        # Calculate total execution time\n",
    "        if operation_start_time:\n",
    "            total_time = time.time() - operation_start_time\n",
    "            log_message(f\"Grid load completed in {total_time:.2f}s\", 'success')\n",
    "        \n",
    "        update_status(f\"Grid loaded: {len(signal_arrays)} signal(s) available\", 100)\n",
    "        error_display.value = f\"<span style='color: green;'>‚úÖ Loaded grid with {len(signal_arrays)} signal(s)</span>\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error loading grid: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "        error_display.value = f\"<span style='color: red;'>‚ùå Error loading grid: {str(e)}</span>\"\n",
    "        update_status(\"Error loading grid\", 0)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        _loading_in_progress = False\n",
    "\n",
    "load_data_button.on_click(load_grid_from_mongodb)\n",
    "\n",
    "# ============================================\n",
    "# Processing Functions\n",
    "# ============================================\n",
    "\n",
    "def execute_processing(button):\n",
    "    \"\"\"Execute processing based on current settings.\"\"\"\n",
    "    global original_data, corrected_data, processed_signals, processing_results, signal_arrays, operation_start_time\n",
    "    \n",
    "    # Initialize timing\n",
    "    operation_start_time = time.time()\n",
    "    \n",
    "    # Clear logs\n",
    "    with processing_logs:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    log_message(\"Starting processing operation...\", 'info')\n",
    "    update_status(\"Initializing processing...\", 0)\n",
    "    error_display.value = \"\"\n",
    "    \n",
    "    try:\n",
    "        # Load data based on source\n",
    "        if INFRASTRUCTURE_AVAILABLE:\n",
    "            # Auto-load grid if not already loaded\n",
    "            if original_data is None or not signal_arrays:\n",
    "                # Try to auto-load if model and grid are selected\n",
    "                model_id = model_dropdown.value\n",
    "                grid_id = grid_dropdown.value\n",
    "                \n",
    "                if model_id and grid_id:\n",
    "                    # Auto-load the grid\n",
    "                    log_message(\"Auto-loading grid...\", 'info')\n",
    "                    update_status(\"Auto-loading grid...\", 5)\n",
    "                    load_grid_from_mongodb(None)\n",
    "                    # Wait a moment for load to complete\n",
    "                    time.sleep(0.5)\n",
    "                    \n",
    "                    # Check again after auto-load\n",
    "                    if original_data is None or not signal_arrays:\n",
    "                        log_message(\"Failed to load grid. Please check your selection and try again.\", 'warning')\n",
    "                        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è Failed to load grid. Please check your selection and try again.</span>\"\n",
    "                        update_status(\"No data loaded\", 0)\n",
    "                        return\n",
    "                else:\n",
    "                    log_message(\"Please select a model and grid first\", 'warning')\n",
    "                    error_display.value = \"<span style='color: red;'>‚ö†Ô∏è Please select a model and grid first</span>\"\n",
    "                    update_status(\"No data loaded\", 0)\n",
    "                    return\n",
    "                \n",
    "                # Get selected signal(s) - handle \"all\" option\n",
    "                selected_signal = signal_dropdown.value\n",
    "                \n",
    "                if selected_signal == 'all':\n",
    "                    # Process all signals - use first one for display/visualization\n",
    "                    # All signals will be processed and saved together\n",
    "                    signal_names = sorted(signal_arrays.keys())\n",
    "                    if not signal_names:\n",
    "                        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No signals available</span>\"\n",
    "                        return\n",
    "                    # Use first signal for initial display\n",
    "                    signal_name = signal_names[0]\n",
    "                else:\n",
    "                    # Process single selected signal\n",
    "                    signal_name = selected_signal if selected_signal else (sorted(signal_arrays.keys())[0] if signal_arrays else None)\n",
    "                    if not signal_name or signal_name not in signal_arrays:\n",
    "                        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è Please select a signal</span>\"\n",
    "                        return\n",
    "                \n",
    "                signal_array = signal_arrays[signal_name]\n",
    "                if not isinstance(signal_array, np.ndarray):\n",
    "                    signal_array = np.array(signal_array)\n",
    "                \n",
    "                # Ensure original_data is set up\n",
    "                if original_data is None:\n",
    "                    metadata = loaded_grid_data.get('metadata', {})\n",
    "                    bbox_min = np.array(metadata.get('bbox_min', [-50, -50, 0]))\n",
    "                    bbox_max = np.array(metadata.get('bbox_max', [50, 50, 100]))\n",
    "                    dims = metadata.get('dims', signal_array.shape)\n",
    "                    x = np.linspace(bbox_min[0], bbox_max[0], dims[0])\n",
    "                    y = np.linspace(bbox_min[1], bbox_max[1], dims[1])\n",
    "                    z = np.linspace(bbox_min[2], bbox_max[2], dims[2])\n",
    "                    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "                    original_data = {\n",
    "                        'points': np.column_stack([X.flatten(), Y.flatten(), Z.flatten()]),\n",
    "                        'signal': signal_array.flatten(),\n",
    "                        'grid_shape': signal_array.shape,\n",
    "                        'all_signals': signal_arrays,\n",
    "                        'selected_signal_mode': selected_signal  # Store whether we're processing all or one\n",
    "                    }\n",
    "                else:\n",
    "                    # Update signal if different one selected\n",
    "                    original_data['signal'] = signal_array.flatten()\n",
    "                    original_data['grid_shape'] = signal_array.shape\n",
    "                    original_data['selected_signal_mode'] = selected_signal\n",
    "                    original_data['all_signals'] = signal_arrays  # Ensure all_signals is always current\n",
    "            \n",
    "            log_message(\"Data loaded from MongoDB\", 'success')\n",
    "            update_status(\"Data loaded\", 20)\n",
    "        else:\n",
    "            # Generate sample data\n",
    "            log_message(\"Generating sample data...\", 'info')\n",
    "            update_status(\"Generating sample data...\", 20)\n",
    "            original_data = generate_sample_data_with_distortion()\n",
    "            log_message(\"Sample data generated\", 'success')\n",
    "            update_status(\"Sample data generated\", 20)\n",
    "        \n",
    "        mode = processing_mode.value\n",
    "        corrected_data = original_data.copy()\n",
    "        \n",
    "        # Check if we're processing all signals - check both original_data and current dropdown\n",
    "        selected_mode = original_data.get('selected_signal_mode', '')\n",
    "        current_dropdown = signal_dropdown.value if signal_dropdown.value else ''\n",
    "        # Process all if: has all_signals with >1 signal AND (mode is 'all' in data OR dropdown is 'all')\n",
    "        has_multiple_signals = 'all_signals' in original_data and len(original_data.get('all_signals', {})) > 1\n",
    "        process_all_signals = has_multiple_signals and (selected_mode == 'all' or current_dropdown == 'all')\n",
    "        \n",
    "        if process_all_signals:\n",
    "            num_signals = len(original_data.get('all_signals', {}))\n",
    "            log_message(f\"Processing {num_signals} signal(s)...\", 'info')\n",
    "            update_status(f\"Processing {num_signals} signal(s)...\", 30)\n",
    "        else:\n",
    "            log_message(\"Processing single signal...\", 'info')\n",
    "            update_status(\"Processing signal...\", 30)\n",
    "        \n",
    "        # Geometric correction (applies to points, shared across all signals)\n",
    "        if mode == 'correction' or mode == 'both':\n",
    "            log_message(f\"Applying geometric correction: {distortion_type.value}\", 'info')\n",
    "            update_status(\"Applying geometric correction...\", 40)\n",
    "            # Apply scaling\n",
    "            if distortion_type.value == 'scaling' or distortion_type.value == 'combined':\n",
    "                scale = np.array([scale_x.value, scale_y.value, scale_z.value])\n",
    "                if uniform_scale.value:\n",
    "                    scale = np.array([scale_x.value] * 3)\n",
    "                # Apply correction (inverse of distortion)\n",
    "                corrected_data['points'] = corrected_data['points'] / scale\n",
    "                log_message(f\"Applied scaling correction: {scale}\", 'success')\n",
    "            \n",
    "            log_message(\"Geometric correction completed\", 'success')\n",
    "            update_status(\"Geometric correction completed\", 50)\n",
    "        \n",
    "        # Signal processing - handle single signal or all signals\n",
    "        if mode == 'processing' or mode == 'both':\n",
    "            if process_all_signals:\n",
    "                # Process all signals\n",
    "                all_signals_dict = original_data.get('all_signals', {})\n",
    "                processed_all_signals = {}\n",
    "                \n",
    "                total_signals = len(all_signals_dict)\n",
    "                for idx, (signal_name, signal_array) in enumerate(sorted(all_signals_dict.items())):\n",
    "                    if not isinstance(signal_array, np.ndarray):\n",
    "                        signal_array = np.array(signal_array)\n",
    "                    \n",
    "                    signal = signal_array.flatten().copy()\n",
    "\n",
    "                    # Outlier detection and clipping (preserve grid structure)\n",
    "                    if remove_outliers.value:\n",
    "                        if outlier_method.value == 'iqr':\n",
    "                            Q1 = np.percentile(signal, 25)\n",
    "                            Q3 = np.percentile(signal, 75)\n",
    "                            IQR = Q3 - Q1\n",
    "                            lower = Q1 - outlier_threshold.value * IQR\n",
    "                            upper = Q3 + outlier_threshold.value * IQR\n",
    "                            # Clip outliers instead of removing them to preserve grid structure\n",
    "                            signal = np.clip(signal, lower, upper)\n",
    "                            log_message(f\"‚úÖ Clipped outliers for signal {signal_name}: bounds=[{lower:.2f}, {upper:.2f}]\", 'info')\n",
    "                            \n",
    "                    # Reshape for processing\n",
    "                    signal_reshaped = signal.reshape(original_data['grid_shape'])\n",
    "                    \n",
    "                    # Smoothing\n",
    "                    if smooth_method.value == 'savgol':\n",
    "                        from scipy.signal import savgol_filter\n",
    "                        # Validate and adjust window_length for Savitzky-Golay filter\n",
    "                        grid_shape = signal_reshaped.shape\n",
    "                        wl = window_length.value\n",
    "                        po = poly_order.value\n",
    "                        \n",
    "                        # Find the best axis (largest dimension)\n",
    "                        best_axis = np.argmax(grid_shape)\n",
    "                        max_size = grid_shape[best_axis]\n",
    "                        \n",
    "                        # Ensure window_length is valid\n",
    "                        if wl > max_size:\n",
    "                            wl = max_size if max_size % 2 == 1 else max_size - 1\n",
    "                            if wl < po + 1:\n",
    "                                wl = po + 1 if (po + 1) % 2 == 1 else po + 2\n",
    "                            log_message(f\"Adjusted window_length from {window_length.value} to {wl} (signal size: {max_size})\", 'warning')\n",
    "                        \n",
    "                        # Ensure window_length is odd and >= poly_order + 1\n",
    "                        if wl % 2 == 0:\n",
    "                            wl = wl - 1\n",
    "                        if wl < po + 1:\n",
    "                            wl = po + 1 if (po + 1) % 2 == 1 else po + 2\n",
    "                        \n",
    "                        # Apply filter along the best axis\n",
    "                        try:\n",
    "                            signal_smooth = savgol_filter(signal_reshaped, wl, po, axis=best_axis)\n",
    "                            processed_signal = signal_smooth\n",
    "                        except Exception as e:\n",
    "                            log_message(f\"Savitzky-Golay filter failed: {e}. Using original signal.\", 'warning')\n",
    "                            processed_signal = signal_reshaped\n",
    "                    elif smooth_method.value == 'moving':\n",
    "                        kernel = np.ones(window_length.value) / window_length.value\n",
    "                        processed_signal = np.apply_along_axis(\n",
    "                            lambda x: np.convolve(x, kernel, mode='same'),\n",
    "                            axis=0, arr=signal_reshaped\n",
    "                        )\n",
    "                    else:  # gaussian\n",
    "                        processed_signal = gaussian_filter(signal_reshaped, sigma=window_length.value/3)\n",
    "                    \n",
    "                    # Noise reduction\n",
    "                    if noise_method.value == 'median':\n",
    "                        processed_signal = median_filter(processed_signal, size=kernel_size.value)\n",
    "                    elif noise_method.value == 'gaussian':\n",
    "                        processed_signal = gaussian_filter(processed_signal, sigma=kernel_size.value/3)\n",
    "                    \n",
    "                    processed_all_signals[signal_name] = processed_signal\n",
    "                    log_message(f\"Processed signal {idx+1}/{total_signals}: {signal_name}\", 'success')\n",
    "                    \n",
    "                    # Update progress\n",
    "                    progress = 50 + int(30 * (idx + 1) / total_signals)\n",
    "                    update_status(f\"Processing signal {idx+1}/{total_signals}...\", progress)\n",
    "                \n",
    "                # Store all processed signals\n",
    "                original_data['processed_all_signals'] = processed_all_signals\n",
    "                # Use first signal for display/visualization\n",
    "                first_signal_name = sorted(all_signals_dict.keys())[0]\n",
    "                processed_signals = processed_all_signals[first_signal_name].flatten()\n",
    "            else:\n",
    "                # Process single signal (original logic)\n",
    "                processed_signals = original_data['signal'].copy()\n",
    "                signal = processed_signals.copy()\n",
    "\n",
    "                # Outlier detection and clipping (preserve grid structure)\n",
    "                if remove_outliers.value:\n",
    "                    if outlier_method.value == 'iqr':\n",
    "                        Q1 = np.percentile(signal, 25)\n",
    "                        Q3 = np.percentile(signal, 75)\n",
    "                        IQR = Q3 - Q1\n",
    "                        lower = Q1 - outlier_threshold.value * IQR\n",
    "                        upper = Q3 + outlier_threshold.value * IQR\n",
    "                        # Clip outliers instead of removing them to preserve grid structure\n",
    "                        signal = np.clip(signal, lower, upper)\n",
    "                        log_message(f\"‚úÖ Clipped outliers for signal {signal_name}: bounds=[{lower:.2f}, {upper:.2f}]\", 'info')\n",
    "                 \n",
    "                # Smoothing\n",
    "                if smooth_method.value == 'savgol':\n",
    "                    # Reshape for processing\n",
    "                    signal_reshaped = signal.reshape(original_data['grid_shape'])\n",
    "                    # Apply Savitzky-Golay filter\n",
    "                    from scipy.signal import savgol_filter\n",
    "                    # Validate and adjust window_length for Savitzky-Golay filter\n",
    "                    grid_shape = signal_reshaped.shape\n",
    "                    wl = window_length.value\n",
    "                    po = poly_order.value\n",
    "                    \n",
    "                    # Find the best axis (largest dimension)\n",
    "                    best_axis = np.argmax(grid_shape)\n",
    "                    max_size = grid_shape[best_axis]\n",
    "                    \n",
    "                    # Ensure window_length is valid\n",
    "                    if wl > max_size:\n",
    "                        wl = max_size if max_size % 2 == 1 else max_size - 1\n",
    "                        if wl < po + 1:\n",
    "                            wl = po + 1 if (po + 1) % 2 == 1 else po + 2\n",
    "                        log_message(f\"Adjusted window_length from {window_length.value} to {wl} (signal size: {max_size})\", 'warning')\n",
    "                    \n",
    "                    # Ensure window_length is odd and >= poly_order + 1\n",
    "                    if wl % 2 == 0:\n",
    "                        wl = wl - 1\n",
    "                    if wl < po + 1:\n",
    "                        wl = po + 1 if (po + 1) % 2 == 1 else po + 2\n",
    "                    \n",
    "                    # Apply filter along the best axis\n",
    "                    try:\n",
    "                        signal_smooth = savgol_filter(signal_reshaped, wl, po, axis=best_axis)\n",
    "                        processed_signals = signal_smooth.flatten()\n",
    "                    except Exception as e:\n",
    "                        log_message(f\"Savitzky-Golay filter failed: {e}. Using original signal.\", 'warning')\n",
    "                        processed_signals = signal.flatten()\n",
    "                elif smooth_method.value == 'moving':\n",
    "                    # Moving average\n",
    "                    signal_reshaped = signal.reshape(original_data['grid_shape'])\n",
    "                    kernel = np.ones(window_length.value) / window_length.value\n",
    "                    processed_signals = np.convolve(signal, kernel, mode='same')\n",
    "                else:  # gaussian\n",
    "                    signal_reshaped = signal.reshape(original_data['grid_shape'])\n",
    "                    processed_signals = gaussian_filter(signal_reshaped, sigma=window_length.value/3).flatten()\n",
    "                \n",
    "                # Noise reduction\n",
    "                if noise_method.value == 'median':\n",
    "                    signal_reshaped = processed_signals.reshape(original_data['grid_shape'])\n",
    "                    processed_signals = median_filter(signal_reshaped, size=kernel_size.value).flatten()\n",
    "                elif noise_method.value == 'gaussian':\n",
    "                    signal_reshaped = processed_signals.reshape(original_data['grid_shape'])\n",
    "                    processed_signals = gaussian_filter(signal_reshaped, sigma=kernel_size.value/3).flatten()\n",
    "            \n",
    "            log_message(\"Signal processing completed\", 'success')\n",
    "            update_status(\"Signal processing completed\", 80)\n",
    "        \n",
    "        # Calculate comprehensive metrics\n",
    "        log_message(\"Calculating processing metrics...\", 'info')\n",
    "        update_status(\"Calculating metrics...\", 85)\n",
    "        processing_results = {}\n",
    "        \n",
    "        # Correction metrics\n",
    "        if mode == 'correction' or mode == 'both':\n",
    "            # Calculate actual correction metrics if possible\n",
    "            if original_data and corrected_data:\n",
    "                # Calculate point displacement\n",
    "                if 'points' in original_data and 'points' in corrected_data:\n",
    "                    original_points = original_data['points']\n",
    "                    corrected_points = corrected_data['points']\n",
    "                    if len(original_points) == len(corrected_points):\n",
    "                        displacement = np.linalg.norm(corrected_points - original_points, axis=1)\n",
    "                        processing_results['correction'] = {\n",
    "                            'mean_error': float(np.mean(displacement)),\n",
    "                            'max_error': float(np.max(displacement)),\n",
    "                            'rms_error': float(np.sqrt(np.mean(displacement**2))),\n",
    "                            'min_error': float(np.min(displacement)),\n",
    "                            'std_error': float(np.std(displacement)),\n",
    "                            'score': float(1.0 / (1.0 + np.mean(displacement)))  # Higher is better\n",
    "                        }\n",
    "                    else:\n",
    "                        # Fallback metrics\n",
    "                        processing_results['correction'] = {\n",
    "                            'mean_error': 0.05,\n",
    "                            'max_error': 0.15,\n",
    "                            'rms_error': 0.08,\n",
    "                            'score': 0.95,\n",
    "                            'note': 'Estimated metrics (point count mismatch)'\n",
    "                        }\n",
    "                else:\n",
    "                    processing_results['correction'] = {\n",
    "                        'mean_error': 0.05,\n",
    "                        'max_error': 0.15,\n",
    "                        'rms_error': 0.08,\n",
    "                        'score': 0.95,\n",
    "                        'note': 'Estimated metrics'\n",
    "                    }\n",
    "        \n",
    "        # Processing metrics\n",
    "        if mode == 'processing' or mode == 'both':\n",
    "            if original_data and processed_signals is not None:\n",
    "                original_signal = original_data.get('signal', [])\n",
    "                if len(original_signal) > 0 and len(processed_signals) > 0:\n",
    "                    # Calculate SNR improvement\n",
    "                    orig_snr = np.mean(original_signal) / (np.std(original_signal) + 1e-10)\n",
    "                    proc_snr = np.mean(processed_signals) / (np.std(processed_signals) + 1e-10)\n",
    "                    snr_improvement = proc_snr - orig_snr\n",
    "                    \n",
    "                    # Calculate noise reduction (std reduction)\n",
    "                    noise_reduction = 1.0 - (np.std(processed_signals) / (np.std(original_signal) + 1e-10))\n",
    "                    \n",
    "                    # Quality score (based on SNR and consistency)\n",
    "                    quality_score = min(1.0, (proc_snr / (orig_snr + 1.0)) * (1.0 + noise_reduction) / 2.0)\n",
    "                    \n",
    "                    processing_results['processing'] = {\n",
    "                        'snr_improvement': float(snr_improvement),\n",
    "                        'noise_reduction': float(noise_reduction),\n",
    "                        'quality_score': float(quality_score),\n",
    "                        'original_snr': float(orig_snr),\n",
    "                        'processed_snr': float(proc_snr),\n",
    "                        'original_std': float(np.std(original_signal)),\n",
    "                        'processed_std': float(np.std(processed_signals))\n",
    "                    }\n",
    "                else:\n",
    "                    processing_results['processing'] = {\n",
    "                        'snr_improvement': 5.2,\n",
    "                        'noise_reduction': 0.3,\n",
    "                        'quality_score': 0.92,\n",
    "                        'note': 'Estimated metrics'\n",
    "                    }\n",
    "        \n",
    "        log_message(\"Metrics calculated\", 'success')\n",
    "        update_status(\"Updating displays...\", 90)\n",
    "        \n",
    "        # Update displays\n",
    "        update_results_display()\n",
    "        update_visualization()\n",
    "\n",
    "        # Show unified save button if MongoDB is available and processing completed\n",
    "        if INFRASTRUCTURE_AVAILABLE:\n",
    "            if (mode == 'correction' and corrected_data is not None) or \\\n",
    "               (mode == 'processing' and processed_signals is not None) or \\\n",
    "               (mode == 'both' and (corrected_data is not None or processed_signals is not None)):\n",
    "                save_button.layout.display = 'flex'\n",
    "                \n",
    "        # Calculate total execution time\n",
    "        if operation_start_time:\n",
    "            total_time = time.time() - operation_start_time\n",
    "            if process_all_signals:\n",
    "                num_signals = len(original_data.get('processed_all_signals', {}))\n",
    "                log_message(f\"Processing completed: {num_signals} signal(s) processed in {total_time:.2f}s\", 'success')\n",
    "                update_status(f\"Processing completed: {num_signals} signal(s) processed\", 100)\n",
    "            else:\n",
    "                log_message(f\"Processing completed successfully in {total_time:.2f}s\", 'success')\n",
    "                update_status(\"Processing completed successfully\", 100)\n",
    "        else:\n",
    "            if process_all_signals:\n",
    "                num_signals = len(original_data.get('processed_all_signals', {}))\n",
    "                log_message(f\"Processing completed: {num_signals} signal(s) processed\", 'success')\n",
    "                update_status(f\"Processing completed: {num_signals} signal(s) processed\", 100)\n",
    "            else:\n",
    "                log_message(\"Processing completed successfully\", 'success')\n",
    "                update_status(\"Processing completed successfully\", 100)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during processing: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "        error_display.value = f\"<span style='color: red;'>‚ùå Error: {str(e)}</span>\"\n",
    "        update_status(\"Error during processing\", 0)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def handle_save(button):\n",
    "    \"\"\"Unified save handler - saves corrected or processed grid based on mode.\"\"\"\n",
    "    mode = processing_mode.value\n",
    "    \n",
    "    if mode == 'correction':\n",
    "        if corrected_data is not None:\n",
    "            save_corrected_grid(button)\n",
    "        else:\n",
    "            log_message(\"No corrected data to save. Please run correction first.\", 'warning')\n",
    "            error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No corrected data to save. Please run correction first.</span>\"\n",
    "    elif mode == 'processing':\n",
    "        if processed_signals is not None:\n",
    "            save_processed_grid(button)\n",
    "        else:\n",
    "            log_message(\"No processed data to save. Please run processing first.\", 'warning')\n",
    "            error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No processed data to save. Please run processing first.</span>\"\n",
    "    elif mode == 'both':\n",
    "        # Save both - corrected first, then processed\n",
    "        if corrected_data is not None:\n",
    "            save_corrected_grid(button)\n",
    "        if processed_signals is not None:\n",
    "            save_processed_grid(button)\n",
    "    else:\n",
    "        log_message(\"No data to save. Please execute processing first.\", 'warning')\n",
    "        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No data to save. Please execute processing first.</span>\"\n",
    "        \n",
    "def save_corrected_grid(button):\n",
    "    \"\"\"Save corrected grid to MongoDB using naming convention.\"\"\"\n",
    "    global corrected_data, current_model_id, current_grid_id, voxel_storage, signal_arrays, loaded_grid_data, operation_start_time\n",
    "    \n",
    "    # Initialize timing\n",
    "    operation_start_time = time.time()\n",
    "    \n",
    "    # Clear logs\n",
    "    with processing_logs:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    log_message(\"Starting corrected grid save operation...\", 'info')\n",
    "    update_status(\"Initializing save...\", 0)\n",
    "    \n",
    "    if not voxel_storage or not mongo_client:\n",
    "        log_message(\"MongoDB not available. Cannot save grid.\", 'error')\n",
    "        error_display.value = \"<span style='color: red;'>‚ùå MongoDB not available</span>\"\n",
    "        update_status(\"MongoDB unavailable\", 0)\n",
    "        return\n",
    "    \n",
    "    if corrected_data is None:\n",
    "        log_message(\"No corrected data to save. Please run correction first.\", 'warning')\n",
    "        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No corrected data to save. Please run correction first.</span>\"\n",
    "        update_status(\"No corrected data\", 0)\n",
    "        return\n",
    "    \n",
    "    # Import GridNaming (required - no fallback)\n",
    "    try:\n",
    "        from am_qadf.voxel_domain import GridNaming\n",
    "    except ImportError as e:\n",
    "        log_message(f\"‚ùå GridNaming module not available: {e}\", 'error')\n",
    "        error_display.value = \"<span style='color: red;'>‚ùå GridNaming module not available. Cannot generate proper grid name.</span>\"\n",
    "        update_status(\"Error: GridNaming not available\", 0)\n",
    "        return\n",
    "    \n",
    "    log_message(\"Saving corrected grid...\", 'info')\n",
    "    error_display.value = \"\"\n",
    "    \n",
    "    try:\n",
    "        # Get model name\n",
    "        model_name = None\n",
    "        if stl_client:\n",
    "            try:\n",
    "                model_info = stl_client.get_model(current_model_id)\n",
    "                if model_info:\n",
    "                    model_name = model_info.get('model_name') or model_info.get('filename', 'Unknown')\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Read source, grid_type, and resolution from metadata (NO UUID fallback)\n",
    "        if not loaded_grid_data:\n",
    "            log_message(\"‚ùå Original grid data not loaded. Cannot determine grid metadata.\", 'error')\n",
    "            error_display.value = \"<span style='color: red;'>‚ùå Original grid data not loaded. Please load a grid first.</span>\"\n",
    "            update_status(\"Error: No grid data\", 0)\n",
    "            return\n",
    "        \n",
    "        metadata = loaded_grid_data.get('metadata', {})\n",
    "        config_metadata_orig = metadata.get('configuration_metadata', {})\n",
    "        \n",
    "        source = config_metadata_orig.get('source', '')\n",
    "        grid_type = config_metadata_orig.get('grid_type', '')\n",
    "        resolution = metadata.get('resolution', None) or config_metadata_orig.get('resolution', None)\n",
    "        \n",
    "        # Validate required fields\n",
    "        if not source or not grid_type or resolution is None:\n",
    "            log_message(f\"‚ùå Missing required fields in metadata. Source: {source}, GridType: {grid_type}, Resolution: {resolution}. Cannot generate proper corrected grid name.\", 'error')\n",
    "            error_display.value = \"<span style='color: red;'>‚ùå Missing metadata fields. Cannot save grid.</span>\"\n",
    "            update_status(\"Error: Missing metadata\", 0)\n",
    "            return\n",
    "        \n",
    "        # Convert resolution to float if needed\n",
    "        resolution = float(resolution)\n",
    "        \n",
    "        # Get correction type\n",
    "        correction_type = distortion_type.value  # scaling, rotation, warping, or combined\n",
    "        \n",
    "        # Generate corrected grid name using naming convention (NO UUID fallback)\n",
    "        grid_name = GridNaming.generate_corrected_grid_name(\n",
    "            source=source,\n",
    "            grid_type=grid_type,\n",
    "            resolution=resolution,\n",
    "            correction_type=correction_type\n",
    "        )\n",
    "        log_message(f\"Generated corrected grid name using GridNaming: {grid_name}\", 'info')\n",
    "        \n",
    "        # Reconstruct voxel grid from corrected data\n",
    "        from am_qadf.voxelization.voxel_grid import VoxelGrid\n",
    "        \n",
    "        # Extract corrected bounding box\n",
    "        points = corrected_data['points']\n",
    "        bbox_min = tuple(points.min(axis=0))\n",
    "        bbox_max = tuple(points.max(axis=0))\n",
    "        \n",
    "        # Create new grid with corrected bounds\n",
    "        corrected_grid = VoxelGrid(\n",
    "            bbox_min=bbox_min,\n",
    "            bbox_max=bbox_max,\n",
    "            resolution=resolution,\n",
    "            aggregation='mean'\n",
    "        )\n",
    "        \n",
    "        # Map signals from original grid to corrected grid structure\n",
    "        # Signals must be mapped to the corrected grid's dimensions (which may differ after geometric correction)\n",
    "        if signal_arrays and len(signal_arrays) > 0:\n",
    "            log_message(f\"Mapping {len(signal_arrays)} signal(s) to corrected grid: {list(signal_arrays.keys())}\", 'info')\n",
    "            \n",
    "            # Get original grid dimensions and corrected grid dimensions\n",
    "            original_dims = metadata.get('dims', [50, 50, 50])\n",
    "            corrected_dims = tuple(corrected_grid.dims)  # This is the actual corrected grid dimensions\n",
    "            \n",
    "            log_message(f\"Original grid dimensions: {original_dims}, Corrected grid dimensions: {corrected_dims}\", 'info')\n",
    "            \n",
    "            # Map each signal to the corrected grid structure\n",
    "            signals_copied = 0\n",
    "            for signal_name, signal_array in signal_arrays.items():\n",
    "                if not isinstance(signal_array, np.ndarray):\n",
    "                    signal_array = np.array(signal_array, dtype=np.float32)\n",
    "                \n",
    "                # Log initial signal info\n",
    "                log_message(f\"Mapping signal {signal_name}: original shape={signal_array.shape}, size={signal_array.size}\", 'info')\n",
    "                \n",
    "                # Ensure original signal is 3D\n",
    "                if signal_array.ndim != 3:\n",
    "                    if signal_array.size == np.prod(original_dims):\n",
    "                        signal_array = signal_array.reshape(original_dims).astype(np.float32)\n",
    "                        log_message(f\"‚úÖ Reshaped original signal {signal_name} to 3D: {signal_array.shape}\", 'info')\n",
    "                    else:\n",
    "                        log_message(f\"‚ö†Ô∏è WARNING: Cannot reshape signal {signal_name} from {signal_array.shape} to {original_dims}\", 'warning')\n",
    "                        # Create zero-filled array with original dimensions as fallback\n",
    "                        signal_array = np.full(original_dims, 0.0, dtype=np.float32)\n",
    "                \n",
    "                # Map signal to corrected grid dimensions using interpolation\n",
    "                try:\n",
    "                    from scipy.ndimage import zoom\n",
    "                    \n",
    "                    # Calculate zoom factors to map from original to corrected dimensions\n",
    "                    zoom_factors = [\n",
    "                        corrected_dims[0] / original_dims[0],\n",
    "                        corrected_dims[1] / original_dims[1],\n",
    "                        corrected_dims[2] / original_dims[2]\n",
    "                    ]\n",
    "                    \n",
    "                    # Interpolate signal to corrected grid dimensions (order=1 for linear interpolation)\n",
    "                    signal_mapped = zoom(signal_array, zoom_factors, order=1, mode='nearest').astype(np.float32)\n",
    "                    \n",
    "                    log_message(f\"‚úÖ Mapped signal {signal_name} from {signal_array.shape} to {signal_mapped.shape} using zoom factors {zoom_factors}\", 'info')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    log_message(f\"‚ö†Ô∏è Interpolation failed for signal {signal_name}: {e}. Using nearest neighbor resize.\", 'warning')\n",
    "                    # Fallback: simple resize using nearest neighbor\n",
    "                    try:\n",
    "                        from scipy.ndimage import zoom\n",
    "                        zoom_factors = [\n",
    "                            corrected_dims[0] / original_dims[0],\n",
    "                            corrected_dims[1] / original_dims[1],\n",
    "                            corrected_dims[2] / original_dims[2]\n",
    "                        ]\n",
    "                        signal_mapped = zoom(signal_array, zoom_factors, order=0, mode='nearest').astype(np.float32)\n",
    "                        log_message(f\"‚úÖ Resized signal {signal_name} using nearest neighbor: {signal_mapped.shape}\", 'info')\n",
    "                    except Exception as e2:\n",
    "                        log_message(f\"‚ùå ERROR: Failed to map signal {signal_name}: {e2}. Creating zero-filled array.\", 'error')\n",
    "                        signal_mapped = np.full(corrected_dims, 0.0, dtype=np.float32)\n",
    "                \n",
    "                # Verify final shape matches corrected grid dimensions\n",
    "                if signal_mapped.shape != corrected_dims:\n",
    "                    log_message(f\"‚ö†Ô∏è WARNING: Mapped signal {signal_name} shape {signal_mapped.shape} doesn't match corrected dims {corrected_dims}. Resizing...\", 'warning')\n",
    "                    if signal_mapped.size == np.prod(corrected_dims):\n",
    "                        signal_mapped = signal_mapped.reshape(corrected_dims).astype(np.float32)\n",
    "                    else:\n",
    "                        # Create zero-filled array with correct dimensions\n",
    "                        signal_mapped = np.full(corrected_dims, 0.0, dtype=np.float32)\n",
    "                        log_message(f\"‚ö†Ô∏è Created zero-filled array for signal {signal_name} due to size mismatch\", 'warning')\n",
    "                \n",
    "                # Verify it's 3D\n",
    "                if signal_mapped.ndim != 3:\n",
    "                    log_message(f\"‚ùå ERROR: Mapped signal {signal_name} is not 3D! Shape: {signal_mapped.shape}\", 'error')\n",
    "                    signal_mapped = np.full(corrected_dims, 0.0, dtype=np.float32)\n",
    "                \n",
    "                # Add signal to corrected grid\n",
    "                if not hasattr(corrected_grid, '_signal_arrays'):\n",
    "                    corrected_grid._signal_arrays = {}\n",
    "                corrected_grid._signal_arrays[signal_name] = signal_mapped\n",
    "                \n",
    "                # Verify it's stored correctly\n",
    "                log_message(f\"‚úÖ Stored signal {signal_name} in corrected grid: shape={signal_mapped.shape}, dtype={signal_mapped.dtype}, min={np.nanmin(signal_mapped):.2f}, max={np.nanmax(signal_mapped):.2f}\", 'info')\n",
    "                \n",
    "                # Also set available_signals\n",
    "                if not hasattr(corrected_grid, 'available_signals'):\n",
    "                    corrected_grid.available_signals = set()\n",
    "                corrected_grid.available_signals.add(signal_name)\n",
    "                signals_copied += 1\n",
    "            \n",
    "            log_message(f\"Successfully mapped {signals_copied} signal(s) to corrected grid. Available signals: {sorted(corrected_grid.available_signals)}\", 'success')\n",
    "            \n",
    "            # Add a get_signal_array method to the grid for voxel_storage compatibility\n",
    "            # This must match VoxelGrid.get_signal_array behavior: always return 3D array, never None\n",
    "            def get_signal_array(signal_name, default=0.0):\n",
    "                # Use corrected grid dimensions (signals are now mapped to corrected grid structure)\n",
    "                grid_dims = tuple(corrected_grid.dims)\n",
    "                \n",
    "                # Check if signal exists in _signal_arrays\n",
    "                if hasattr(corrected_grid, '_signal_arrays') and signal_name in corrected_grid._signal_arrays:\n",
    "                    signal_array = corrected_grid._signal_arrays[signal_name]\n",
    "                    \n",
    "                    # Ensure it's a numpy array\n",
    "                    if not isinstance(signal_array, np.ndarray):\n",
    "                        signal_array = np.array(signal_array, dtype=np.float32)\n",
    "                    \n",
    "                    # Verify 3D structure\n",
    "                    if signal_array.ndim != 3:\n",
    "                        # Try to reshape if size matches\n",
    "                        if signal_array.size == np.prod(grid_dims):\n",
    "                            signal_array = signal_array.reshape(grid_dims).astype(np.float32)\n",
    "                        else:\n",
    "                            # Can't reshape - return default array\n",
    "                            return np.full(grid_dims, default, dtype=np.float32)\n",
    "                    \n",
    "                    # Verify shape matches grid dimensions\n",
    "                    if signal_array.shape != grid_dims:\n",
    "                        if signal_array.size == np.prod(grid_dims):\n",
    "                            signal_array = signal_array.reshape(grid_dims).astype(np.float32)\n",
    "                        else:\n",
    "                            # Shape mismatch and size mismatch - return default\n",
    "                            return np.full(grid_dims, default, dtype=np.float32)\n",
    "                    else:\n",
    "                        # Shape matches - ensure correct dtype\n",
    "                        signal_array = signal_array.astype(np.float32)\n",
    "                    \n",
    "                    # Return a copy to ensure data integrity\n",
    "                    return np.array(signal_array, dtype=np.float32, copy=True)\n",
    "                \n",
    "                # Signal not found - return array with default values (consistent with VoxelGrid.get_signal_array)\n",
    "                return np.full(grid_dims, default, dtype=np.float32)\n",
    "            \n",
    "            corrected_grid.get_signal_array = get_signal_array\n",
    "            \n",
    "            # Verify all signals are accessible before saving\n",
    "            log_message(\"Verifying signals are accessible before saving...\", 'info')\n",
    "            signals_verified = 0\n",
    "            signals_failed = []\n",
    "            \n",
    "            # Check if _signal_arrays exists and has signals\n",
    "            if not hasattr(corrected_grid, '_signal_arrays') or not corrected_grid._signal_arrays:\n",
    "                log_message(\"‚ùå ERROR: corrected_grid._signal_arrays is missing or empty!\", 'error')\n",
    "                error_display.value = \"<span style='color: red;'>‚ùå No signals in corrected grid. Cannot save.</span>\"\n",
    "                update_status(\"No signals to save\", 0)\n",
    "                return\n",
    "            \n",
    "            log_message(f\"Found {len(corrected_grid._signal_arrays)} signal(s) in _signal_arrays: {list(corrected_grid._signal_arrays.keys())}\", 'info')\n",
    "            \n",
    "            # Verify each signal\n",
    "            for signal_name in corrected_grid.available_signals:\n",
    "                try:\n",
    "                    # Check if signal is in _signal_arrays\n",
    "                    if signal_name not in corrected_grid._signal_arrays:\n",
    "                        signals_failed.append(f\"{signal_name} (not in _signal_arrays)\")\n",
    "                        log_message(f\"‚ùå Signal {signal_name}: Not found in _signal_arrays\", 'error')\n",
    "                        continue\n",
    "                    \n",
    "                    # Check signal in _signal_arrays\n",
    "                    signal_in_storage = corrected_grid._signal_arrays[signal_name]\n",
    "                    log_message(f\"Signal {signal_name} in _signal_arrays: shape={signal_in_storage.shape if hasattr(signal_in_storage, 'shape') else 'unknown'}, type={type(signal_in_storage)}\", 'info')\n",
    "                    \n",
    "                    # Test get_signal_array\n",
    "                    signal_array = corrected_grid.get_signal_array(signal_name, default=0.0)\n",
    "                    if signal_array is None:\n",
    "                        signals_failed.append(f\"{signal_name} (get_signal_array returned None)\")\n",
    "                        log_message(f\"‚ùå Signal {signal_name}: get_signal_array returned None\", 'error')\n",
    "                    elif signal_array.ndim != 3:\n",
    "                        signals_failed.append(f\"{signal_name} (not 3D: {signal_array.shape})\")\n",
    "                        log_message(f\"‚ùå Signal {signal_name}: Not 3D! Shape: {signal_array.shape}\", 'error')\n",
    "                    elif signal_array.size == 0:\n",
    "                        signals_failed.append(f\"{signal_name} (empty array)\")\n",
    "                        log_message(f\"‚ùå Signal {signal_name}: Empty array\", 'error')\n",
    "                    else:\n",
    "                        signals_verified += 1\n",
    "                        log_message(f\"‚úÖ Signal {signal_name}: Verified - shape={signal_array.shape}, size={signal_array.size}, dtype={signal_array.dtype}, min={np.nanmin(signal_array):.2f}, max={np.nanmax(signal_array):.2f}\", 'success')\n",
    "                except Exception as e:\n",
    "                    signals_failed.append(f\"{signal_name} (error: {str(e)})\")\n",
    "                    log_message(f\"‚ùå Signal {signal_name}: Error accessing - {e}\", 'error')\n",
    "                    import traceback\n",
    "                    log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "            \n",
    "            if signals_failed:\n",
    "                error_msg = f\"‚ùå {len(signals_failed)} signal(s) failed verification: {', '.join(signals_failed)}\"\n",
    "                log_message(error_msg, 'error')\n",
    "                error_display.value = f\"<span style='color: red;'>{error_msg}. Cannot save grid.</span>\"\n",
    "                update_status(\"Signal verification failed\", 0)\n",
    "                return\n",
    "            \n",
    "            log_message(f\"‚úÖ All {signals_verified} signal(s) verified successfully. Proceeding to save...\", 'success')\n",
    "        else:\n",
    "            log_message(\"WARNING: No signal arrays found to copy to corrected grid!\", 'warning')\n",
    "            error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No signals to save. Cannot save grid.</span>\"\n",
    "            update_status(\"No signals to save\", 0)\n",
    "            return\n",
    "        \n",
    "        # Store comprehensive correction metadata - COMPREHENSIVE (include source, grid_type, resolution)\n",
    "        config_metadata = {\n",
    "            # CRITICAL: Source, grid_type, resolution (required for all operations)\n",
    "            'source': source,\n",
    "            'grid_type': grid_type,\n",
    "            'resolution': resolution,\n",
    "            \n",
    "            # Correction information\n",
    "            'correction_type': correction_type,\n",
    "            'correction_applied': True,\n",
    "            'original_grid_id': current_grid_id,\n",
    "            'original_grid_name': loaded_grid_data.get('grid_name', ''),\n",
    "            'correction_timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Scaling parameters\n",
    "        if correction_type == 'scaling' or correction_type == 'combined':\n",
    "            config_metadata['scaling'] = {\n",
    "                'scale_x': scale_x.value,\n",
    "                'scale_y': scale_y.value,\n",
    "                'scale_z': scale_z.value,\n",
    "                'uniform_scale': uniform_scale.value\n",
    "            }\n",
    "        \n",
    "        # Rotation parameters\n",
    "        if correction_type == 'rotation' or correction_type == 'combined':\n",
    "            config_metadata['rotation'] = {\n",
    "                'rot_x_deg': rot_x.value,\n",
    "                'rot_y_deg': rot_y.value,\n",
    "                'rot_z_deg': rot_z.value,\n",
    "                'rotation_center': {\n",
    "                    'x': rot_center_x.value,\n",
    "                    'y': rot_center_y.value,\n",
    "                    'z': rot_center_z.value\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Warping parameters\n",
    "        if correction_type == 'warping' or correction_type == 'combined':\n",
    "            config_metadata['warping'] = {\n",
    "                'warp_type': warp_type.value,\n",
    "                'warp_degree': warp_degree.value\n",
    "            }\n",
    "        \n",
    "        # Calibration data (if used)\n",
    "        if use_calibration.value:\n",
    "            config_metadata['calibration'] = {\n",
    "                'calibration_id': calibration_selector.value,\n",
    "                'calibration_used': True\n",
    "            }\n",
    "        \n",
    "        # Correction metrics (if available)\n",
    "        if processing_results and 'correction' in processing_results:\n",
    "            config_metadata['correction_metrics'] = processing_results['correction']\n",
    "        \n",
    "        # Store corrected bounding box\n",
    "        config_metadata['corrected_bbox'] = {\n",
    "            'bbox_min': list(bbox_min),\n",
    "            'bbox_max': list(bbox_max)\n",
    "        }\n",
    "        \n",
    "        # Save grid\n",
    "        log_message(\"Saving grid to MongoDB...\", 'info')\n",
    "        update_status(\"Saving grid to MongoDB...\", 80)\n",
    "        saved_grid_id = voxel_storage.save_voxel_grid(\n",
    "            model_id=current_model_id,\n",
    "            grid_name=grid_name,\n",
    "            voxel_grid=corrected_grid,\n",
    "            description=f\"Corrected {source.upper()} grid ({correction_type}) - {model_name}\",\n",
    "            model_name=model_name,\n",
    "            configuration_metadata=config_metadata,\n",
    "            tags=['corrected', correction_type, source, grid_type]\n",
    "        )\n",
    "        \n",
    "        log_message(f\"Grid saved with ID: {saved_grid_id[:8]}...\", 'success')\n",
    "        log_message(f\"Corrected grid contains {len(corrected_grid.available_signals)} signal(s): {sorted(corrected_grid.available_signals)}\", 'info')\n",
    "        \n",
    "        # Verify signals were actually saved to GridFS\n",
    "        log_message(\"Verifying signals were saved to GridFS...\", 'info')\n",
    "        try:\n",
    "            from bson import ObjectId\n",
    "            collection = mongo_client.get_collection('voxel_grids')\n",
    "            saved_grid_doc = collection.find_one({'_id': ObjectId(saved_grid_id)})\n",
    "            \n",
    "            if saved_grid_doc:\n",
    "                signal_references = saved_grid_doc.get('signal_references', {})\n",
    "                available_signals_in_db = saved_grid_doc.get('available_signals', [])\n",
    "                \n",
    "                log_message(f\"Grid document has {len(signal_references)} signal reference(s) in GridFS\", 'info')\n",
    "                log_message(f\"Grid document lists {len(available_signals_in_db)} available signal(s): {available_signals_in_db}\", 'info')\n",
    "                \n",
    "                if len(signal_references) == 0:\n",
    "                    log_message(f\"‚ùå ERROR: No signals were saved to GridFS! signal_references is empty.\", 'error')\n",
    "                    log_message(f\"Expected {len(corrected_grid.available_signals)} signal(s): {sorted(corrected_grid.available_signals)}\", 'error')\n",
    "                    error_display.value = f\"<span style='color: red;'>‚ùå WARNING: Grid saved but NO signals were saved to GridFS! This grid cannot be loaded properly.</span>\"\n",
    "                elif len(signal_references) < len(corrected_grid.available_signals):\n",
    "                    missing = set(corrected_grid.available_signals) - set(signal_references.keys())\n",
    "                    log_message(f\"‚ö†Ô∏è WARNING: Only {len(signal_references)}/{len(corrected_grid.available_signals)} signals saved to GridFS. Missing: {sorted(missing)}\", 'warning')\n",
    "                    error_display.value = f\"<span style='color: orange;'>‚ö†Ô∏è WARNING: Only {len(signal_references)}/{len(corrected_grid.available_signals)} signals saved to GridFS.</span>\"\n",
    "                else:\n",
    "                    log_message(f\"‚úÖ All {len(signal_references)} signal(s) successfully saved to GridFS: {sorted(signal_references.keys())}\", 'success')\n",
    "            else:\n",
    "                log_message(f\"‚ö†Ô∏è WARNING: Could not verify saved grid - document not found\", 'warning')\n",
    "        except Exception as e:\n",
    "            log_message(f\"‚ö†Ô∏è Error verifying saved grid: {e}\", 'warning')\n",
    "            import traceback\n",
    "            log_message(f\"Traceback: {traceback.format_exc()}\", 'warning')\n",
    "        \n",
    "        # Calculate total execution time\n",
    "        if operation_start_time:\n",
    "            total_time = time.time() - operation_start_time\n",
    "            log_message(f\"Corrected grid saved successfully in {total_time:.2f}s (ID: {saved_grid_id[:8]}...)\", 'success')\n",
    "        else:\n",
    "            log_message(f\"Corrected grid saved successfully (ID: {saved_grid_id[:8]}...)\", 'success')\n",
    "        \n",
    "        update_status(\"Corrected grid saved successfully\", 100)\n",
    "        error_display.value = f\"<span style='color: green;'>‚úÖ Saved corrected grid: {grid_name} (ID: {saved_grid_id[:8]}...) with {len(corrected_grid.available_signals)} signal(s)</span>\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error saving corrected grid: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "        error_display.value = f\"<span style='color: red;'>‚ùå Error saving corrected grid: {str(e)}</span>\"\n",
    "        update_status(\"Error saving grid\", 0)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "def save_processed_grid(button):\n",
    "    \"\"\"Save processed grid with processed signals to MongoDB using naming convention.\"\"\"\n",
    "    global processed_signals, current_model_id, current_grid_id, voxel_storage, signal_arrays, original_data, loaded_grid_data, operation_start_time\n",
    "    \n",
    "    # Initialize timing\n",
    "    operation_start_time = time.time()\n",
    "    \n",
    "    # Clear logs\n",
    "    with processing_logs:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    log_message(\"Starting processed grid save operation...\", 'info')\n",
    "    update_status(\"Initializing save...\", 0)\n",
    "    \n",
    "    if not voxel_storage or not mongo_client:\n",
    "        log_message(\"MongoDB not available. Cannot save grid.\", 'error')\n",
    "        error_display.value = \"<span style='color: red;'>‚ùå MongoDB not available</span>\"\n",
    "        update_status(\"MongoDB unavailable\", 0)\n",
    "        return\n",
    "    \n",
    "    if processed_signals is None:\n",
    "        log_message(\"No processed signals to save. Please run processing first.\", 'warning')\n",
    "        error_display.value = \"<span style='color: red;'>‚ö†Ô∏è No processed signals to save. Please run processing first.</span>\"\n",
    "        update_status(\"No processed signals\", 0)\n",
    "        return\n",
    "    \n",
    "    # Import GridNaming (required - no fallback)\n",
    "    try:\n",
    "        from am_qadf.voxel_domain import GridNaming\n",
    "    except ImportError as e:\n",
    "        log_message(f\"‚ùå GridNaming module not available: {e}\", 'error')\n",
    "        error_display.value = \"<span style='color: red;'>‚ùå GridNaming module not available. Cannot generate proper grid name.</span>\"\n",
    "        update_status(\"Error: GridNaming not available\", 0)\n",
    "        return\n",
    "    \n",
    "    log_message(\"Saving processed grid...\", 'info')\n",
    "    error_display.value = \"\"\n",
    "    \n",
    "    try:\n",
    "        # Get model name\n",
    "        model_name = None\n",
    "        if stl_client:\n",
    "            try:\n",
    "                model_info = stl_client.get_model(current_model_id)\n",
    "                if model_info:\n",
    "                    model_name = model_info.get('model_name') or model_info.get('filename', 'Unknown')\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Read source, grid_type, and resolution from metadata (NO UUID fallback)\n",
    "        if not loaded_grid_data:\n",
    "            log_message(\"‚ùå Original grid data not loaded. Cannot determine grid metadata.\", 'error')\n",
    "            error_display.value = \"<span style='color: red;'>‚ùå Original grid data not loaded. Please load a grid first.</span>\"\n",
    "            update_status(\"Error: No grid data\", 0)\n",
    "            return\n",
    "        \n",
    "        metadata = loaded_grid_data.get('metadata', {})\n",
    "        config_metadata_orig = metadata.get('configuration_metadata', {})\n",
    "        \n",
    "        source = config_metadata_orig.get('source', '')\n",
    "        grid_type = config_metadata_orig.get('grid_type', '')\n",
    "        resolution = metadata.get('resolution', None) or config_metadata_orig.get('resolution', None)\n",
    "        \n",
    "        # Validate required fields\n",
    "        if not source or not grid_type or resolution is None:\n",
    "            log_message(f\"‚ùå Missing required fields in metadata. Source: {source}, GridType: {grid_type}, Resolution: {resolution}. Cannot generate proper processed grid name.\", 'error')\n",
    "            error_display.value = \"<span style='color: red;'>‚ùå Missing metadata fields. Cannot save grid.</span>\"\n",
    "            update_status(\"Error: Missing metadata\", 0)\n",
    "            return\n",
    "        \n",
    "        # Convert resolution to float if needed\n",
    "        resolution = float(resolution)\n",
    "        \n",
    "        # Determine processing type based on what was applied\n",
    "        processing_type = None\n",
    "        processing_methods = []\n",
    "        \n",
    "        # Check what processing methods were applied\n",
    "        if smooth_method.value and smooth_method.value != 'none':\n",
    "            processing_methods.append('smoothing')\n",
    "        if noise_method.value and noise_method.value != 'none':\n",
    "            processing_methods.append('noise_reduction')\n",
    "        if derived_signal_type.value != 'none':\n",
    "            processing_methods.append('derived')\n",
    "        \n",
    "        # Determine processing_type\n",
    "        if len(processing_methods) == 0:\n",
    "            processing_type = None  # No processing applied (shouldn't happen, but handle it)\n",
    "        elif len(processing_methods) == 1:\n",
    "            processing_type = processing_methods[0]  # Single method\n",
    "        else:\n",
    "            processing_type = 'combined'  # Multiple methods\n",
    "        \n",
    "        # Generate processed grid name using naming convention (NO UUID fallback)\n",
    "        grid_name = GridNaming.generate_processed_grid_name(\n",
    "            source=source,\n",
    "            grid_type=grid_type,\n",
    "            resolution=resolution,\n",
    "            processing_type=processing_type\n",
    "        )\n",
    "        log_message(f\"Generated processed grid name using GridNaming: {grid_name}\", 'info')\n",
    "        \n",
    "        # Load grid structure from loaded_grid_data (this will be the corrected grid if processing from corrected)\n",
    "        if loaded_grid_data:\n",
    "            metadata = loaded_grid_data.get('metadata', {})\n",
    "            bbox_min = tuple(metadata.get('bbox_min', [-50, -50, 0]))\n",
    "            bbox_max = tuple(metadata.get('bbox_max', [50, 50, 100]))\n",
    "            resolution = metadata.get('resolution', 2.0)\n",
    "        else:\n",
    "            bbox_min = tuple(original_data['points'].min(axis=0))\n",
    "            bbox_max = tuple(original_data['points'].max(axis=0))\n",
    "            resolution = 2.0\n",
    "        \n",
    "        # Reconstruct voxel grid (will have dimensions matching the source grid - corrected or original)\n",
    "        from am_qadf.voxelization.voxel_grid import VoxelGrid\n",
    "        \n",
    "        processed_grid = VoxelGrid(\n",
    "            bbox_min=bbox_min,\n",
    "            bbox_max=bbox_max,\n",
    "            resolution=resolution,\n",
    "            aggregation='mean'\n",
    "        )\n",
    "        \n",
    "        # Get processed grid dimensions (matches source grid - corrected or original)\n",
    "        processed_dims = tuple(processed_grid.dims)\n",
    "        log_message(f\"Processed grid dimensions: {processed_dims} (matches source grid)\", 'info')\n",
    "\n",
    "        # Check if we processed all signals - retrieve from original_data FIRST\n",
    "        processed_all_signals = original_data.get('processed_all_signals', {})\n",
    "        selected_signal_mode = original_data.get('selected_signal_mode', '')\n",
    "        current_dropdown = signal_dropdown.value if signal_dropdown.value else ''\n",
    "        \n",
    "        # Check both: processed_all_signals exists AND we're in \"all\" mode (check both data and dropdown)\n",
    "        process_all = (len(processed_all_signals) > 0) and (selected_signal_mode == 'all' or current_dropdown == 'all')\n",
    "        \n",
    "        # Debug logging\n",
    "        log_message(f\"üîç Save check: processed_all_signals={len(processed_all_signals)}, selected_signal_mode='{selected_signal_mode}', dropdown='{current_dropdown}', process_all={process_all}\", 'info')\n",
    "        if len(processed_all_signals) > 0:\n",
    "            log_message(f\"üîç Processed signals: {list(processed_all_signals.keys())}\", 'info')\n",
    "\n",
    "        # Add debug logging to help diagnose\n",
    "        if len(processed_all_signals) > 0 and selected_signal_mode != 'all':\n",
    "            log_message(f\"‚ö†Ô∏è Warning: processed_all_signals found ({len(processed_all_signals)} signals) but selected_signal_mode is '{selected_signal_mode}', not 'all'\", 'warning')\n",
    "        if selected_signal_mode == 'all' and len(processed_all_signals) == 0:\n",
    "            log_message(f\"‚ö†Ô∏è Warning: selected_signal_mode is 'all' but processed_all_signals is empty. Available keys in original_data: {list(original_data.keys())}\", 'warning')\n",
    "        \n",
    "        log_message(f\"Processing mode: {'all signals' if process_all else 'single signal'}\", 'info')\n",
    "        if process_all:\n",
    "            log_message(f\"Mapping {len(processed_all_signals)} processed signal(s) to processed grid: {list(processed_all_signals.keys())}\", 'info')\n",
    "        else:\n",
    "            log_message(\"Mapping single processed signal to processed grid\", 'info')\n",
    "        \n",
    "        # Map processed signal(s) to processed grid structure - USE PROCESSED GRID DIMENSIONS\n",
    "        if process_all:\n",
    "            # Save all processed signals\n",
    "            signals_saved = 0\n",
    "            for signal_name, processed_signal_array in processed_all_signals.items():\n",
    "                if not isinstance(processed_signal_array, np.ndarray):\n",
    "                    processed_signal_array = np.array(processed_signal_array, dtype=np.float32)\n",
    "                \n",
    "                log_message(f\"Mapping processed signal {signal_name}: original shape={processed_signal_array.shape}, size={processed_signal_array.size}, processed_dims={processed_dims}, expected_size={np.prod(processed_dims)}\", 'info')\n",
    "                \n",
    "                # Ensure processed signal is 3D\n",
    "                if processed_signal_array.ndim != 3:\n",
    "                    if processed_signal_array.size == np.prod(processed_dims):\n",
    "                        processed_signal_array = processed_signal_array.reshape(processed_dims).astype(np.float32)\n",
    "                        log_message(f\"‚úÖ Reshaped processed signal {signal_name} to 3D: {processed_signal_array.shape}\", 'info')\n",
    "                    else:\n",
    "                        log_message(f\"‚ö†Ô∏è WARNING: Cannot reshape processed signal {signal_name} from {processed_signal_array.shape} to {processed_dims}\", 'warning')\n",
    "                        # Create zero-filled array with processed dimensions as fallback\n",
    "                        processed_signal_array = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "                \n",
    "                # Map signal to processed grid dimensions (should already match, but verify)\n",
    "                if processed_signal_array.shape == processed_dims:\n",
    "                    # Already correct shape\n",
    "                    processed_signal_reshaped = processed_signal_array.astype(np.float32)\n",
    "                    log_message(f\"‚úÖ Processed signal {signal_name} already matches processed grid dimensions: {processed_signal_reshaped.shape}\", 'info')\n",
    "                elif processed_signal_array.size == np.prod(processed_dims):\n",
    "                    # Size matches - reshape to processed grid dimensions\n",
    "                    processed_signal_reshaped = processed_signal_array.reshape(processed_dims).astype(np.float32)\n",
    "                    log_message(f\"‚úÖ Reshaped processed signal {signal_name} from {processed_signal_array.shape} to processed grid dimensions: {processed_signal_reshaped.shape}\", 'info')\n",
    "                else:\n",
    "                    # Size mismatch - this shouldn't happen if processing was done correctly\n",
    "                    log_message(f\"‚ö†Ô∏è WARNING: Processed signal {signal_name} size {processed_signal_array.size} doesn't match processed grid size {np.prod(processed_dims)}. Shape: {processed_signal_array.shape}\", 'warning')\n",
    "                    if processed_signal_array.ndim == 3:\n",
    "                        processed_signal_reshaped = processed_signal_array.astype(np.float32)\n",
    "                        log_message(f\"‚ö†Ô∏è Using processed signal {signal_name} with mismatched 3D shape: {processed_signal_reshaped.shape}\", 'warning')\n",
    "                    else:\n",
    "                        # Create zero-filled 3D array\n",
    "                        processed_signal_reshaped = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "                        log_message(f\"‚ö†Ô∏è Created zero-filled 3D array for processed signal {signal_name} due to size mismatch\", 'warning')\n",
    "                \n",
    "                # Verify final shape is 3D and matches processed grid dimensions\n",
    "                if processed_signal_reshaped.ndim != 3:\n",
    "                    log_message(f\"‚ùå ERROR: Processed signal {signal_name} is not 3D! Shape: {processed_signal_reshaped.shape}. Forcing 3D...\", 'error')\n",
    "                    if processed_signal_reshaped.size == np.prod(processed_dims):\n",
    "                        processed_signal_reshaped = processed_signal_reshaped.reshape(processed_dims).astype(np.float32)\n",
    "                    else:\n",
    "                        processed_signal_reshaped = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "                \n",
    "                if processed_signal_reshaped.shape != processed_dims:\n",
    "                    log_message(f\"‚ö†Ô∏è WARNING: Processed signal {signal_name} shape {processed_signal_reshaped.shape} doesn't match processed grid dims {processed_dims}. Resizing...\", 'warning')\n",
    "                    if processed_signal_reshaped.size == np.prod(processed_dims):\n",
    "                        processed_signal_reshaped = processed_signal_reshaped.reshape(processed_dims).astype(np.float32)\n",
    "                    else:\n",
    "                        processed_signal_reshaped = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "                \n",
    "                # Create a processed signal name (add _processed suffix)\n",
    "                processed_signal_name = f\"{signal_name}_processed\"\n",
    "                \n",
    "                # Store in _signal_arrays\n",
    "                if not hasattr(processed_grid, '_signal_arrays'):\n",
    "                    processed_grid._signal_arrays = {}\n",
    "                processed_grid._signal_arrays[processed_signal_name] = processed_signal_reshaped\n",
    "                \n",
    "                # Verify it's stored correctly\n",
    "                log_message(f\"‚úÖ Stored processed signal {processed_signal_name} in processed grid: shape={processed_signal_reshaped.shape}, dtype={processed_signal_reshaped.dtype}, min={np.nanmin(processed_signal_reshaped):.2f}, max={np.nanmax(processed_signal_reshaped):.2f}\", 'info')\n",
    "                \n",
    "                # Set available signals\n",
    "                if not hasattr(processed_grid, 'available_signals'):\n",
    "                    processed_grid.available_signals = set()\n",
    "                processed_grid.available_signals.add(processed_signal_name)\n",
    "                signals_saved += 1\n",
    "            \n",
    "            log_message(f\"Successfully mapped {signals_saved} processed signal(s) to processed grid. Available signals: {sorted(processed_grid.available_signals)}\", 'success')\n",
    "        else:\n",
    "            # Save single processed signal\n",
    "            if not isinstance(processed_signals, np.ndarray):\n",
    "                processed_signals = np.array(processed_signals, dtype=np.float32)\n",
    "            \n",
    "            log_message(f\"Mapping single processed signal: original shape={processed_signals.shape}, size={processed_signals.size}, processed_dims={processed_dims}, expected_size={np.prod(processed_dims)}\", 'info')\n",
    "            \n",
    "            # Ensure processed signal is 3D\n",
    "            if processed_signals.ndim != 3:\n",
    "                if processed_signals.size == np.prod(processed_dims):\n",
    "                    processed_signals = processed_signals.reshape(processed_dims).astype(np.float32)\n",
    "                    log_message(f\"‚úÖ Reshaped processed signal to 3D: {processed_signals.shape}\", 'info')\n",
    "                else:\n",
    "                    log_message(f\"‚ö†Ô∏è WARNING: Cannot reshape processed signal from {processed_signals.shape} to {processed_dims}\", 'warning')\n",
    "                    processed_signals = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "            \n",
    "            # Map signal to processed grid dimensions\n",
    "            if processed_signals.shape == processed_dims:\n",
    "                processed_signal_reshaped = processed_signals.astype(np.float32)\n",
    "                log_message(f\"‚úÖ Processed signal already matches processed grid dimensions: {processed_signal_reshaped.shape}\", 'info')\n",
    "            elif processed_signals.size == np.prod(processed_dims):\n",
    "                processed_signal_reshaped = processed_signals.reshape(processed_dims).astype(np.float32)\n",
    "                log_message(f\"‚úÖ Reshaped processed signal from {processed_signals.shape} to processed grid dimensions: {processed_signal_reshaped.shape}\", 'info')\n",
    "            else:\n",
    "                log_message(f\"‚ö†Ô∏è WARNING: Processed signal size {processed_signals.size} doesn't match processed grid size {np.prod(processed_dims)}. Shape: {processed_signals.shape}\", 'warning')\n",
    "                if processed_signals.ndim == 3:\n",
    "                    processed_signal_reshaped = processed_signals.astype(np.float32)\n",
    "                else:\n",
    "                    processed_signal_reshaped = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "\n",
    "            # Verify final shape is 3D and matches processed grid dimensions\n",
    "            if processed_signal_reshaped.ndim != 3:\n",
    "                log_message(f\"‚ùå ERROR: Processed signal is not 3D! Shape: {processed_signal_reshaped.shape}. Forcing 3D...\", 'error')\n",
    "                if processed_signal_reshaped.size == np.prod(processed_dims):\n",
    "                    processed_signal_reshaped = processed_signal_reshaped.reshape(processed_dims).astype(np.float32)\n",
    "                else:\n",
    "                    processed_signal_reshaped = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "            \n",
    "            if processed_signal_reshaped.shape != processed_dims:\n",
    "                log_message(f\"‚ö†Ô∏è WARNING: Processed signal shape {processed_signal_reshaped.shape} doesn't match processed grid dims {processed_dims}. Resizing...\", 'warning')\n",
    "                if processed_signal_reshaped.size == np.prod(processed_dims):\n",
    "                    processed_signal_reshaped = processed_signal_reshaped.reshape(processed_dims).astype(np.float32)\n",
    "                else:\n",
    "                    processed_signal_reshaped = np.full(processed_dims, 0.0, dtype=np.float32)\n",
    "            \n",
    "            # Create a processed signal name (add _processed suffix)\n",
    "            signal_name = signal_dropdown.value if signal_dropdown.value and signal_dropdown.value != 'all' else \"signal\"\n",
    "            processed_signal_name = f\"{signal_name}_processed\"\n",
    "            \n",
    "            # Store in _signal_arrays\n",
    "            if not hasattr(processed_grid, '_signal_arrays'):\n",
    "                processed_grid._signal_arrays = {}\n",
    "            processed_grid._signal_arrays[processed_signal_name] = processed_signal_reshaped\n",
    "            \n",
    "            # Verify it's stored correctly\n",
    "            log_message(f\"‚úÖ Stored processed signal {processed_signal_name} in processed grid: shape={processed_signal_reshaped.shape}, dtype={processed_signal_reshaped.dtype}, min={np.nanmin(processed_signal_reshaped):.2f}, max={np.nanmax(processed_signal_reshaped):.2f}\", 'info')\n",
    "            \n",
    "            # Set available signals\n",
    "            if not hasattr(processed_grid, 'available_signals'):\n",
    "                processed_grid.available_signals = set()\n",
    "            processed_grid.available_signals.add(processed_signal_name)\n",
    "            \n",
    "            log_message(f\"Successfully mapped single processed signal: {processed_signal_name}\", 'success')\n",
    "        \n",
    "        # Add get_signal_array method - ENSURE 3D STRUCTURE\n",
    "        # This must match VoxelGrid.get_signal_array behavior: always return 3D array, never None\n",
    "        def get_signal_array(signal_name, default=0.0):\n",
    "            # Use processed grid dimensions (matches source grid - corrected or original)\n",
    "            grid_dims = tuple(processed_grid.dims)\n",
    "            \n",
    "            # Check if signal exists in _signal_arrays\n",
    "            if hasattr(processed_grid, '_signal_arrays') and signal_name in processed_grid._signal_arrays:\n",
    "                signal_array = processed_grid._signal_arrays[signal_name]\n",
    "                \n",
    "                # Ensure it's a numpy array\n",
    "                if not isinstance(signal_array, np.ndarray):\n",
    "                    signal_array = np.array(signal_array, dtype=np.float32)\n",
    "                \n",
    "                # Verify 3D structure\n",
    "                if signal_array.ndim != 3:\n",
    "                    # Try to reshape if size matches\n",
    "                    if signal_array.size == np.prod(grid_dims):\n",
    "                        signal_array = signal_array.reshape(grid_dims).astype(np.float32)\n",
    "                    else:\n",
    "                        # Can't reshape - return default array\n",
    "                        return np.full(grid_dims, default, dtype=np.float32)\n",
    "                \n",
    "                # Verify shape matches grid dimensions\n",
    "                if signal_array.shape != grid_dims:\n",
    "                    if signal_array.size == np.prod(grid_dims):\n",
    "                        signal_array = signal_array.reshape(grid_dims).astype(np.float32)\n",
    "                    else:\n",
    "                        # Shape mismatch and size mismatch - return default\n",
    "                        return np.full(grid_dims, default, dtype=np.float32)\n",
    "                else:\n",
    "                    # Shape matches - ensure correct dtype\n",
    "                    signal_array = signal_array.astype(np.float32)\n",
    "                \n",
    "                # Return a copy to ensure data integrity\n",
    "                return np.array(signal_array, dtype=np.float32, copy=True)\n",
    "            \n",
    "            # Signal not found - return array with default values (consistent with VoxelGrid.get_signal_array)\n",
    "            return np.full(grid_dims, default, dtype=np.float32)\n",
    "        \n",
    "        processed_grid.get_signal_array = get_signal_array\n",
    "        \n",
    "        # Verify all signals are accessible before saving\n",
    "        log_message(\"Verifying signals are accessible before saving...\", 'info')\n",
    "        signals_verified = 0\n",
    "        signals_failed = []\n",
    "        \n",
    "        # Check if _signal_arrays exists and has signals\n",
    "        if not hasattr(processed_grid, '_signal_arrays') or not processed_grid._signal_arrays:\n",
    "            log_message(\"‚ùå ERROR: processed_grid._signal_arrays is missing or empty!\", 'error')\n",
    "            error_display.value = \"<span style='color: red;'>‚ùå No signals in processed grid. Cannot save.</span>\"\n",
    "            update_status(\"No signals to save\", 0)\n",
    "            return\n",
    "        \n",
    "        log_message(f\"Found {len(processed_grid._signal_arrays)} signal(s) in _signal_arrays: {list(processed_grid._signal_arrays.keys())}\", 'info')\n",
    "        \n",
    "        # Verify each signal\n",
    "        for signal_name in processed_grid.available_signals:\n",
    "            try:\n",
    "                # Check if signal is in _signal_arrays\n",
    "                if signal_name not in processed_grid._signal_arrays:\n",
    "                    signals_failed.append(f\"{signal_name} (not in _signal_arrays)\")\n",
    "                    log_message(f\"‚ùå Signal {signal_name}: Not found in _signal_arrays\", 'error')\n",
    "                    continue\n",
    "                \n",
    "                # Check signal in _signal_arrays\n",
    "                signal_in_storage = processed_grid._signal_arrays[signal_name]\n",
    "                log_message(f\"Signal {signal_name} in _signal_arrays: shape={signal_in_storage.shape if hasattr(signal_in_storage, 'shape') else 'unknown'}, type={type(signal_in_storage)}\", 'info')\n",
    "                \n",
    "                # Test get_signal_array\n",
    "                signal_array = processed_grid.get_signal_array(signal_name, default=0.0)\n",
    "                if signal_array is None:\n",
    "                    signals_failed.append(f\"{signal_name} (get_signal_array returned None)\")\n",
    "                    log_message(f\"‚ùå Signal {signal_name}: get_signal_array returned None\", 'error')\n",
    "                elif signal_array.ndim != 3:\n",
    "                    signals_failed.append(f\"{signal_name} (not 3D: {signal_array.shape})\")\n",
    "                    log_message(f\"‚ùå Signal {signal_name}: Not 3D! Shape: {signal_array.shape}\", 'error')\n",
    "                elif signal_array.size == 0:\n",
    "                    signals_failed.append(f\"{signal_name} (empty array)\")\n",
    "                    log_message(f\"‚ùå Signal {signal_name}: Empty array\", 'error')\n",
    "                else:\n",
    "                    signals_verified += 1\n",
    "                    log_message(f\"‚úÖ Signal {signal_name}: Verified - shape={signal_array.shape}, size={signal_array.size}, dtype={signal_array.dtype}, min={np.nanmin(signal_array):.2f}, max={np.nanmax(signal_array):.2f}\", 'success')\n",
    "            except Exception as e:\n",
    "                signals_failed.append(f\"{signal_name} (error: {str(e)})\")\n",
    "                log_message(f\"‚ùå Signal {signal_name}: Error accessing - {e}\", 'error')\n",
    "                import traceback\n",
    "                log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "        \n",
    "        if signals_failed:\n",
    "            error_msg = f\"‚ùå {len(signals_failed)} signal(s) failed verification: {', '.join(signals_failed)}\"\n",
    "            log_message(error_msg, 'error')\n",
    "            error_display.value = f\"<span style='color: red;'>{error_msg}. Cannot save grid.</span>\"\n",
    "            update_status(\"Signal verification failed\", 0)\n",
    "            return\n",
    "        \n",
    "        log_message(f\"‚úÖ All {signals_verified} signal(s) verified successfully. Proceeding to save...\", 'success')\n",
    "        \n",
    "        # Store comprehensive processing metadata - COMPREHENSIVE (include source, grid_type, resolution)\n",
    "        if process_all:\n",
    "            processed_signal_list = list(processed_all_signals.keys())\n",
    "            config_metadata = {\n",
    "                # CRITICAL: Source, grid_type, resolution (required for all operations)\n",
    "                'source': source,\n",
    "                'grid_type': grid_type,\n",
    "                'resolution': resolution,\n",
    "                \n",
    "                # Processing information\n",
    "                'processing_applied': True,\n",
    "                'processing_type': processing_type,\n",
    "                'original_grid_id': current_grid_id,\n",
    "                'original_grid_name': loaded_grid_data.get('grid_name', ''),\n",
    "                'processed_signals': processed_signal_list,\n",
    "                'num_signals_processed': len(processed_signal_list),\n",
    "                'processing_timestamp': datetime.now().isoformat(),\n",
    "                'processing_methods': processing_methods\n",
    "            }\n",
    "        else:\n",
    "            signal_name = signal_dropdown.value if signal_dropdown.value and signal_dropdown.value != 'all' else \"signal\"\n",
    "            config_metadata = {\n",
    "                # CRITICAL: Source, grid_type, resolution (required for all operations)\n",
    "                'source': source,\n",
    "                'grid_type': grid_type,\n",
    "                'resolution': resolution,\n",
    "                \n",
    "                # Processing information\n",
    "                'processing_applied': True,\n",
    "                'processing_type': processing_type,\n",
    "                'original_grid_id': current_grid_id,\n",
    "                'original_grid_name': loaded_grid_data.get('grid_name', ''),\n",
    "                'processed_signal': signal_name,\n",
    "                'processing_timestamp': datetime.now().isoformat(),\n",
    "                'processing_methods': processing_methods\n",
    "            }\n",
    "        \n",
    "        # Outlier detection parameters\n",
    "        if remove_outliers.value:\n",
    "            config_metadata['outlier_detection'] = {\n",
    "                'enabled': True,\n",
    "                'method': outlier_method.value,\n",
    "                'threshold': outlier_threshold.value\n",
    "            }\n",
    "            config_metadata['processing_methods'].append(f\"outlier_removal_{outlier_method.value}\")\n",
    "        else:\n",
    "            config_metadata['outlier_detection'] = {'enabled': False}\n",
    "        \n",
    "        # Signal smoothing parameters\n",
    "        if smooth_method.value:\n",
    "            config_metadata['smoothing'] = {\n",
    "                'method': smooth_method.value,\n",
    "                'window_length': window_length.value,\n",
    "                'poly_order': poly_order.value if smooth_method.value == 'savgol' else None\n",
    "            }\n",
    "            config_metadata['processing_methods'].append(f\"smoothing_{smooth_method.value}\")\n",
    "        \n",
    "        # Noise reduction parameters\n",
    "        if noise_method.value:\n",
    "            config_metadata['noise_reduction'] = {\n",
    "                'method': noise_method.value,\n",
    "                'kernel_size': kernel_size.value\n",
    "            }\n",
    "            config_metadata['processing_methods'].append(f\"noise_reduction_{noise_method.value}\")\n",
    "        \n",
    "        # Derived signal generation (if applied)\n",
    "        if derived_signal_type.value != 'none':\n",
    "            config_metadata['derived_signal'] = {\n",
    "                'type': derived_signal_type.value\n",
    "            }\n",
    "            if derived_signal_type.value == 'thermal':\n",
    "                config_metadata['derived_signal']['thermal_coefficient'] = thermal_coeff.value\n",
    "            elif derived_signal_type.value == 'density':\n",
    "                config_metadata['derived_signal']['density_coefficient'] = density_coeff.value\n",
    "        \n",
    "        # Processing metrics (if available)\n",
    "        if processing_results and 'processing' in processing_results:\n",
    "            config_metadata['processing_metrics'] = processing_results['processing']\n",
    "        \n",
    "        # Signal statistics\n",
    "        if processed_signals is not None:\n",
    "            config_metadata['signal_statistics'] = {\n",
    "                'mean': float(np.mean(processed_signals)),\n",
    "                'std': float(np.std(processed_signals)),\n",
    "                'min': float(np.min(processed_signals)),\n",
    "                'max': float(np.max(processed_signals)),\n",
    "                'percentile_25': float(np.percentile(processed_signals, 25)),\n",
    "                'percentile_75': float(np.percentile(processed_signals, 75))\n",
    "            }\n",
    "        \n",
    "        # Save grid\n",
    "        log_message(\"Saving processed grid to MongoDB...\", 'info')\n",
    "        update_status(\"Saving processed grid to MongoDB...\", 80)\n",
    "        saved_grid_id = voxel_storage.save_voxel_grid(\n",
    "            model_id=current_model_id,\n",
    "            grid_name=grid_name,\n",
    "            voxel_grid=processed_grid,\n",
    "            description=f\"Processed {source.upper()} grid ({processing_type}) - {model_name}\",\n",
    "            model_name=model_name,\n",
    "            configuration_metadata=config_metadata,\n",
    "            tags=['processed', processing_type if processing_type else 'unknown', source, grid_type]\n",
    "        )\n",
    "        \n",
    "        log_message(f\"Processed grid saved with ID: {saved_grid_id[:8]}...\", 'success')\n",
    "        log_message(f\"Processed grid contains {len(processed_grid.available_signals)} signal(s): {sorted(processed_grid.available_signals)}\", 'info')\n",
    "        \n",
    "        # Verify signals were actually saved to GridFS\n",
    "        log_message(\"Verifying signals were saved to GridFS...\", 'info')\n",
    "        try:\n",
    "            from bson import ObjectId\n",
    "            collection = mongo_client.get_collection('voxel_grids')\n",
    "            saved_grid_doc = collection.find_one({'_id': ObjectId(saved_grid_id)})\n",
    "            \n",
    "            if saved_grid_doc:\n",
    "                signal_references = saved_grid_doc.get('signal_references', {})\n",
    "                available_signals_in_db = saved_grid_doc.get('available_signals', [])\n",
    "                \n",
    "                log_message(f\"Grid document has {len(signal_references)} signal reference(s) in GridFS\", 'info')\n",
    "                log_message(f\"Grid document lists {len(available_signals_in_db)} available signal(s): {available_signals_in_db}\", 'info')\n",
    "                \n",
    "                if len(signal_references) == 0:\n",
    "                    log_message(f\"‚ùå ERROR: No signals were saved to GridFS! signal_references is empty.\", 'error')\n",
    "                    log_message(f\"Expected {len(processed_grid.available_signals)} signal(s): {sorted(processed_grid.available_signals)}\", 'error')\n",
    "                    error_display.value = f\"<span style='color: red;'>‚ùå WARNING: Grid saved but NO signals were saved to GridFS! This grid cannot be loaded properly.</span>\"\n",
    "                elif len(signal_references) < len(processed_grid.available_signals):\n",
    "                    missing = set(processed_grid.available_signals) - set(signal_references.keys())\n",
    "                    log_message(f\"‚ö†Ô∏è WARNING: Only {len(signal_references)}/{len(processed_grid.available_signals)} signals saved to GridFS. Missing: {sorted(missing)}\", 'warning')\n",
    "                    error_display.value = f\"<span style='color: orange;'>‚ö†Ô∏è WARNING: Only {len(signal_references)}/{len(processed_grid.available_signals)} signals saved to GridFS.</span>\"\n",
    "                else:\n",
    "                    log_message(f\"‚úÖ All {len(signal_references)} signal(s) successfully saved to GridFS: {sorted(signal_references.keys())}\", 'success')\n",
    "            else:\n",
    "                log_message(f\"‚ö†Ô∏è WARNING: Could not verify saved grid - document not found\", 'warning')\n",
    "        except Exception as e:\n",
    "            log_message(f\"‚ö†Ô∏è Error verifying saved grid: {e}\", 'warning')\n",
    "            import traceback\n",
    "            log_message(f\"Traceback: {traceback.format_exc()}\", 'warning')\n",
    "        \n",
    "        # Calculate total execution time\n",
    "        if operation_start_time:\n",
    "            total_time = time.time() - operation_start_time\n",
    "            log_message(f\"Processed grid saved successfully in {total_time:.2f}s (ID: {saved_grid_id[:8]}...)\", 'success')\n",
    "        else:\n",
    "            log_message(f\"Processed grid saved successfully (ID: {saved_grid_id[:8]}...)\", 'success')\n",
    "        \n",
    "        update_status(\"Processed grid saved successfully\", 100)\n",
    "        error_display.value = f\"<span style='color: green;'>‚úÖ Saved processed grid: {grid_name} (ID: {saved_grid_id[:8]}...) with {len(processed_grid.available_signals)} signal(s)</span>\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error saving processed grid: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "        error_display.value = f\"<span style='color: red;'>‚ùå Error saving processed grid: {str(e)}</span>\"\n",
    "        update_status(\"Error saving grid\", 0)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "def reset_processing(button):\n",
    "    \"\"\"Reset all processing state.\"\"\"\n",
    "    global original_data, corrected_data, processed_signals, processing_results, signal_arrays\n",
    "    \n",
    "    original_data = None\n",
    "    corrected_data = None\n",
    "    processed_signals = None\n",
    "    processing_results = {}\n",
    "    signal_arrays = {}\n",
    "    \n",
    "    # Reset displays\n",
    "    signal_dropdown.value = None\n",
    "    signal_dropdown.layout.display = 'none'\n",
    "    save_button.layout.display = 'none'\n",
    "    results_display.value = \"<p>No data loaded</p>\"\n",
    "    metrics_display.value = \"<p>No data loaded</p>\"\n",
    "    with viz_output:\n",
    "        clear_output(wait=False)\n",
    "    status_display.value = \"<b>Status:</b> Ready to process data\"\n",
    "    error_display.value = \"\"\n",
    "    progress_bar.value = 0\n",
    "\n",
    "def update_results_display():\n",
    "    \"\"\"Update results and metrics displays.\"\"\"\n",
    "    global processing_results, original_data, processed_signals\n",
    "    \n",
    "    if not processing_results:\n",
    "        return\n",
    "    \n",
    "    # Correction metrics\n",
    "    if 'correction' in processing_results:\n",
    "        corr = processing_results['correction']\n",
    "        correction_html = f\"\"\"\n",
    "        <p><b>Mean Error:</b> {corr['mean_error']:.3f} mm</p>\n",
    "        <p><b>Max Error:</b> {corr['max_error']:.3f} mm</p>\n",
    "        <p><b>RMS Error:</b> {corr['rms_error']:.3f} mm</p>\n",
    "        <p><b>Score:</b> {corr['score']:.2f}</p>\n",
    "        \"\"\"\n",
    "        correction_metrics_display.value = correction_html\n",
    "    \n",
    "    # Processing metrics\n",
    "    if 'processing' in processing_results:\n",
    "        proc = processing_results['processing']\n",
    "        processing_html = f\"\"\"\n",
    "        <p><b>SNR Improvement:</b> {proc['snr_improvement']:.1f} dB</p>\n",
    "        <p><b>Noise Reduction:</b> {proc['noise_reduction']:.2f}</p>\n",
    "        <p><b>Quality Score:</b> {proc['quality_score']:.2f}</p>\n",
    "        \"\"\"\n",
    "        processing_metrics_display.value = processing_html\n",
    "    \n",
    "    # Signal statistics\n",
    "    if processed_signals is not None:\n",
    "        stats_html = f\"\"\"\n",
    "        <p><b>Mean:</b> {np.mean(processed_signals):.2f}</p>\n",
    "        <p><b>Std:</b> {np.std(processed_signals):.2f}</p>\n",
    "        <p><b>Min:</b> {np.min(processed_signals):.2f}</p>\n",
    "        <p><b>Max:</b> {np.max(processed_signals):.2f}</p>\n",
    "        <p><b>Percentiles:</b> 25%={np.percentile(processed_signals, 25):.2f}, 75%={np.percentile(processed_signals, 75):.2f}</p>\n",
    "        \"\"\"\n",
    "        signal_stats_display.value = stats_html\n",
    "    \n",
    "    # Validation\n",
    "    validation_html = \"<p style='color: green;'>‚úÖ <b>Pass</b></p>\"\n",
    "    validation_display.value = validation_html\n",
    "\n",
    "# def update_visualization():\n",
    "#     \"\"\"Update visualization display.\"\"\"\n",
    "#     global original_data, corrected_data, processed_signals\n",
    "    \n",
    "#     with viz_output:\n",
    "#         clear_output(wait=True)\n",
    "        \n",
    "#         if original_data is None:\n",
    "#             display(HTML(\"<p>Execute processing to see visualization</p>\"))\n",
    "#             return\n",
    "        \n",
    "#         mode = viz_mode.value\n",
    "        \n",
    "#         if mode == 'before_after':\n",
    "#             fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "#             # Before\n",
    "#             ax1 = axes[0]\n",
    "#             signal_orig = original_data['signal'].reshape(original_data['grid_shape'])\n",
    "#             slice_idx = signal_orig.shape[2] // 2\n",
    "#             im1 = ax1.imshow(signal_orig[:, :, slice_idx], cmap='viridis', origin='lower')\n",
    "#             ax1.set_title('Before Processing')\n",
    "#             ax1.set_xlabel('X')\n",
    "#             ax1.set_ylabel('Y')\n",
    "#             plt.colorbar(im1, ax=ax1)\n",
    "            \n",
    "#             # After\n",
    "#             ax2 = axes[1]\n",
    "#             if processed_signals is not None:\n",
    "#                 signal_proc = processed_signals.reshape(original_data['grid_shape'])\n",
    "#                 im2 = ax2.imshow(signal_proc[:, :, slice_idx], cmap='viridis', origin='lower')\n",
    "#             else:\n",
    "#                 im2 = ax2.imshow(signal_orig[:, :, slice_idx], cmap='viridis', origin='lower')\n",
    "#             ax2.set_title('After Processing')\n",
    "#             ax2.set_xlabel('X')\n",
    "#             ax2.set_ylabel('Y')\n",
    "#             plt.colorbar(im2, ax=ax2)\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "        \n",
    "#         elif mode == 'difference':\n",
    "#             fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            \n",
    "#             signal_orig = original_data['signal'].reshape(original_data['grid_shape'])\n",
    "#             if processed_signals is not None:\n",
    "#                 signal_proc = processed_signals.reshape(original_data['grid_shape'])\n",
    "#                 diff = signal_proc - signal_orig\n",
    "#             else:\n",
    "#                 diff = np.zeros_like(signal_orig)\n",
    "            \n",
    "#             slice_idx = diff.shape[2] // 2\n",
    "#             im = ax.imshow(diff[:, :, slice_idx], cmap='RdBu', origin='lower')\n",
    "#             ax.set_title('Difference (After - Before)')\n",
    "#             ax.set_xlabel('X')\n",
    "#             ax.set_ylabel('Y')\n",
    "#             plt.colorbar(im, ax=ax)\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "        \n",
    "#         else:  # quality\n",
    "#             fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "#             # SNR plot\n",
    "#             ax1 = axes[0]\n",
    "#             if processed_signals is not None:\n",
    "#                 signal_orig = original_data['signal']\n",
    "#                 signal_proc = processed_signals\n",
    "#                 snr_orig = np.mean(signal_orig) / np.std(signal_orig)\n",
    "#                 snr_proc = np.mean(signal_proc) / np.std(signal_proc)\n",
    "#                 ax1.bar(['Original', 'Processed'], [snr_orig, snr_proc])\n",
    "#                 ax1.set_ylabel('SNR')\n",
    "#                 ax1.set_title('Signal-to-Noise Ratio')\n",
    "            \n",
    "#             # Distribution\n",
    "#             ax2 = axes[1]\n",
    "#             if processed_signals is not None:\n",
    "#                 ax2.hist(original_data['signal'], bins=50, alpha=0.5, label='Original', density=True)\n",
    "#                 ax2.hist(processed_signals, bins=50, alpha=0.5, label='Processed', density=True)\n",
    "#                 ax2.set_xlabel('Signal Value')\n",
    "#                 ax2.set_ylabel('Density')\n",
    "#                 ax2.set_title('Signal Distribution')\n",
    "#                 ax2.legend()\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "\n",
    "def update_visualization():\n",
    "    \"\"\"Update visualization display.\"\"\"\n",
    "    global original_data, corrected_data, processed_signals\n",
    "    \n",
    "    with viz_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if original_data is None:\n",
    "            display(HTML(\"<p>Execute processing to see visualization</p>\"))\n",
    "            return\n",
    "        \n",
    "        mode = viz_mode.value\n",
    "        grid_shape = original_data.get('grid_shape', None)\n",
    "        \n",
    "        # Ensure grid_shape is a tuple/list\n",
    "        if grid_shape is None:\n",
    "            display(HTML(\"<p style='color: red;'>Error: Grid shape not available</p>\"))\n",
    "            return\n",
    "        \n",
    "        # Convert to tuple if it's a list or array\n",
    "        if isinstance(grid_shape, (list, np.ndarray)):\n",
    "            grid_shape = tuple(grid_shape)\n",
    "        elif not isinstance(grid_shape, tuple):\n",
    "            grid_shape = tuple(grid_shape) if hasattr(grid_shape, '__iter__') else (grid_shape,)\n",
    "        \n",
    "        # Handle different dimensionalities\n",
    "        if len(grid_shape) == 1:\n",
    "            # 1D signal - show as line plot\n",
    "            display(HTML(\"<p style='color: orange;'>‚ö†Ô∏è 1D signal detected. Visualization limited to quality metrics.</p>\"))\n",
    "            mode = 'quality'  # Force quality mode for 1D\n",
    "        elif len(grid_shape) == 2:\n",
    "            # 2D signal - show directly\n",
    "            display(HTML(\"<p style='color: orange;'>‚ö†Ô∏è 2D signal detected. Showing 2D visualization.</p>\"))\n",
    "        elif len(grid_shape) >= 3:\n",
    "            # 3D signal - show middle slice\n",
    "            pass  # Normal 3D handling\n",
    "        else:\n",
    "            display(HTML(\"<p style='color: red;'>Error: Invalid grid shape</p>\"))\n",
    "            return\n",
    "        \n",
    "        if mode == 'before_after':\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "            # Before\n",
    "            ax1 = axes[0]\n",
    "            try:\n",
    "                signal_orig = original_data['signal'].reshape(grid_shape)\n",
    "                \n",
    "                if len(grid_shape) == 3:\n",
    "                    slice_idx = signal_orig.shape[2] // 2\n",
    "                    im1 = ax1.imshow(signal_orig[:, :, slice_idx], cmap='viridis', origin='lower')\n",
    "                elif len(grid_shape) == 2:\n",
    "                    im1 = ax1.imshow(signal_orig, cmap='viridis', origin='lower')\n",
    "                else:\n",
    "                    # 1D - can't show in imshow, show as line plot\n",
    "                    ax1.plot(signal_orig)\n",
    "                    ax1.set_title('Before Processing (1D Signal)')\n",
    "                    ax1.set_xlabel('Index')\n",
    "                    ax1.set_ylabel('Signal Value')\n",
    "                    im1 = None\n",
    "                \n",
    "                if im1 is not None:\n",
    "                    ax1.set_title('Before Processing')\n",
    "                    ax1.set_xlabel('X')\n",
    "                    ax1.set_ylabel('Y')\n",
    "                    plt.colorbar(im1, ax=ax1)\n",
    "            except Exception as e:\n",
    "                ax1.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center', transform=ax1.transAxes)\n",
    "                ax1.set_title('Before Processing (Error)')\n",
    "            \n",
    "            # After\n",
    "            ax2 = axes[1]\n",
    "            try:\n",
    "                if processed_signals is not None:\n",
    "                    signal_proc = processed_signals.reshape(grid_shape)\n",
    "                    if len(grid_shape) == 3:\n",
    "                        slice_idx = signal_proc.shape[2] // 2\n",
    "                        im2 = ax2.imshow(signal_proc[:, :, slice_idx], cmap='viridis', origin='lower')\n",
    "                    elif len(grid_shape) == 2:\n",
    "                        im2 = ax2.imshow(signal_proc, cmap='viridis', origin='lower')\n",
    "                    else:\n",
    "                        ax2.plot(signal_proc)\n",
    "                        ax2.set_title('After Processing (1D Signal)')\n",
    "                        ax2.set_xlabel('Index')\n",
    "                        ax2.set_ylabel('Signal Value')\n",
    "                        im2 = None\n",
    "                else:\n",
    "                    # Show original if no processed signal\n",
    "                    signal_orig = original_data['signal'].reshape(grid_shape)\n",
    "                    if len(grid_shape) == 3:\n",
    "                        slice_idx = signal_orig.shape[2] // 2\n",
    "                        im2 = ax2.imshow(signal_orig[:, :, slice_idx], cmap='viridis', origin='lower')\n",
    "                    elif len(grid_shape) == 2:\n",
    "                        im2 = ax2.imshow(signal_orig, cmap='viridis', origin='lower')\n",
    "                    else:\n",
    "                        ax2.plot(signal_orig)\n",
    "                        im2 = None\n",
    "                \n",
    "                if im2 is not None:\n",
    "                    ax2.set_title('After Processing')\n",
    "                    ax2.set_xlabel('X')\n",
    "                    ax2.set_ylabel('Y')\n",
    "                    plt.colorbar(im2, ax=ax2)\n",
    "            except Exception as e:\n",
    "                ax2.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center', transform=ax2.transAxes)\n",
    "                ax2.set_title('After Processing (Error)')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        elif mode == 'difference':\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            \n",
    "            try:\n",
    "                signal_orig = original_data['signal'].reshape(grid_shape)\n",
    "                if processed_signals is not None:\n",
    "                    signal_proc = processed_signals.reshape(grid_shape)\n",
    "                    diff = signal_proc - signal_orig\n",
    "                else:\n",
    "                    diff = np.zeros_like(signal_orig)\n",
    "                \n",
    "                if len(grid_shape) == 3:\n",
    "                    slice_idx = diff.shape[2] // 2\n",
    "                    im = ax.imshow(diff[:, :, slice_idx], cmap='RdBu', origin='lower')\n",
    "                elif len(grid_shape) == 2:\n",
    "                    im = ax.imshow(diff, cmap='RdBu', origin='lower')\n",
    "                else:\n",
    "                    ax.plot(diff)\n",
    "                    ax.set_title('Difference (After - Before) - 1D Signal')\n",
    "                    ax.set_xlabel('Index')\n",
    "                    ax.set_ylabel('Difference')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    return\n",
    "                \n",
    "                ax.set_title('Difference (After - Before)')\n",
    "                ax.set_xlabel('X')\n",
    "                ax.set_ylabel('Y')\n",
    "                plt.colorbar(im, ax=ax)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title('Difference (Error)')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        \n",
    "        else:  # quality\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "            # SNR plot\n",
    "            ax1 = axes[0]\n",
    "            if processed_signals is not None:\n",
    "                signal_orig = original_data['signal']\n",
    "                signal_proc = processed_signals\n",
    "                snr_orig = np.mean(signal_orig) / (np.std(signal_orig) + 1e-10)  # Avoid division by zero\n",
    "                snr_proc = np.mean(signal_proc) / (np.std(signal_proc) + 1e-10)\n",
    "                ax1.bar(['Original', 'Processed'], [snr_orig, snr_proc])\n",
    "                ax1.set_ylabel('SNR')\n",
    "                ax1.set_title('Signal-to-Noise Ratio')\n",
    "            \n",
    "            # Distribution\n",
    "            ax2 = axes[1]\n",
    "            if processed_signals is not None:\n",
    "                ax2.hist(original_data['signal'], bins=50, alpha=0.5, label='Original', density=True)\n",
    "                ax2.hist(processed_signals, bins=50, alpha=0.5, label='Processed', density=True)\n",
    "                ax2.set_xlabel('Signal Value')\n",
    "                ax2.set_ylabel('Density')\n",
    "                ax2.set_title('Signal Distribution')\n",
    "                ax2.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Connect events\n",
    "execute_button.on_click(execute_processing)\n",
    "reset_button.on_click(reset_processing)\n",
    "save_button.on_click(handle_save)\n",
    "viz_mode.observe(lambda x: update_visualization(), names='value')\n",
    "signal_dropdown.observe(lambda x: execute_processing(None) if original_data else None, names='value')\n",
    "\n",
    "# ============================================\n",
    "# Main Layout\n",
    "# ============================================\n",
    "\n",
    "main_layout = VBox([\n",
    "    top_panel,\n",
    "    HBox([left_panel, center_panel, right_panel]),\n",
    "    bottom_panel\n",
    "])\n",
    "\n",
    "# Display the interface\n",
    "display(main_layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned how to correct geometric distortions and process signals.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Geometric Correction**: Correct scaling, rotation, and warping distortions\n",
    "2. **Calibration**: Use calibration data for accurate corrections\n",
    "3. **Signal Processing**: Remove outliers, smooth signals, and reduce noise\n",
    "4. **Derived Signals**: Generate thermal, density, and stress signals\n",
    "5. **Quality Assessment**: Evaluate processing quality using metrics\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Proceed to:\n",
    "- **06_Multi_Source_Data_Fusion.ipynb** - Learn data fusion strategies\n",
    "- **07_Quality_Assessment.ipynb** - Learn quality assessment methods\n",
    "\n",
    "### Related Resources\n",
    "\n",
    "- Correction Module Documentation: `../docs/AM_QADF/05-modules/correction.md`\n",
    "- Processing Module Documentation: `../docs/AM_QADF/05-modules/processing.md`\n",
    "- API Reference: `../docs/AM_QADF/06-api-reference/`\n",
    "- Examples: `../examples/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
