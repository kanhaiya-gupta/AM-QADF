{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Optimization and Prediction\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook teaches you how to implement process optimization and prediction for additive manufacturing processes. You'll learn to build predictive quality models, perform early defect detection, optimize process parameters (single and multi-objective), validate optimization results, and track model performance using a unified interactive interface with real-time progress tracking and detailed logging.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Build predictive quality models (Random Forest, Gradient Boosting, MLP)\n",
    "- ‚úÖ Perform early defect detection before build completion\n",
    "- ‚úÖ Forecast quality metrics using time-series models (ARIMA, Exponential Smoothing, Moving Average, Prophet)\n",
    "- ‚úÖ Optimize process parameters (single-objective and multi-objective)\n",
    "- ‚úÖ Handle constraints in optimization (penalty, barrier, augmented Lagrangian)\n",
    "- ‚úÖ Validate optimization results (cross-validation, experimental, simulation)\n",
    "- ‚úÖ Track model performance over time with drift detection\n",
    "- ‚úÖ Register and version models in a model registry\n",
    "- ‚úÖ Execute complete end-to-end prediction and optimization workflows\n",
    "- ‚úÖ Monitor prediction and optimization progress with real-time status and logs\n",
    "\n",
    "## Estimated Duration\n",
    "\n",
    "90-120 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Process Optimization and Prediction enables data-driven optimization of manufacturing processes with predictive models. The AM-QADF framework provides comprehensive capabilities:\n",
    "\n",
    "- üîÆ **Predictive Quality Models**: Random Forest, Gradient Boosting, MLP for quality prediction\n",
    "- ‚ö†Ô∏è **Early Defect Detection**: Predict defects early in build process before completion\n",
    "- üìà **Time-Series Forecasting**: ARIMA, Exponential Smoothing, Moving Average, Prophet for quality and parameter forecasting\n",
    "- üéØ **Single-Objective Optimization**: Differential Evolution, L-BFGS-B for parameter optimization\n",
    "- üìä **Multi-Objective Optimization**: NSGA-II, Weighted Sum for Pareto front generation\n",
    "- üöß **Constrained Optimization**: Penalty, Barrier, Augmented Lagrangian constraint handling\n",
    "- ‚ö° **Real-Time Optimization**: Streaming optimization with adaptive parameter updates\n",
    "- ‚úÖ **Optimization Validation**: Cross-validation, experimental, and simulation validation\n",
    "- üìù **Model Registry**: Version control and storage for trained models\n",
    "- üìà **Performance Tracking**: Monitor model performance, detect degradation and drift\n",
    "- üîç **Model Monitoring**: Continuous monitoring with retraining triggers\n",
    "\n",
    "The notebook features a unified interactive interface with:\n",
    "- **Progress Tracking**: Visual progress bars showing completion percentage\n",
    "- **Status Monitoring**: Real-time status updates with elapsed time\n",
    "- **Detailed Logging**: Timestamped logs with success/warning/error indicators for all operations\n",
    "- **Error Handling**: Comprehensive error messages and tracebacks in the logs\n",
    "\n",
    "Use the interactive widgets below to build models, optimize parameters, and track performance - no coding required! Monitor your prediction and optimization progress in real-time using the status bar and logs section at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Process Optimization and Prediction Interface\n",
    "\n",
    "Use the widgets below to build predictive models, perform early defect detection, forecast quality metrics, optimize process parameters, validate results, and track model performance. All prediction and optimization tasks are organized systematically in one unified interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded from development.env\n",
      "‚úÖ Prediction classes available\n",
      "‚ö†Ô∏è Model tracking classes not available: cannot import name 'ModelMonitoringConfig' from 'am_qadf.analytics.process_analysis.model_tracking.model_monitor' (/mnt/c/Users/kanha/Independent_Research/AM-QADF/src/am_qadf/analytics/process_analysis/model_tracking/model_monitor.py) - using demo mode\n",
      "‚úÖ Optimization classes available\n",
      "‚úÖ Quality analysis classes available\n",
      "‚úÖ Connected to MongoDB: am_qadf_data\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory and src directory to path for imports\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent\n",
    "src_dir = project_root / 'src'\n",
    "\n",
    "# Add project root to path (for src.infrastructure imports)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Add src directory to path (for am_qadf imports)\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Core imports\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    VBox, HBox, Accordion, Tab, Dropdown, RadioButtons, \n",
    "    Checkbox, Button, Output, Text, IntSlider, FloatSlider,\n",
    "    Layout, Box, Label, FloatText, IntText, SelectMultiple,\n",
    "    HTML as WidgetHTML, Textarea, FileUpload, Valid, Play, jslink\n",
    ")\n",
    "from IPython.display import display, Markdown, HTML, clear_output, Javascript\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "import asyncio\n",
    "from collections import deque\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load environment variables from development.env\n",
    "import os\n",
    "env_file = project_root / 'development.env'\n",
    "if env_file.exists():\n",
    "    with open(env_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                value = value.strip('\"\\'')\n",
    "                os.environ[key] = value\n",
    "    print(\"‚úÖ Environment variables loaded from development.env\")\n",
    "\n",
    "# Try to import prediction classes\n",
    "PREDICTION_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.analytics.process_analysis.prediction.early_defect_predictor import (\n",
    "        EarlyDefectPredictor, PredictionConfig, EarlyDefectPredictionResult\n",
    "    )\n",
    "    from am_qadf.analytics.process_analysis.prediction.time_series_predictor import (\n",
    "        TimeSeriesPredictor, TimeSeriesPredictionResult\n",
    "    )\n",
    "    from am_qadf.analytics.process_analysis.prediction.prediction_validator import (\n",
    "        PredictionValidator, OptimizationValidationResult\n",
    "    )\n",
    "    PREDICTION_AVAILABLE = True\n",
    "    print(\"‚úÖ Prediction classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Prediction classes not available: {e} - using demo mode\")\n",
    "\n",
    "# Try to import model tracking classes\n",
    "MODEL_TRACKING_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.analytics.process_analysis.model_tracking.model_registry import (\n",
    "        ModelRegistry, ModelVersion\n",
    "    )\n",
    "    from am_qadf.analytics.process_analysis.model_tracking.performance_tracker import (\n",
    "        ModelPerformanceTracker, ModelPerformanceMetrics\n",
    "    )\n",
    "    from am_qadf.analytics.process_analysis.model_tracking.model_monitor import (\n",
    "        ModelMonitor, ModelMonitoringConfig\n",
    "    )\n",
    "    MODEL_TRACKING_AVAILABLE = True\n",
    "    print(\"‚úÖ Model tracking classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Model tracking classes not available: {e} - using demo mode\")\n",
    "\n",
    "# Try to import optimization classes\n",
    "OPTIMIZATION_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.analytics.process_analysis.optimization import (\n",
    "        ProcessOptimizer, OptimizationConfig, OptimizationResult,\n",
    "        ConstraintHandler, ParetoVisualizer\n",
    "    )\n",
    "    OPTIMIZATION_AVAILABLE = True\n",
    "    print(\"‚úÖ Optimization classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Optimization classes not available: {e} - using demo mode\")\n",
    "\n",
    "# Try to import quality analysis classes\n",
    "QUALITY_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.analytics.process_analysis.quality_analysis import (\n",
    "        QualityPredictor, QualityAnalysisConfig, QualityAnalysisResult\n",
    "    )\n",
    "    QUALITY_AVAILABLE = True\n",
    "    print(\"‚úÖ Quality analysis classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Quality analysis classes not available: {e} - using demo mode\")\n",
    "\n",
    "# MongoDB connection setup (optional, for persistence)\n",
    "INFRASTRUCTURE_AVAILABLE = False\n",
    "mongo_client = None\n",
    "\n",
    "try:\n",
    "    from src.infrastructure.config import MongoDBConfig\n",
    "    from src.infrastructure.database import MongoDBClient\n",
    "    \n",
    "    config = MongoDBConfig.from_env()\n",
    "    if not config.username:\n",
    "        config.username = os.getenv('MONGO_ROOT_USERNAME', 'admin')\n",
    "    if not config.password:\n",
    "        config.password = os.getenv('MONGO_ROOT_PASSWORD', 'password')\n",
    "    \n",
    "    mongo_client = MongoDBClient(config=config)\n",
    "    try:\n",
    "        if mongo_client.is_connected():\n",
    "            INFRASTRUCTURE_AVAILABLE = True\n",
    "            print(f\"‚úÖ Connected to MongoDB: {config.database}\")\n",
    "        else:\n",
    "            mongo_client = None\n",
    "            print(\"‚ö†Ô∏è MongoDB connection failed - using demo mode\")\n",
    "    except Exception as conn_error:\n",
    "        mongo_client = None\n",
    "        print(f\"‚ö†Ô∏è MongoDB connection check failed: {conn_error} - using demo mode\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è MongoDB infrastructure not available: {e} - using demo mode\")\n",
    "    mongo_client = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MongoDB not available: {e} - using demo mode\")\n",
    "    mongo_client = None\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Model registry not available - using demo mode\n",
      "‚úÖ Quality predictor initialized\n",
      "‚úÖ Prediction components initialized\n",
      "‚úÖ Optimizer initialized\n",
      "‚úÖ Helper functions initialized\n"
     ]
    }
   ],
   "source": [
    "# Create Interactive Process Optimization and Prediction Interface\n",
    "\n",
    "# Global state\n",
    "prediction_results = {}\n",
    "optimization_results = {}\n",
    "model_registry = None\n",
    "performance_trackers = {}\n",
    "current_operation = None\n",
    "operation_start_time = None\n",
    "is_operation_active = False\n",
    "\n",
    "# Initialize model registry if available\n",
    "if MODEL_TRACKING_AVAILABLE:\n",
    "    temp_registry_dir = tempfile.mkdtemp()\n",
    "    model_registry = ModelRegistry(storage_path=temp_registry_dir)\n",
    "    print(\"‚úÖ Model registry initialized\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model registry not available - using demo mode\")\n",
    "\n",
    "# Initialize clients\n",
    "quality_predictor = None\n",
    "early_defect_predictor = None\n",
    "time_series_predictor = None\n",
    "prediction_validator = None\n",
    "optimizer = None\n",
    "\n",
    "if QUALITY_AVAILABLE:\n",
    "    quality_config = QualityAnalysisConfig(random_seed=42)\n",
    "    quality_predictor = QualityPredictor(quality_config)\n",
    "    print(\"‚úÖ Quality predictor initialized\")\n",
    "\n",
    "if PREDICTION_AVAILABLE:\n",
    "    pred_config = PredictionConfig(random_seed=42)\n",
    "    early_defect_predictor = EarlyDefectPredictor(pred_config)\n",
    "    time_series_predictor = TimeSeriesPredictor(pred_config)\n",
    "    prediction_validator = PredictionValidator(pred_config)\n",
    "    print(\"‚úÖ Prediction components initialized\")\n",
    "\n",
    "if OPTIMIZATION_AVAILABLE:\n",
    "    opt_config = OptimizationConfig(random_seed=42)\n",
    "    optimizer = ProcessOptimizer(opt_config)\n",
    "    print(\"‚úÖ Optimizer initialized\")\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions for Demo Data Generation\n",
    "# ============================================\n",
    "\n",
    "def generate_demo_process_data(n_samples=200, n_features=5):\n",
    "    \"\"\"Generate demo process data for prediction and optimization.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate process parameters\n",
    "    data = {\n",
    "        'laser_power': np.random.uniform(200, 300, n_samples),\n",
    "        'scan_speed': np.random.uniform(800, 1200, n_samples),\n",
    "        'layer_thickness': np.random.uniform(0.02, 0.04, n_samples),\n",
    "        'hatch_spacing': np.random.uniform(0.08, 0.12, n_samples),\n",
    "        'temperature': np.random.uniform(800, 1200, n_samples),\n",
    "    }\n",
    "    \n",
    "    # Create quality as function of parameters\n",
    "    quality = (\n",
    "        0.7 +\n",
    "        0.001 * data['laser_power'] +\n",
    "        0.0002 * data['scan_speed'] -\n",
    "        10 * data['layer_thickness'] -\n",
    "        5 * data['hatch_spacing'] +\n",
    "        np.random.randn(n_samples) * 0.05\n",
    "    )\n",
    "    quality = np.clip(quality, 0.0, 1.0)\n",
    "    data['quality'] = quality\n",
    "    \n",
    "    # Create defect labels (1 if quality < 0.6)\n",
    "    data['defect_label'] = (quality < 0.6).astype(int)\n",
    "    \n",
    "    # Add temporal structure\n",
    "    data['timestamp'] = pd.date_range(start='2024-01-01', periods=n_samples, freq='H')\n",
    "    data['build_id'] = [f'build_{i//50}' for i in range(n_samples)]\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"‚úÖ Helper functions initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Top panel created\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Top Panel: Operation Type Selection and Actions\n",
    "# ============================================\n",
    "\n",
    "operation_type_label = WidgetHTML(\"<b>Operation Type:</b>\")\n",
    "operation_type = RadioButtons(\n",
    "    options=[\n",
    "        ('Predictive Quality Models', 'quality_prediction'),\n",
    "        ('Early Defect Detection', 'early_defect'),\n",
    "        ('Time-Series Forecasting', 'time_series'),\n",
    "        ('Process Optimization (Single-objective)', 'optimization_single'),\n",
    "        ('Process Optimization (Multi-objective)', 'optimization_multi'),\n",
    "        ('Optimization Validation', 'validation'),\n",
    "        ('Real-Time Optimization', 'realtime_optimization'),\n",
    "        ('Model Tracking', 'model_tracking'),\n",
    "        ('Complete Workflow', 'complete')\n",
    "    ],\n",
    "    value='quality_prediction',\n",
    "    description='Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "data_source_label = WidgetHTML(\"<b>Data Source:</b>\")\n",
    "data_source_mode = RadioButtons(\n",
    "    options=[('Demo Data', 'demo'), ('MongoDB', 'mongodb'), ('CSV File', 'csv')],\n",
    "    value='demo',\n",
    "    description='Source:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "execute_button = Button(\n",
    "    description='Execute Operation',\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    layout=Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "stop_button = Button(\n",
    "    description='Stop Operation',\n",
    "    button_style='danger',\n",
    "    icon='stop',\n",
    "    layout=Layout(width='180px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "export_button = Button(\n",
    "    description='Export Results',\n",
    "    button_style='',\n",
    "    icon='download',\n",
    "    layout=Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "top_panel = VBox([\n",
    "    HBox([operation_type_label, operation_type], layout=Layout(margin='10px')),\n",
    "    HBox([data_source_label, data_source_mode, execute_button, stop_button, export_button], \n",
    "         layout=Layout(margin='10px'))\n",
    "], layout=Layout(border='2px solid #0277bd', padding='10px', margin='5px'))\n",
    "\n",
    "print(\"‚úÖ Top panel created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration accordion created\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Left Panel: Configuration Accordion\n",
    "# ============================================\n",
    "\n",
    "# Prediction Configuration\n",
    "prediction_model_type = Dropdown(\n",
    "    options=['random_forest', 'gradient_boosting', 'mlp'],\n",
    "    value='random_forest',\n",
    "    description='Model Type:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "prediction_features = SelectMultiple(\n",
    "    options=['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing', 'temperature'],\n",
    "    value=['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing'],\n",
    "    description='Features:',\n",
    "    layout=Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "train_test_split = FloatSlider(\n",
    "    value=0.2,\n",
    "    min=0.1,\n",
    "    max=0.5,\n",
    "    step=0.05,\n",
    "    description='Train-Test Split:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "cv_folds = IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='CV Folds:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_early_prediction = Checkbox(\n",
    "    value=True,\n",
    "    description='Enable Early Prediction',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "early_prediction_horizon = IntSlider(\n",
    "    value=100,\n",
    "    min=50,\n",
    "    max=500,\n",
    "    step=50,\n",
    "    description='Early Horizon:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_time_series = Checkbox(\n",
    "    value=False,\n",
    "    description='Enable Time-Series',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "forecast_horizon = IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=5,\n",
    "    description='Forecast Horizon:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "prediction_config = VBox([\n",
    "    WidgetHTML(\"<b>Prediction Configuration</b>\"),\n",
    "    prediction_model_type,\n",
    "    prediction_features,\n",
    "    train_test_split,\n",
    "    cv_folds,\n",
    "    enable_early_prediction,\n",
    "    early_prediction_horizon,\n",
    "    enable_time_series,\n",
    "    forecast_horizon,\n",
    "], layout=Layout(padding='10px'))\n",
    "\n",
    "# Optimization Configuration\n",
    "optimization_type = RadioButtons(\n",
    "    options=[('Single-objective', 'single'), ('Multi-objective', 'multi')],\n",
    "    value='single',\n",
    "    description='Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "optimization_method = Dropdown(\n",
    "    options=['differential_evolution', 'minimize', 'nsga2', 'realtime'],\n",
    "    value='differential_evolution',\n",
    "    description='Method:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "n_objectives = IntSlider(\n",
    "    value=2,\n",
    "    min=2,\n",
    "    max=5,\n",
    "    step=1,\n",
    "    description='Objectives:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "max_iterations = IntSlider(\n",
    "    value=1000,\n",
    "    min=100,\n",
    "    max=10000,\n",
    "    step=100,\n",
    "    description='Max Iterations:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "population_size = IntSlider(\n",
    "    value=50,\n",
    "    min=10,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Population Size:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_constraints = Checkbox(\n",
    "    value=False,\n",
    "    description='Enable Constraints',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "constraint_method = Dropdown(\n",
    "    options=['penalty', 'barrier', 'augmented_lagrangian'],\n",
    "    value='penalty',\n",
    "    description='Constraint Method:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_realtime = Checkbox(\n",
    "    value=False,\n",
    "    description='Enable Real-Time',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "realtime_update_interval = FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.1,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Update Interval (s):',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "optimization_config = VBox([\n",
    "    WidgetHTML(\"<b>Optimization Configuration</b>\"),\n",
    "    optimization_type,\n",
    "    optimization_method,\n",
    "    n_objectives,\n",
    "    max_iterations,\n",
    "    population_size,\n",
    "    enable_constraints,\n",
    "    constraint_method,\n",
    "    enable_realtime,\n",
    "    realtime_update_interval,\n",
    "], layout=Layout(padding='10px'))\n",
    "\n",
    "# Validation Configuration\n",
    "validation_method = RadioButtons(\n",
    "    options=[('Cross-validation', 'cross_validation'), ('Experimental', 'experimental'), ('Simulation', 'simulation')],\n",
    "    value='cross_validation',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "validation_folds = IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Folds:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "validation_tolerance = FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.01,\n",
    "    max=0.5,\n",
    "    step=0.01,\n",
    "    description='Tolerance:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_experimental = Checkbox(\n",
    "    value=False,\n",
    "    description='Enable Experimental',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "validation_config = VBox([\n",
    "    WidgetHTML(\"<b>Validation Configuration</b>\"),\n",
    "    validation_method,\n",
    "    validation_folds,\n",
    "    validation_tolerance,\n",
    "    enable_experimental,\n",
    "], layout=Layout(padding='10px'))\n",
    "\n",
    "# Model Tracking Configuration\n",
    "enable_model_registry = Checkbox(\n",
    "    value=True,\n",
    "    description='Enable Model Registry',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_performance_tracking = Checkbox(\n",
    "    value=True,\n",
    "    description='Enable Performance Tracking',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "enable_drift_detection = Checkbox(\n",
    "    value=True,\n",
    "    description='Enable Drift Detection',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "drift_threshold = FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.05,\n",
    "    max=0.3,\n",
    "    step=0.05,\n",
    "    description='Drift Threshold:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "degradation_threshold = FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.05,\n",
    "    max=0.3,\n",
    "    step=0.05,\n",
    "    description='Degradation Threshold:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "model_tracking_config = VBox([\n",
    "    WidgetHTML(\"<b>Model Tracking Configuration</b>\"),\n",
    "    enable_model_registry,\n",
    "    enable_performance_tracking,\n",
    "    enable_drift_detection,\n",
    "    drift_threshold,\n",
    "    degradation_threshold,\n",
    "], layout=Layout(padding='10px'))\n",
    "\n",
    "# Configuration Accordion\n",
    "config_accordion = Accordion(children=[\n",
    "    prediction_config,\n",
    "    optimization_config,\n",
    "    validation_config,\n",
    "    model_tracking_config,\n",
    "], selected_index=None, layout=Layout(width='100%'))\n",
    "\n",
    "config_accordion.set_title(0, 'Prediction')\n",
    "config_accordion.set_title(1, 'Optimization')\n",
    "config_accordion.set_title(2, 'Validation')\n",
    "config_accordion.set_title(3, 'Model Tracking')\n",
    "\n",
    "left_panel = VBox([\n",
    "    WidgetHTML(\"<h3>Configuration</h3>\"),\n",
    "    config_accordion,\n",
    "], layout=Layout(width='350px', border='2px solid #f57c00', padding='10px', margin='5px'))\n",
    "\n",
    "print(\"‚úÖ Configuration accordion created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Center panel created\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Center Panel: Main Output\n",
    "# ============================================\n",
    "\n",
    "main_output = Output(layout=Layout(height='600px', border='1px solid #ccc', overflow_y='auto'))\n",
    "\n",
    "# Initialize main output\n",
    "with main_output:\n",
    "    display(HTML(\"<p><i>Results and visualizations will appear here...</i></p>\"))\n",
    "\n",
    "center_panel = VBox([\n",
    "    WidgetHTML(\"<h3>Results & Visualizations</h3>\"),\n",
    "    main_output,\n",
    "], layout=Layout(flex='1 1 auto', border='2px solid #4caf50', padding='10px', margin='5px'))\n",
    "\n",
    "print(\"‚úÖ Center panel created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Right panel created\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Right Panel: Status Displays\n",
    "# ============================================\n",
    "\n",
    "# Status Display\n",
    "status_display = WidgetHTML(\n",
    "    value='<b>Status:</b> Ready<br><b>Operation:</b> None<br><b>Time:</b> 0:00',\n",
    "    layout=Layout(height='150px', border='1px solid #ccc', padding='10px')\n",
    ")\n",
    "\n",
    "# Model Performance Display\n",
    "model_performance_display = WidgetHTML(\n",
    "    value='<b>Model Performance:</b><br>No model trained yet',\n",
    "    layout=Layout(height='150px', border='1px solid #ccc', padding='10px')\n",
    ")\n",
    "\n",
    "# Optimization Results Display\n",
    "optimization_results_display = WidgetHTML(\n",
    "    value='<b>Optimization Results:</b><br>No optimization performed yet',\n",
    "    layout=Layout(height='150px', border='1px solid #ccc', padding='10px')\n",
    ")\n",
    "\n",
    "# Model Tracking Display\n",
    "model_tracking_display = WidgetHTML(\n",
    "    value='<b>Model Tracking:</b><br>No models registered yet',\n",
    "    layout=Layout(height='150px', border='1px solid #ccc', padding='10px')\n",
    ")\n",
    "\n",
    "right_panel = VBox([\n",
    "    WidgetHTML(\"<h3>Status & Metrics</h3>\"),\n",
    "    status_display,\n",
    "    model_performance_display,\n",
    "    optimization_results_display,\n",
    "    model_tracking_display,\n",
    "], layout=Layout(width='300px', border='2px solid #7b1fa2', padding='10px', margin='5px'))\n",
    "\n",
    "print(\"‚úÖ Right panel created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bottom panel created\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Bottom Panel: Progress and Logs\n",
    "# ============================================\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Status text\n",
    "status_text = WidgetHTML(value='<b>Status:</b> Ready')\n",
    "\n",
    "# Processing logs output\n",
    "processing_logs = Output(layout=Layout(height='200px', border='1px solid #ccc', overflow_y='auto'))\n",
    "\n",
    "# Initialize logs\n",
    "with processing_logs:\n",
    "    display(HTML(\"<p><i>Processing logs will appear here...</i></p>\"))\n",
    "\n",
    "# Global time tracking\n",
    "operation_start_time = None\n",
    "\n",
    "bottom_panel = VBox([\n",
    "    progress_bar,\n",
    "    status_text,\n",
    "    WidgetHTML(\"<b>Processing Logs:</b>\"),\n",
    "    processing_logs,\n",
    "], layout=Layout(padding='10px', border='1px solid #ccc', margin='5px'))\n",
    "\n",
    "print(\"‚úÖ Bottom panel created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Logging functions created\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Logging Functions\n",
    "# ============================================\n",
    "\n",
    "def log_message(message: str, level: str = 'info'):\n",
    "    \"\"\"Log a message to the processing logs with timestamp and emoji.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    \n",
    "    if level == 'success':\n",
    "        emoji = '‚úÖ'\n",
    "        color = 'green'\n",
    "    elif level == 'warning':\n",
    "        emoji = '‚ö†Ô∏è'\n",
    "        color = 'orange'\n",
    "    elif level == 'error':\n",
    "        emoji = '‚ùå'\n",
    "        color = 'red'\n",
    "    else:\n",
    "        emoji = '‚ÑπÔ∏è'\n",
    "        color = 'blue'\n",
    "    \n",
    "    log_entry = f'<p style=\"color: {color}; margin: 2px 0;\"><b>{emoji} [{timestamp}]</b> {message}</p>'\n",
    "    \n",
    "    with processing_logs:\n",
    "        display(HTML(log_entry), display_id=True)\n",
    "\n",
    "def update_progress(value: int, message: str = ''):\n",
    "    \"\"\"Update progress bar and status.\"\"\"\n",
    "    progress_bar.value = value\n",
    "    if message:\n",
    "        status_text.value = f'<b>Status:</b> {message} | <b>Progress:</b> {value}%'\n",
    "    else:\n",
    "        status_text.value = f'<b>Status:</b> In Progress | <b>Progress:</b> {value}%'\n",
    "\n",
    "def update_status(operation: str, status: str, elapsed_time: float = None):\n",
    "    \"\"\"Update status display.\"\"\"\n",
    "    time_str = f\"{elapsed_time:.1f}s\" if elapsed_time else \"0:00\"\n",
    "    status_display.value = f'<b>Status:</b> {status}<br><b>Operation:</b> {operation}<br><b>Time:</b> {time_str}'\n",
    "\n",
    "def update_model_performance(metrics: Dict[str, float]):\n",
    "    \"\"\"Update model performance display.\"\"\"\n",
    "    metrics_html = '<br>'.join([f'<b>{k}:</b> {v:.4f}' for k, v in metrics.items()])\n",
    "    model_performance_display.value = f'<b>Model Performance:</b><br>{metrics_html}'\n",
    "\n",
    "def update_optimization_results(result: Dict[str, Any]):\n",
    "    \"\"\"Update optimization results display.\"\"\"\n",
    "    if result:\n",
    "        params_html = '<br>'.join([f'<b>{k}:</b> {v:.4f}' for k, v in result.get('optimal_parameters', {}).items()])\n",
    "        value_html = f\"<b>Optimal Value:</b> {result.get('optimal_value', 'N/A')}\"\n",
    "        optimization_results_display.value = f'<b>Optimization Results:</b><br>{params_html}<br>{value_html}'\n",
    "    else:\n",
    "        optimization_results_display.value = '<b>Optimization Results:</b><br>No optimization performed yet'\n",
    "\n",
    "def update_model_tracking(info: Dict[str, Any]):\n",
    "    \"\"\"Update model tracking display.\"\"\"\n",
    "    if info:\n",
    "        models_html = f\"<b>Registered Models:</b> {info.get('registered_count', 0)}<br>\"\n",
    "        models_html += f\"<b>Performance Evaluations:</b> {info.get('evaluation_count', 0)}<br>\"\n",
    "        models_html += f\"<b>Drift Score:</b> {info.get('drift_score', 0.0):.4f}\"\n",
    "        model_tracking_display.value = f'<b>Model Tracking:</b><br>{models_html}'\n",
    "    else:\n",
    "        model_tracking_display.value = '<b>Model Tracking:</b><br>No models registered yet'\n",
    "\n",
    "print(\"‚úÖ Logging functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Execution functions created (partial)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Execution Functions\n",
    "# ============================================\n",
    "\n",
    "def execute_quality_prediction():\n",
    "    \"\"\"Execute predictive quality model training and evaluation.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Quality Prediction'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting quality prediction model training...\", 'info')\n",
    "        update_progress(10, \"Loading data...\")\n",
    "        update_status(current_operation, \"Loading Data\")\n",
    "        \n",
    "        # Load or generate data\n",
    "        if data_source_mode.value == 'demo':\n",
    "            process_data = generate_demo_process_data(n_samples=200)\n",
    "            log_message(f\"Generated demo data: {len(process_data)} samples\", 'success')\n",
    "        else:\n",
    "            log_message(\"MongoDB/CSV data loading not implemented in demo\", 'warning')\n",
    "            process_data = generate_demo_process_data(n_samples=200)\n",
    "        \n",
    "        update_progress(30, \"Training model...\")\n",
    "        log_message(\"Training quality prediction model...\", 'info')\n",
    "        \n",
    "        # Configure and train\n",
    "        if QUALITY_AVAILABLE and quality_predictor:\n",
    "            feature_names = list(prediction_features.value)\n",
    "            if not feature_names:\n",
    "                feature_names = ['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']\n",
    "            \n",
    "            result = quality_predictor.analyze_quality_prediction(\n",
    "                process_data,\n",
    "                quality_target='quality',\n",
    "                feature_names=feature_names\n",
    "            )\n",
    "            \n",
    "            update_progress(70, \"Evaluating model...\")\n",
    "            \n",
    "            if result.success:\n",
    "                log_message(f\"Model trained successfully! R¬≤: {result.model_performance.get('r2_score', 0):.4f}\", 'success')\n",
    "                update_model_performance(result.model_performance)\n",
    "                \n",
    "                # Register model if enabled\n",
    "                if enable_model_registry.value and MODEL_TRACKING_AVAILABLE and model_registry and quality_predictor.trained_model:\n",
    "                    try:\n",
    "                        model_id = model_registry.register_model(\n",
    "                            model=quality_predictor.trained_model,\n",
    "                            model_type=prediction_model_type.value.title().replace('_', ''),\n",
    "                            version='1.0',\n",
    "                            metadata={'feature_names': feature_names},\n",
    "                            performance_metrics=result.model_performance\n",
    "                        )\n",
    "                        log_message(f\"Model registered: {model_id}\", 'success')\n",
    "                        update_model_tracking({'registered_count': len(model_registry._models)})\n",
    "                    except Exception as e:\n",
    "                        log_message(f\"Model registration failed: {e}\", 'warning')\n",
    "                \n",
    "                # Visualize results\n",
    "                update_progress(90, \"Generating visualizations...\")\n",
    "                with main_output:\n",
    "                    clear_output(wait=True)\n",
    "                    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                    \n",
    "                    # Quality predictions vs actual\n",
    "                    axes[0, 0].scatter(process_data['quality'].values[:len(result.quality_predictions)], \n",
    "                                     result.quality_predictions, alpha=0.6)\n",
    "                    axes[0, 0].plot([0, 1], [0, 1], 'r--', lw=2)\n",
    "                    axes[0, 0].set_xlabel('Actual Quality')\n",
    "                    axes[0, 0].set_ylabel('Predicted Quality')\n",
    "                    axes[0, 0].set_title('Quality Predictions vs Actual')\n",
    "                    axes[0, 0].grid(True)\n",
    "                    \n",
    "                    # Feature importance (if available)\n",
    "                    if hasattr(quality_predictor.trained_model, 'feature_importances_'):\n",
    "                        importances = quality_predictor.trained_model.feature_importances_\n",
    "                        feature_names_list = feature_names[:len(importances)]\n",
    "                        axes[0, 1].barh(feature_names_list, importances)\n",
    "                        axes[0, 1].set_xlabel('Importance')\n",
    "                        axes[0, 1].set_title('Feature Importance')\n",
    "                        axes[0, 1].grid(True)\n",
    "                    \n",
    "                    # Quality distribution\n",
    "                    axes[1, 0].hist(result.quality_predictions, bins=20, alpha=0.7, edgecolor='black')\n",
    "                    axes[1, 0].set_xlabel('Predicted Quality')\n",
    "                    axes[1, 0].set_ylabel('Frequency')\n",
    "                    axes[1, 0].set_title('Quality Distribution')\n",
    "                    axes[1, 0].grid(True)\n",
    "                    \n",
    "                    # Model performance metrics\n",
    "                    metrics = result.model_performance\n",
    "                    metric_names = list(metrics.keys())[:5]  # Top 5 metrics\n",
    "                    metric_values = [metrics[k] for k in metric_names]\n",
    "                    axes[1, 1].bar(metric_names, metric_values)\n",
    "                    axes[1, 1].set_ylabel('Value')\n",
    "                    axes[1, 1].set_title('Model Performance Metrics')\n",
    "                    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "                    axes[1, 1].grid(True)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                update_progress(100, \"Complete!\")\n",
    "                elapsed = time.time() - operation_start_time\n",
    "                update_status(current_operation, \"Complete\", elapsed)\n",
    "                log_message(f\"Quality prediction completed in {elapsed:.2f}s\", 'success')\n",
    "                \n",
    "                prediction_results['quality'] = result\n",
    "            else:\n",
    "                log_message(f\"Model training failed: {result.error_message}\", 'error')\n",
    "                update_progress(100, \"Failed\")\n",
    "        else:\n",
    "            log_message(\"Quality predictor not available - using demo mode\", 'warning')\n",
    "            update_progress(100, \"Demo mode\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in quality prediction: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "        update_progress(100, \"Error\")\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "def execute_early_defect_detection():\n",
    "    \"\"\"Execute early defect detection.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Early Defect Detection'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting early defect detection model training...\", 'info')\n",
    "        update_progress(10, \"Loading data...\")\n",
    "        \n",
    "        # Load or generate data\n",
    "        process_data = generate_demo_process_data(n_samples=200)\n",
    "        feature_names = list(prediction_features.value) if prediction_features.value else ['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']\n",
    "        \n",
    "        update_progress(30, \"Training early defect model...\")\n",
    "        \n",
    "        if PREDICTION_AVAILABLE and early_defect_predictor:\n",
    "            # Train model\n",
    "            result = early_defect_predictor.train_early_prediction_model(\n",
    "                process_data[feature_names],\n",
    "                process_data['defect_label'].values,\n",
    "                feature_names=feature_names,\n",
    "                early_horizon=early_prediction_horizon.value\n",
    "            )\n",
    "            \n",
    "            update_progress(70, \"Evaluating predictions...\")\n",
    "            \n",
    "            if result.success:\n",
    "                log_message(f\"Early defect model trained! Accuracy: {result.early_prediction_accuracy:.4f}\", 'success')\n",
    "                update_model_performance(result.model_performance)\n",
    "                \n",
    "                # Test on partial data\n",
    "                partial_data = process_data[feature_names].iloc[:30]\n",
    "                defect_prob, confidence = early_defect_predictor.predict_early_defect(\n",
    "                    partial_data, build_progress=0.3\n",
    "                )\n",
    "                \n",
    "                # Visualize\n",
    "                update_progress(90, \"Generating visualizations...\")\n",
    "                with main_output:\n",
    "                    clear_output(wait=True)\n",
    "                    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                    \n",
    "                    # Defect probability over time\n",
    "                    axes[0, 0].plot(defect_prob, 'b-', label='Defect Probability', linewidth=2)\n",
    "                    axes[0, 0].axhline(y=0.5, color='r', linestyle='--', label='Threshold')\n",
    "                    axes[0, 0].set_xlabel('Sample Index')\n",
    "                    axes[0, 0].set_ylabel('Defect Probability')\n",
    "                    axes[0, 0].set_title('Early Defect Probability')\n",
    "                    axes[0, 0].legend()\n",
    "                    axes[0, 0].grid(True)\n",
    "                    \n",
    "                    # Prediction confidence\n",
    "                    axes[0, 1].plot(confidence, 'g-', label='Confidence', linewidth=2)\n",
    "                    axes[0, 1].set_xlabel('Sample Index')\n",
    "                    axes[0, 1].set_ylabel('Confidence')\n",
    "                    axes[0, 1].set_title('Prediction Confidence')\n",
    "                    axes[0, 1].legend()\n",
    "                    axes[0, 1].grid(True)\n",
    "                    \n",
    "                    # Feature importance\n",
    "                    if result.feature_importance:\n",
    "                        top_features = sorted(result.feature_importance.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "                        feature_names_list = [f[0] for f in top_features]\n",
    "                        importances = [f[1] for f in top_features]\n",
    "                        axes[1, 0].barh(feature_names_list, importances)\n",
    "                        axes[1, 0].set_xlabel('Importance')\n",
    "                        axes[1, 0].set_title('Feature Importance for Early Detection')\n",
    "                        axes[1, 0].grid(True)\n",
    "                    \n",
    "                    # Model performance\n",
    "                    metrics = result.model_performance\n",
    "                    metric_names = list(metrics.keys())\n",
    "                    metric_values = [metrics[k] for k in metric_names]\n",
    "                    axes[1, 1].bar(metric_names, metric_values)\n",
    "                    axes[1, 1].set_ylabel('Value')\n",
    "                    axes[1, 1].set_title('Model Performance')\n",
    "                    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "                    axes[1, 1].grid(True)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                update_progress(100, \"Complete!\")\n",
    "                elapsed = time.time() - operation_start_time\n",
    "                update_status(current_operation, \"Complete\", elapsed)\n",
    "                log_message(f\"Early defect detection completed in {elapsed:.2f}s\", 'success')\n",
    "                \n",
    "                prediction_results['early_defect'] = result\n",
    "            else:\n",
    "                log_message(f\"Early defect model training failed: {result.error_message}\", 'error')\n",
    "        else:\n",
    "            log_message(\"Early defect predictor not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in early defect detection: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "def execute_time_series_forecasting():\n",
    "    \"\"\"Execute time-series forecasting.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Time-Series Forecasting'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting time-series forecasting...\", 'info')\n",
    "        update_progress(20, \"Loading data...\")\n",
    "        \n",
    "        # Generate time-series data\n",
    "        process_data = generate_demo_process_data(n_samples=100)\n",
    "        quality_series = process_data['quality'].values\n",
    "        \n",
    "        update_progress(40, \"Forecasting...\")\n",
    "        \n",
    "        if PREDICTION_AVAILABLE and time_series_predictor:\n",
    "            # Forecast using moving average (most reliable)\n",
    "            result = time_series_predictor.forecast_quality_metric(\n",
    "                quality_series,\n",
    "                forecast_horizon=forecast_horizon.value,\n",
    "                model_type='moving_average'\n",
    "            )\n",
    "            \n",
    "            update_progress(80, \"Generating visualizations...\")\n",
    "            \n",
    "            if result.success:\n",
    "                log_message(f\"Forecast completed! Horizon: {result.forecast_horizon}\", 'success')\n",
    "                \n",
    "                # Visualize\n",
    "                with main_output:\n",
    "                    clear_output(wait=True)\n",
    "                    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "                    \n",
    "                    # Historical and forecast\n",
    "                    historical_len = len(result.historical_data)\n",
    "                    forecast_len = len(result.forecast)\n",
    "                    x_historical = np.arange(historical_len)\n",
    "                    x_forecast = np.arange(historical_len, historical_len + forecast_len)\n",
    "                    \n",
    "                    axes[0].plot(x_historical, result.historical_data, 'b-', label='Historical', linewidth=2)\n",
    "                    axes[0].plot(x_forecast, result.forecast, 'r-', label='Forecast', linewidth=2)\n",
    "                    axes[0].fill_between(x_forecast, result.forecast_lower_bound, result.forecast_upper_bound, \n",
    "                                          alpha=0.3, color='red', label='Confidence Interval')\n",
    "                    axes[0].axvline(x=historical_len, color='g', linestyle='--', label='Forecast Start')\n",
    "                    axes[0].set_xlabel('Time Step')\n",
    "                    axes[0].set_ylabel('Quality')\n",
    "                    axes[0].set_title('Quality Time-Series Forecast')\n",
    "                    axes[0].legend()\n",
    "                    axes[0].grid(True)\n",
    "                    \n",
    "                    # Forecast with bounds\n",
    "                    axes[1].plot(x_forecast, result.forecast, 'r-', label='Forecast', linewidth=2)\n",
    "                    axes[1].fill_between(x_forecast, result.forecast_lower_bound, result.forecast_upper_bound, \n",
    "                                        alpha=0.3, color='red', label='Confidence Interval')\n",
    "                    axes[1].set_xlabel('Forecast Step')\n",
    "                    axes[1].set_ylabel('Quality')\n",
    "                    axes[1].set_title('Forecast with Confidence Intervals')\n",
    "                    axes[1].legend()\n",
    "                    axes[1].grid(True)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                update_progress(100, \"Complete!\")\n",
    "                elapsed = time.time() - operation_start_time\n",
    "                update_status(current_operation, \"Complete\", elapsed)\n",
    "                log_message(f\"Time-series forecasting completed in {elapsed:.2f}s\", 'success')\n",
    "                \n",
    "                prediction_results['time_series'] = result\n",
    "            else:\n",
    "                log_message(f\"Forecasting failed: {result.error_message}\", 'error')\n",
    "        else:\n",
    "            log_message(\"Time-series predictor not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in time-series forecasting: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "print(\"‚úÖ Execution functions created (partial)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Optimization execution functions created\n"
     ]
    }
   ],
   "source": [
    "# Continue execution functions\n",
    "\n",
    "def execute_optimization_single():\n",
    "    \"\"\"Execute single-objective optimization.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Single-Objective Optimization'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting single-objective optimization...\", 'info')\n",
    "        update_progress(10, \"Preparing data and model...\")\n",
    "        \n",
    "        # First train quality predictor if not already trained\n",
    "        process_data = generate_demo_process_data(n_samples=200)\n",
    "        feature_names = ['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']\n",
    "        \n",
    "        if QUALITY_AVAILABLE and quality_predictor:\n",
    "            if quality_predictor.trained_model is None:\n",
    "                log_message(\"Training quality predictor for optimization...\", 'info')\n",
    "                quality_predictor.analyze_quality_prediction(\n",
    "                    process_data, quality_target='quality', feature_names=feature_names\n",
    "                )\n",
    "            \n",
    "            update_progress(30, \"Defining objective function...\")\n",
    "            \n",
    "            # Define objective function\n",
    "            def objective_function(params):\n",
    "                param_df = pd.DataFrame([params])\n",
    "                quality_pred = quality_predictor.predict_quality(param_df)\n",
    "                return -quality_pred[0]  # Negative for minimization\n",
    "            \n",
    "            # Parameter bounds\n",
    "            parameter_bounds = {\n",
    "                'laser_power': (200.0, 300.0),\n",
    "                'scan_speed': (800.0, 1200.0),\n",
    "                'layer_thickness': (0.02, 0.04),\n",
    "                'hatch_spacing': (0.08, 0.12)\n",
    "            }\n",
    "            \n",
    "            update_progress(50, \"Running optimization...\")\n",
    "            log_message(f\"Optimization method: {optimization_method.value}, Max iterations: {max_iterations.value}\", 'info')\n",
    "            \n",
    "            if OPTIMIZATION_AVAILABLE and optimizer:\n",
    "                # Configure optimizer\n",
    "                optimizer.config.max_iterations = max_iterations.value\n",
    "                optimizer.config.population_size = population_size.value\n",
    "                optimizer.config.optimization_method = optimization_method.value\n",
    "                \n",
    "                # Handle constraints if enabled\n",
    "                if enable_constraints.value:\n",
    "                    def energy_constraint(params):\n",
    "                        return (params['laser_power'] / params['scan_speed']) - 0.3\n",
    "                    \n",
    "                    result = optimizer.optimize_with_constraints(\n",
    "                        objective_function,\n",
    "                        parameter_bounds,\n",
    "                        [energy_constraint],\n",
    "                        constraint_method=constraint_method.value\n",
    "                    )\n",
    "                else:\n",
    "                    result = optimizer.optimize_single_objective(\n",
    "                        objective_function,\n",
    "                        parameter_bounds\n",
    "                    )\n",
    "                \n",
    "                update_progress(90, \"Generating visualizations...\")\n",
    "                \n",
    "                if result.success:\n",
    "                    log_message(f\"Optimization completed! Optimal value: {result.optimal_values:.4f}\", 'success')\n",
    "                    \n",
    "                    opt_result_dict = {\n",
    "                        'optimal_parameters': result.optimal_parameters,\n",
    "                        'optimal_value': -result.optimal_values  # Convert back to positive\n",
    "                    }\n",
    "                    update_optimization_results(opt_result_dict)\n",
    "                    optimization_results['single'] = result\n",
    "                    \n",
    "                    # Visualize\n",
    "                    with main_output:\n",
    "                        clear_output(wait=True)\n",
    "                        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                        \n",
    "                        # Optimal parameters\n",
    "                        param_names = list(result.optimal_parameters.keys())\n",
    "                        param_values = list(result.optimal_parameters.values())\n",
    "                        axes[0, 0].bar(param_names, param_values)\n",
    "                        axes[0, 0].set_ylabel('Value')\n",
    "                        axes[0, 0].set_title('Optimal Parameters')\n",
    "                        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "                        axes[0, 0].grid(True)\n",
    "                        \n",
    "                        # Parameter comparison (optimal vs bounds)\n",
    "                        bounds_mid = [(parameter_bounds[k][0] + parameter_bounds[k][1]) / 2 for k in param_names]\n",
    "                        axes[0, 1].barh([f\"{n}_optimal\" for n in param_names], param_values, alpha=0.7, label='Optimal')\n",
    "                        axes[0, 1].barh([f\"{n}_mid\" for n in param_names], bounds_mid, alpha=0.5, label='Bounds Mid')\n",
    "                        axes[0, 1].set_xlabel('Value')\n",
    "                        axes[0, 1].set_title('Optimal vs Bounds Midpoint')\n",
    "                        axes[0, 1].legend()\n",
    "                        axes[0, 1].grid(True)\n",
    "                        \n",
    "                        # Optimization history (if available)\n",
    "                        if result.optimization_history:\n",
    "                            axes[1, 0].plot(result.optimization_history, 'b-', linewidth=2)\n",
    "                            axes[1, 0].set_xlabel('Iteration')\n",
    "                            axes[1, 0].set_ylabel('Objective Value')\n",
    "                            axes[1, 0].set_title('Optimization Convergence')\n",
    "                            axes[1, 0].grid(True)\n",
    "                        \n",
    "                        # Quality prediction at optimal parameters\n",
    "                        optimal_df = pd.DataFrame([result.optimal_parameters])\n",
    "                        optimal_quality = quality_predictor.predict_quality(optimal_df)[0]\n",
    "                        axes[1, 1].bar(['Optimal Quality'], [optimal_quality], color='green', alpha=0.7)\n",
    "                        axes[1, 1].axhline(y=0.8, color='r', linestyle='--', label='Target (0.8)')\n",
    "                        axes[1, 1].set_ylabel('Quality')\n",
    "                        axes[1, 1].set_title('Predicted Quality at Optimal Parameters')\n",
    "                        axes[1, 1].legend()\n",
    "                        axes[1, 1].grid(True)\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    \n",
    "                    update_progress(100, \"Complete!\")\n",
    "                    elapsed = time.time() - operation_start_time\n",
    "                    update_status(current_operation, \"Complete\", elapsed)\n",
    "                    log_message(f\"Single-objective optimization completed in {elapsed:.2f}s\", 'success')\n",
    "                else:\n",
    "                    log_message(f\"Optimization failed: {result.error_message}\", 'error')\n",
    "            else:\n",
    "                log_message(\"Optimizer not available\", 'warning')\n",
    "        else:\n",
    "            log_message(\"Quality predictor not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in optimization: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "def execute_optimization_multi():\n",
    "    \"\"\"Execute multi-objective optimization.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Multi-Objective Optimization'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting multi-objective optimization...\", 'info')\n",
    "        update_progress(20, \"Defining objectives...\")\n",
    "        \n",
    "        # Define multiple objectives\n",
    "        def objective_functions(params):\n",
    "            # Objective 1: Maximize quality\n",
    "            quality = 0.7 + 0.001 * params['laser_power'] - 10 * params['layer_thickness']\n",
    "            quality = np.clip(quality, 0.0, 1.0)\n",
    "            \n",
    "            # Objective 2: Minimize energy consumption\n",
    "            energy = params['laser_power'] / params['scan_speed']\n",
    "            \n",
    "            return [-quality, energy]  # Negative quality for minimization\n",
    "        \n",
    "        parameter_bounds = {\n",
    "            'laser_power': (200.0, 300.0),\n",
    "            'scan_speed': (800.0, 1200.0),\n",
    "            'layer_thickness': (0.02, 0.04)\n",
    "        }\n",
    "        \n",
    "        update_progress(40, \"Running multi-objective optimization...\")\n",
    "        \n",
    "        if OPTIMIZATION_AVAILABLE and optimizer:\n",
    "            optimizer.config.max_iterations = max_iterations.value\n",
    "            optimizer.config.population_size = population_size.value\n",
    "            optimizer.config.n_objectives = n_objectives.value\n",
    "            optimizer.config.pareto_front_size = 50\n",
    "            \n",
    "            result = optimizer.optimize_multi_objective(\n",
    "                objective_functions,\n",
    "                parameter_bounds,\n",
    "                n_objectives=n_objectives.value\n",
    "            )\n",
    "            \n",
    "            update_progress(80, \"Generating visualizations...\")\n",
    "            \n",
    "            if result.success and result.pareto_front is not None and len(result.pareto_front) > 0:\n",
    "                log_message(f\"Multi-objective optimization completed! Pareto solutions: {len(result.pareto_front)}\", 'success')\n",
    "                \n",
    "                # Extract Pareto front\n",
    "                pareto_df = result.pareto_front\n",
    "                \n",
    "                # Visualize\n",
    "                with main_output:\n",
    "                    clear_output(wait=True)\n",
    "                    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                    \n",
    "                    # Pareto front (if objectives available)\n",
    "                    if 'objectives' in pareto_df.columns:\n",
    "                        objectives_list = pareto_df['objectives'].tolist()\n",
    "                        if len(objectives_list) > 0 and isinstance(objectives_list[0], (list, np.ndarray)):\n",
    "                            obj1 = [-o[0] for o in objectives_list]  # Quality (negate back)\n",
    "                            obj2 = [o[1] for o in objectives_list]  # Energy\n",
    "                            \n",
    "                            axes[0, 0].scatter(obj2, obj1, alpha=0.6, s=50)\n",
    "                            axes[0, 0].set_xlabel('Energy Consumption')\n",
    "                            axes[0, 0].set_ylabel('Quality')\n",
    "                            axes[0, 0].set_title('Pareto Front: Quality vs Energy')\n",
    "                            axes[0, 0].grid(True)\n",
    "                    \n",
    "                    # Parameter distributions in Pareto front\n",
    "                    if 'parameters' in pareto_df.columns:\n",
    "                        params_list = pareto_df['parameters'].tolist()\n",
    "                        if len(params_list) > 0:\n",
    "                            laser_powers = [p[0] if isinstance(p, (list, np.ndarray)) else 0 for p in params_list]\n",
    "                            scan_speeds = [p[1] if isinstance(p, (list, np.ndarray)) and len(p) > 1 else 0 for p in params_list]\n",
    "                            \n",
    "                            axes[0, 1].scatter(laser_powers, scan_speeds, alpha=0.6, s=50)\n",
    "                            axes[0, 1].set_xlabel('Laser Power')\n",
    "                            axes[0, 1].set_ylabel('Scan Speed')\n",
    "                            axes[0, 1].set_title('Parameter Space in Pareto Front')\n",
    "                            axes[0, 1].grid(True)\n",
    "                    \n",
    "                    # Pareto front size\n",
    "                    axes[1, 0].bar(['Pareto Solutions'], [len(pareto_df)], color='green', alpha=0.7)\n",
    "                    axes[1, 0].set_ylabel('Number of Solutions')\n",
    "                    axes[1, 0].set_title('Pareto Front Size')\n",
    "                    axes[1, 0].grid(True)\n",
    "                    \n",
    "                    # Solution distribution\n",
    "                    axes[1, 1].hist(range(len(pareto_df)), bins=min(20, len(pareto_df)), alpha=0.7, edgecolor='black')\n",
    "                    axes[1, 1].set_xlabel('Solution Index')\n",
    "                    axes[1, 1].set_ylabel('Frequency')\n",
    "                    axes[1, 1].set_title('Solution Distribution')\n",
    "                    axes[1, 1].grid(True)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                optimization_results['multi'] = result\n",
    "                update_progress(100, \"Complete!\")\n",
    "                elapsed = time.time() - operation_start_time\n",
    "                update_status(current_operation, \"Complete\", elapsed)\n",
    "                log_message(f\"Multi-objective optimization completed in {elapsed:.2f}s\", 'success')\n",
    "            else:\n",
    "                log_message(\"Multi-objective optimization failed or no Pareto solutions\", 'error')\n",
    "        else:\n",
    "            log_message(\"Optimizer not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in multi-objective optimization: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "print(\"‚úÖ Optimization execution functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All execution functions created\n"
     ]
    }
   ],
   "source": [
    "# Continue with validation, model tracking, and complete workflow functions\n",
    "\n",
    "def execute_validation():\n",
    "    \"\"\"Execute optimization validation.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Optimization Validation'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting optimization validation...\", 'info')\n",
    "        update_progress(10, \"Preparing validation...\")\n",
    "        \n",
    "        process_data = generate_demo_process_data(n_samples=200)\n",
    "        feature_names = ['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']\n",
    "        \n",
    "        # Train quality predictor\n",
    "        if QUALITY_AVAILABLE and quality_predictor:\n",
    "            if quality_predictor.trained_model is None:\n",
    "                quality_predictor.analyze_quality_prediction(\n",
    "                    process_data, quality_target='quality', feature_names=feature_names\n",
    "                )\n",
    "            \n",
    "            update_progress(30, \"Performing validation...\")\n",
    "            \n",
    "            if PREDICTION_AVAILABLE and prediction_validator:\n",
    "                if validation_method.value == 'cross_validation':\n",
    "                    log_message(\"Performing cross-validation...\", 'info')\n",
    "                    cv_result = prediction_validator.cross_validate_model(\n",
    "                        quality_predictor,\n",
    "                        process_data,\n",
    "                        quality_target='quality',\n",
    "                        n_folds=validation_folds.value,\n",
    "                        validation_method='kfold'\n",
    "                    )\n",
    "                    \n",
    "                    update_progress(80, \"Generating visualizations...\")\n",
    "                    \n",
    "                    with main_output:\n",
    "                        clear_output(wait=True)\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "                        \n",
    "                        # CV metrics\n",
    "                        if 'mean_r2' in cv_result:\n",
    "                            metrics = ['mean_r2', 'mean_rmse', 'mean_mae']\n",
    "                            means = [cv_result.get(m, 0) for m in metrics]\n",
    "                            stds = [cv_result.get(m.replace('mean', 'std'), 0) for m in metrics]\n",
    "                            \n",
    "                            x = np.arange(len(metrics))\n",
    "                            axes[0].bar(x, means, yerr=stds, alpha=0.7, capsize=5)\n",
    "                            axes[0].set_xticks(x)\n",
    "                            axes[0].set_xticklabels(metrics, rotation=45)\n",
    "                            axes[0].set_ylabel('Value')\n",
    "                            axes[0].set_title('Cross-Validation Metrics')\n",
    "                            axes[0].grid(True)\n",
    "                        \n",
    "                        # Validation summary\n",
    "                        summary_text = f\"Validation Method: {cv_result.get('validation_method', 'N/A')}<br>\"\n",
    "                        summary_text += f\"Folds: {cv_result.get('n_folds', 'N/A')}<br>\"\n",
    "                        summary_text += f\"Analysis Time: {cv_result.get('analysis_time', 0):.2f}s\"\n",
    "                        axes[1].text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center',\n",
    "                                    transform=axes[1].transAxes)\n",
    "                        axes[1].axis('off')\n",
    "                        axes[1].set_title('Validation Summary')\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    \n",
    "                    log_message(f\"Cross-validation completed! Mean R¬≤: {cv_result.get('mean_r2', 0):.4f}\", 'success')\n",
    "                \n",
    "                elif validation_method.value == 'experimental':\n",
    "                    log_message(\"Performing experimental validation...\", 'info')\n",
    "                    \n",
    "                    # Simulate experimental data\n",
    "                    predicted_data = process_data.iloc[:20].copy()\n",
    "                    experimental_data = pd.DataFrame({\n",
    "                        'quality': process_data['quality'].iloc[:20].values + np.random.randn(20) * 0.05\n",
    "                    })\n",
    "                    \n",
    "                    validation_result = prediction_validator.validate_with_experimental_data(\n",
    "                        quality_predictor,\n",
    "                        predicted_data,\n",
    "                        experimental_data,\n",
    "                        quality_target='quality'\n",
    "                    )\n",
    "                    \n",
    "                    if validation_result.success:\n",
    "                        log_message(f\"Experimental validation completed! Error: {validation_result.validation_error:.4f}\", 'success')\n",
    "                        \n",
    "                        with main_output:\n",
    "                            clear_output(wait=True)\n",
    "                            fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "                            \n",
    "                            # Predicted vs Experimental\n",
    "                            axes[0].scatter(validation_result.experimental_objective, \n",
    "                                          validation_result.predicted_objective, alpha=0.6)\n",
    "                            axes[0].plot([0, 1], [0, 1], 'r--', lw=2)\n",
    "                            axes[0].set_xlabel('Experimental Quality')\n",
    "                            axes[0].set_ylabel('Predicted Quality')\n",
    "                            axes[0].set_title('Predicted vs Experimental')\n",
    "                            axes[0].grid(True)\n",
    "                            \n",
    "                            # Validation metrics\n",
    "                            metrics = validation_result.validation_metrics\n",
    "                            metric_names = list(metrics.keys())\n",
    "                            metric_values = [metrics[k] for k in metric_names]\n",
    "                            axes[1].bar(metric_names, metric_values)\n",
    "                            axes[1].set_ylabel('Value')\n",
    "                            axes[1].set_title('Validation Metrics')\n",
    "                            axes[1].tick_params(axis='x', rotation=45)\n",
    "                            axes[1].grid(True)\n",
    "                            \n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                \n",
    "                update_progress(100, \"Complete!\")\n",
    "                elapsed = time.time() - operation_start_time\n",
    "                update_status(current_operation, \"Complete\", elapsed)\n",
    "                log_message(f\"Validation completed in {elapsed:.2f}s\", 'success')\n",
    "            else:\n",
    "                log_message(\"Prediction validator not available\", 'warning')\n",
    "        else:\n",
    "            log_message(\"Quality predictor not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in validation: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "def execute_model_tracking():\n",
    "    \"\"\"Execute model tracking operations.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Model Tracking'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting model tracking operations...\", 'info')\n",
    "        update_progress(20, \"Loading models...\")\n",
    "        \n",
    "        if MODEL_TRACKING_AVAILABLE and model_registry:\n",
    "            # List all models\n",
    "            all_models = model_registry.list_models()\n",
    "            log_message(f\"Found {len(all_models)} registered models\", 'info')\n",
    "            \n",
    "            if len(all_models) > 0:\n",
    "                update_progress(40, \"Evaluating model performance...\")\n",
    "                \n",
    "                # Get first model for tracking\n",
    "                model_id = all_models[0]['model_id']\n",
    "                model, model_version = model_registry.load_model(model_id)\n",
    "                \n",
    "                # Create tracker\n",
    "                tracker = ModelPerformanceTracker(\n",
    "                    model_id=model_id,\n",
    "                    model_registry=model_registry,\n",
    "                    history_size=10\n",
    "                )\n",
    "                \n",
    "                # Generate test data\n",
    "                test_data = generate_demo_process_data(n_samples=30)\n",
    "                \n",
    "                # Evaluate performance\n",
    "                metrics = tracker.evaluate_model_performance(\n",
    "                    model=model,\n",
    "                    test_data=test_data,\n",
    "                    quality_target='quality'\n",
    "                )\n",
    "                \n",
    "                update_progress(60, \"Calculating drift...\")\n",
    "                \n",
    "                # Calculate drift\n",
    "                training_data = generate_demo_process_data(n_samples=100)\n",
    "                drift_score = tracker.calculate_drift_score(\n",
    "                    test_data[['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']],\n",
    "                    training_data[['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']]\n",
    "                )\n",
    "                \n",
    "                update_progress(80, \"Generating visualizations...\")\n",
    "                \n",
    "                # Get performance trend\n",
    "                trend = tracker.get_performance_trend('r2_score' if 'r2_score' in metrics.performance_metrics else 'mae')\n",
    "                \n",
    "                # Update displays\n",
    "                update_model_performance(metrics.performance_metrics)\n",
    "                update_model_tracking({\n",
    "                    'registered_count': len(all_models),\n",
    "                    'evaluation_count': len(tracker.performance_history),\n",
    "                    'drift_score': drift_score\n",
    "                })\n",
    "                \n",
    "                # Visualize\n",
    "                with main_output:\n",
    "                    clear_output(wait=True)\n",
    "                    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                    \n",
    "                    # Model performance metrics\n",
    "                    perf_metrics = metrics.performance_metrics\n",
    "                    metric_names = list(perf_metrics.keys())[:5]\n",
    "                    metric_values = [perf_metrics[k] for k in metric_names]\n",
    "                    axes[0, 0].bar(metric_names, metric_values)\n",
    "                    axes[0, 0].set_ylabel('Value')\n",
    "                    axes[0, 0].set_title('Model Performance Metrics')\n",
    "                    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "                    axes[0, 0].grid(True)\n",
    "                    \n",
    "                    # Performance history\n",
    "                    history = tracker.get_performance_history()\n",
    "                    if len(history) > 0:\n",
    "                        r2_scores = [h.get('performance_metrics', {}).get('r2_score', 0) for h in history if 'r2_score' in h.get('performance_metrics', {})]\n",
    "                        if r2_scores:\n",
    "                            axes[0, 1].plot(r2_scores, 'b-o', linewidth=2, markersize=8)\n",
    "                            axes[0, 1].set_xlabel('Evaluation')\n",
    "                            axes[0, 1].set_ylabel('R¬≤ Score')\n",
    "                            axes[0, 1].set_title('Performance History')\n",
    "                            axes[0, 1].grid(True)\n",
    "                    \n",
    "                    # Drift score\n",
    "                    axes[1, 0].bar(['Drift Score'], [drift_score], color='orange', alpha=0.7)\n",
    "                    axes[1, 0].axhline(y=drift_threshold.value, color='r', linestyle='--', label=f'Threshold ({drift_threshold.value})')\n",
    "                    axes[1, 0].set_ylabel('Drift Score')\n",
    "                    axes[1, 0].set_title('Data Drift Detection')\n",
    "                    axes[1, 0].legend()\n",
    "                    axes[1, 0].grid(True)\n",
    "                    \n",
    "                    # Performance trend\n",
    "                    if trend.get('trend_available'):\n",
    "                        trend_dir = trend.get('trend_direction', 'unknown')\n",
    "                        axes[1, 1].text(0.5, 0.5, f\"Trend: {trend_dir}\\nSlope: {trend.get('slope', 0):.4f}\",\n",
    "                                       fontsize=14, ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "                        axes[1, 1].set_title('Performance Trend')\n",
    "                    else:\n",
    "                        axes[1, 1].text(0.5, 0.5, \"Insufficient data for trend\",\n",
    "                                       fontsize=12, ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "                        axes[1, 1].set_title('Performance Trend')\n",
    "                    axes[1, 1].axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                update_progress(100, \"Complete!\")\n",
    "                elapsed = time.time() - operation_start_time\n",
    "                update_status(current_operation, \"Complete\", elapsed)\n",
    "                log_message(f\"Model tracking completed in {elapsed:.2f}s\", 'success')\n",
    "            else:\n",
    "                log_message(\"No models registered. Train a model first.\", 'warning')\n",
    "        else:\n",
    "            log_message(\"Model tracking not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in model tracking: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "def execute_complete_workflow():\n",
    "    \"\"\"Execute complete end-to-end workflow.\"\"\"\n",
    "    global current_operation, operation_start_time, is_operation_active\n",
    "    \n",
    "    try:\n",
    "        is_operation_active = True\n",
    "        current_operation = 'Complete Workflow'\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        log_message(\"Starting complete prediction and optimization workflow...\", 'info')\n",
    "        update_progress(5, \"Step 1: Training quality predictor...\")\n",
    "        \n",
    "        # Step 1: Train quality predictor\n",
    "        process_data = generate_demo_process_data(n_samples=200)\n",
    "        feature_names = ['laser_power', 'scan_speed', 'layer_thickness', 'hatch_spacing']\n",
    "        \n",
    "        if QUALITY_AVAILABLE and quality_predictor:\n",
    "            quality_result = quality_predictor.analyze_quality_prediction(\n",
    "                process_data, quality_target='quality', feature_names=feature_names\n",
    "            )\n",
    "            \n",
    "            if quality_result.success:\n",
    "                log_message(\"Step 1 complete: Quality predictor trained\", 'success')\n",
    "                update_progress(20, \"Step 2: Registering model...\")\n",
    "                \n",
    "                # Step 2: Register model\n",
    "                if enable_model_registry.value and MODEL_TRACKING_AVAILABLE and model_registry:\n",
    "                    model_id = model_registry.register_model(\n",
    "                        model=quality_predictor.trained_model,\n",
    "                        model_type='RandomForestRegressor',\n",
    "                        version='1.0',\n",
    "                        metadata={'feature_names': feature_names},\n",
    "                        performance_metrics=quality_result.model_performance\n",
    "                    )\n",
    "                    log_message(f\"Step 2 complete: Model registered ({model_id})\", 'success')\n",
    "                \n",
    "                update_progress(40, \"Step 3: Optimizing parameters...\")\n",
    "                \n",
    "                # Step 3: Optimize\n",
    "                if OPTIMIZATION_AVAILABLE and optimizer:\n",
    "                    def objective_function(params):\n",
    "                        param_df = pd.DataFrame([params])\n",
    "                        quality_pred = quality_predictor.predict_quality(param_df)\n",
    "                        return -quality_pred[0]\n",
    "                    \n",
    "                    parameter_bounds = {\n",
    "                        'laser_power': (200.0, 300.0),\n",
    "                        'scan_speed': (800.0, 1200.0),\n",
    "                        'layer_thickness': (0.02, 0.04),\n",
    "                        'hatch_spacing': (0.08, 0.12)\n",
    "                    }\n",
    "                    \n",
    "                    opt_result = optimizer.optimize_single_objective(\n",
    "                        objective_function,\n",
    "                        parameter_bounds\n",
    "                    )\n",
    "                    \n",
    "                    if opt_result.success:\n",
    "                        log_message(\"Step 3 complete: Optimization completed\", 'success')\n",
    "                        optimization_results['workflow'] = opt_result\n",
    "                        \n",
    "                        update_progress(70, \"Step 4: Validating results...\")\n",
    "                        \n",
    "                        # Step 4: Validate\n",
    "                        if PREDICTION_AVAILABLE and prediction_validator:\n",
    "                            predicted_data = pd.DataFrame([opt_result.optimal_parameters])\n",
    "                            experimental_data = pd.DataFrame({'quality': [0.85]})\n",
    "                            \n",
    "                            validation_result = prediction_validator.validate_with_experimental_data(\n",
    "                                quality_predictor,\n",
    "                                predicted_data,\n",
    "                                experimental_data,\n",
    "                                quality_target='quality'\n",
    "                            )\n",
    "                            \n",
    "                            if validation_result.success:\n",
    "                                log_message(\"Step 4 complete: Validation completed\", 'success')\n",
    "                        \n",
    "                        update_progress(90, \"Generating visualizations...\")\n",
    "                        \n",
    "                        # Visualize complete workflow\n",
    "                        with main_output:\n",
    "                            clear_output(wait=True)\n",
    "                            fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                            \n",
    "                            # Quality predictions\n",
    "                            axes[0, 0].scatter(process_data['quality'].values[:len(quality_result.quality_predictions)], \n",
    "                                             quality_result.quality_predictions, alpha=0.6)\n",
    "                            axes[0, 0].plot([0, 1], [0, 1], 'r--', lw=2)\n",
    "                            axes[0, 0].set_xlabel('Actual Quality')\n",
    "                            axes[0, 0].set_ylabel('Predicted Quality')\n",
    "                            axes[0, 0].set_title('Quality Predictions')\n",
    "                            axes[0, 0].grid(True)\n",
    "                            \n",
    "                            # Optimal parameters\n",
    "                            param_names = list(opt_result.optimal_parameters.keys())\n",
    "                            param_values = list(opt_result.optimal_parameters.values())\n",
    "                            axes[0, 1].bar(param_names, param_values)\n",
    "                            axes[0, 1].set_ylabel('Value')\n",
    "                            axes[0, 1].set_title('Optimal Parameters')\n",
    "                            axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "                            axes[0, 1].grid(True)\n",
    "                            \n",
    "                            # Model performance\n",
    "                            metrics = quality_result.model_performance\n",
    "                            metric_names = list(metrics.keys())[:5]\n",
    "                            metric_values = [metrics[k] for k in metric_names]\n",
    "                            axes[1, 0].bar(metric_names, metric_values)\n",
    "                            axes[1, 0].set_ylabel('Value')\n",
    "                            axes[1, 0].set_title('Model Performance')\n",
    "                            axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "                            axes[1, 0].grid(True)\n",
    "                            \n",
    "                            # Workflow summary\n",
    "                            summary = f\"Models Registered: {len(model_registry._models) if model_registry else 0}<br>\"\n",
    "                            summary += f\"Optimal Quality: {-opt_result.optimal_values:.4f}<br>\"\n",
    "                            summary += f\"Validation Error: {validation_result.validation_error:.4f if 'validation_result' in locals() else 'N/A'}\"\n",
    "                            axes[1, 1].text(0.5, 0.5, summary, fontsize=12, ha='center', va='center',\n",
    "                                          transform=axes[1, 1].transAxes)\n",
    "                            axes[1, 1].set_title('Workflow Summary')\n",
    "                            axes[1, 1].axis('off')\n",
    "                            \n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                        \n",
    "                        update_progress(100, \"Complete!\")\n",
    "                        elapsed = time.time() - operation_start_time\n",
    "                        update_status(current_operation, \"Complete\", elapsed)\n",
    "                        log_message(f\"Complete workflow finished in {elapsed:.2f}s\", 'success')\n",
    "                    else:\n",
    "                        log_message(\"Optimization failed in workflow\", 'error')\n",
    "            else:\n",
    "                log_message(\"Quality prediction failed in workflow\", 'error')\n",
    "        else:\n",
    "            log_message(\"Required components not available\", 'warning')\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in complete workflow: {str(e)}\", 'error')\n",
    "        import traceback\n",
    "        log_message(f\"Traceback: {traceback.format_exc()}\", 'error')\n",
    "    finally:\n",
    "        is_operation_active = False\n",
    "\n",
    "print(\"‚úÖ All execution functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Event handlers attached\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Main Execution Handler\n",
    "# ============================================\n",
    "\n",
    "def on_execute_button_clicked(b):\n",
    "    \"\"\"Handle execute button click.\"\"\"\n",
    "    global is_operation_active\n",
    "    \n",
    "    if is_operation_active:\n",
    "        log_message(\"Operation already in progress. Please wait or stop current operation.\", 'warning')\n",
    "        return\n",
    "    \n",
    "    op_type = operation_type.value\n",
    "    \n",
    "    # Clear previous results\n",
    "    with main_output:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # Route to appropriate execution function\n",
    "    if op_type == 'quality_prediction':\n",
    "        execute_quality_prediction()\n",
    "    elif op_type == 'early_defect':\n",
    "        execute_early_defect_detection()\n",
    "    elif op_type == 'time_series':\n",
    "        execute_time_series_forecasting()\n",
    "    elif op_type == 'optimization_single':\n",
    "        execute_optimization_single()\n",
    "    elif op_type == 'optimization_multi':\n",
    "        execute_optimization_multi()\n",
    "    elif op_type == 'validation':\n",
    "        execute_validation()\n",
    "    elif op_type == 'realtime_optimization':\n",
    "        log_message(\"Real-time optimization not fully implemented in demo\", 'warning')\n",
    "        execute_optimization_single()  # Fallback to single-objective\n",
    "    elif op_type == 'model_tracking':\n",
    "        execute_model_tracking()\n",
    "    elif op_type == 'complete':\n",
    "        execute_complete_workflow()\n",
    "    else:\n",
    "        log_message(f\"Unknown operation type: {op_type}\", 'error')\n",
    "\n",
    "def on_stop_button_clicked(b):\n",
    "    \"\"\"Handle stop button click.\"\"\"\n",
    "    global is_operation_active\n",
    "    is_operation_active = False\n",
    "    log_message(\"Operation stopped by user\", 'warning')\n",
    "    update_progress(0, \"Stopped\")\n",
    "    stop_button.disabled = True\n",
    "    execute_button.disabled = False\n",
    "\n",
    "def on_export_button_clicked(b):\n",
    "    \"\"\"Handle export button click.\"\"\"\n",
    "    try:\n",
    "        export_data = {\n",
    "            'prediction_results': {k: str(v) for k, v in prediction_results.items()},\n",
    "            'optimization_results': {k: str(v) for k, v in optimization_results.items()},\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        export_file = f\"optimization_prediction_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(export_file, 'w') as f:\n",
    "            json.dump(export_data, f, indent=2, default=str)\n",
    "        \n",
    "        log_message(f\"Results exported to {export_file}\", 'success')\n",
    "    except Exception as e:\n",
    "        log_message(f\"Export failed: {e}\", 'error')\n",
    "\n",
    "# Attach event handlers\n",
    "execute_button.on_click(on_execute_button_clicked)\n",
    "stop_button.on_click(on_stop_button_clicked)\n",
    "export_button.on_click(on_export_button_clicked)\n",
    "\n",
    "print(\"‚úÖ Event handlers attached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb99bdedb0645cb9873f51c3cb6ba12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b>Operation Type:</b>'), RadioButtons(description='T‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# Display Complete Interface\n",
    "# ============================================\n",
    "\n",
    "# Main layout: Top, then Left-Center-Right, then Bottom\n",
    "main_layout = VBox([\n",
    "    top_panel,\n",
    "    HBox([\n",
    "        left_panel,\n",
    "        center_panel,\n",
    "        right_panel,\n",
    "    ], layout=Layout(width='100%', height='650px')),\n",
    "    bottom_panel,\n",
    "], layout=Layout(width='100%', padding='10px'))\n",
    "\n",
    "display(main_layout)\n",
    "\n",
    "log_message(\"Interactive Process Optimization and Prediction Interface ready!\", 'success')\n",
    "log_message(\"Select an operation type and click 'Execute Operation' to begin.\", 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
