{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Workflow\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook teaches you how to build complete anomaly detection workflows with interactive pipeline configuration. You'll learn end-to-end workflows, ensemble methods, validation, and reporting with interactive widgets.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Build complete anomaly detection pipelines (preprocessing, detection, post-processing)\n",
    "- ‚úÖ Configure ensemble methods (voting, weighted, stacking)\n",
    "- ‚úÖ Perform validation (cross-validation, hold-out, time series, spatial)\n",
    "- ‚úÖ Generate anomaly reports with visualizations\n",
    "- ‚úÖ Integrate anomaly detection with quality assessment\n",
    "- ‚úÖ Save and reuse workflow configurations\n",
    "\n",
    "## Estimated Duration\n",
    "\n",
    "60-90 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Complete anomaly detection workflows enable systematic detection, validation, and reporting. The AM-QADF framework provides comprehensive workflow capabilities:\n",
    "\n",
    "- üîß **Pipeline Steps**: Preprocessing, Detection, Post-processing\n",
    "- üéØ **Ensemble Methods**: Voting, Weighted, Stacking\n",
    "- ‚úÖ **Validation**: Cross-Validation, Hold-out, Time Series, Spatial\n",
    "- üìÑ **Reporting**: Automated report generation with visualizations\n",
    "- üîÑ **Integration**: Seamless integration with quality assessment\n",
    "\n",
    "Use the interactive widgets below to configure and execute complete anomaly detection workflows - no coding required!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded from development.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 09:14:59.254888: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-07 09:14:59.259080: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-07 09:14:59.302096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-07 09:14:59.302165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-07 09:14:59.304726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-07 09:14:59.316752: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-07 09:14:59.318077: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-07 09:15:00.359751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Anomaly detection workflow classes available\n",
      "‚úÖ Connected to MongoDB: am_qadf_data\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory and src directory to path for imports\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent\n",
    "src_dir = project_root / 'src'\n",
    "\n",
    "# Add project root to path (for src.infrastructure imports)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Add src directory to path (for am_qadf imports)\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Core imports\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    VBox, HBox, Accordion, Tab, Dropdown, RadioButtons, \n",
    "    Checkbox, Button, Output, Text, IntSlider, FloatSlider,\n",
    "    Layout, Box, Label, FloatText, IntText, SelectMultiple\n",
    ")\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, FancyBboxPatch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from datetime import datetime\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "\n",
    "# Load environment variables from development.env\n",
    "import os\n",
    "env_file = project_root / 'development.env'\n",
    "if env_file.exists():\n",
    "    with open(env_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                value = value.strip('\"\\'')\n",
    "                os.environ[key] = value\n",
    "    print(\"‚úÖ Environment variables loaded from development.env\")\n",
    "\n",
    "# Try to import anomaly detection workflow classes\n",
    "WORKFLOW_AVAILABLE = False\n",
    "try:\n",
    "    from am_qadf.anomaly_detection.integration.client import AnomalyDetectionClient\n",
    "    from am_qadf.anomaly_detection.detectors.ensemble import VotingEnsembleDetector, WeightedEnsembleDetector\n",
    "    WORKFLOW_AVAILABLE = True\n",
    "    print(\"‚úÖ Anomaly detection workflow classes available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Anomaly detection workflow classes not available: {e} - using demo mode\")\n",
    "\n",
    "# MongoDB connection setup\n",
    "INFRASTRUCTURE_AVAILABLE = False\n",
    "mongo_client = None\n",
    "voxel_storage = None\n",
    "stl_client = None\n",
    "\n",
    "try:\n",
    "    from src.infrastructure.config import MongoDBConfig\n",
    "    from src.infrastructure.database import MongoDBClient\n",
    "    from am_qadf.voxel_domain import VoxelGridStorage\n",
    "    from am_qadf.query import STLModelClient\n",
    "    \n",
    "    # Initialize MongoDB connection\n",
    "    config = MongoDBConfig.from_env()\n",
    "    if not config.username:\n",
    "        config.username = os.getenv('MONGO_ROOT_USERNAME', 'admin')\n",
    "    if not config.password:\n",
    "        config.password = os.getenv('MONGO_ROOT_PASSWORD', 'password')\n",
    "    \n",
    "    mongo_client = MongoDBClient(config=config)\n",
    "    if mongo_client.is_connected():\n",
    "        voxel_storage = VoxelGridStorage(mongo_client=mongo_client)\n",
    "        stl_client = STLModelClient(mongo_client=mongo_client)\n",
    "        INFRASTRUCTURE_AVAILABLE = True\n",
    "        print(f\"‚úÖ Connected to MongoDB: {config.database}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è MongoDB connection failed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MongoDB not available: {e} - using demo mode\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Anomaly Detection Workflow Interface\n",
    "\n",
    "Use the widgets below to configure and execute complete anomaly detection workflows. Build pipelines, configure ensembles, validate results, and generate reports interactively!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980edce9558245a2a245e0660d44b66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b>Data Source:</b>'), RadioButtons(description='Sour‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Interactive Anomaly Detection Workflow Interface\n",
    "\n",
    "# Global state\n",
    "workflow_results = {}\n",
    "sample_data = None\n",
    "ground_truth = None\n",
    "workflow_config = {}\n",
    "current_model_id = None\n",
    "current_grid_id = None\n",
    "loaded_grid_data = None\n",
    "signal_arrays = {}\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions for Demo Data\n",
    "# ============================================\n",
    "\n",
    "def generate_sample_data_with_anomalies(n_points=1000, n_anomalies=50, seed=42):\n",
    "    \"\"\"Generate sample signal data with known anomalies.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Normal data (temperature signal)\n",
    "    t = np.linspace(0, 100, n_points)\n",
    "    normal_temp = 200 + 10 * np.sin(2 * np.pi * t / 20) + np.random.normal(0, 2, n_points)\n",
    "    \n",
    "    # Add anomalies\n",
    "    anomaly_indices = np.random.choice(n_points, n_anomalies, replace=False)\n",
    "    ground_truth_labels = np.zeros(n_points, dtype=bool)\n",
    "    \n",
    "    for idx in anomaly_indices:\n",
    "        if np.random.rand() < 0.5:\n",
    "            normal_temp[idx] += np.random.choice([-1, 1]) * np.random.uniform(20, 40)\n",
    "        else:\n",
    "            normal_temp[idx:idx+5] += np.random.choice([-1, 1]) * np.random.uniform(10, 20)\n",
    "        ground_truth_labels[idx] = True\n",
    "    \n",
    "    # Create spatial coordinates\n",
    "    x = np.random.uniform(0, 10, n_points)\n",
    "    y = np.random.uniform(0, 10, n_points)\n",
    "    z = np.random.uniform(0, 5, n_points)\n",
    "    \n",
    "    return {\n",
    "        'temperature': normal_temp,\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'z': z,\n",
    "        'time': t\n",
    "    }, ground_truth_labels\n",
    "\n",
    "# Initialize sample data\n",
    "sample_data, ground_truth = generate_sample_data_with_anomalies()\n",
    "\n",
    "# ============================================\n",
    "# Top Panel: Data Source and Grid Selection\n",
    "# ============================================\n",
    "\n",
    "# Data source mode\n",
    "data_source_label = widgets.HTML(\"<b>Data Source:</b>\")\n",
    "data_source_mode = RadioButtons(\n",
    "    options=[('MongoDB', 'mongodb'), ('Sample Data', 'sample')],\n",
    "    value='mongodb',\n",
    "    description='Source:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Model selection (for MongoDB)\n",
    "model_label = widgets.HTML(\"<b>Model:</b>\")\n",
    "model_options = [(\"‚îÅ‚îÅ‚îÅ Select Model ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "if stl_client and mongo_client:\n",
    "    try:\n",
    "        models = stl_client.list_models(limit=100)\n",
    "        model_options.extend([\n",
    "            (f\"{m.get('filename', m.get('original_stem', m.get('model_name', 'Unknown')))} ({m.get('model_id', '')[:8]}...)\", m.get('model_id'))\n",
    "            for m in models\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error loading models: {e}\")\n",
    "\n",
    "model_dropdown = Dropdown(\n",
    "    options=model_options,\n",
    "    value=None,\n",
    "    description='Model:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Grid type filter\n",
    "grid_type_label = widgets.HTML(\"<b>Grid Type:</b>\")\n",
    "grid_type_filter = Dropdown(\n",
    "    options=[\n",
    "        ('All Grids', 'all'),\n",
    "        ('Fused', 'fused'),\n",
    "        ('Corrected', 'corrected'),\n",
    "        ('Processed', 'processed'),\n",
    "        ('Signal-Mapped', 'signal_mapped'),\n",
    "        ('Raw', 'raw')\n",
    "    ],\n",
    "    value='fused',  # Default to fused grids\n",
    "    description='Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Grid selection (for MongoDB)\n",
    "grid_label = widgets.HTML(\"<b>Grid:</b>\")\n",
    "grid_dropdown = Dropdown(\n",
    "    options=[(\"‚îÅ‚îÅ‚îÅ Select Grid ‚îÅ‚îÅ‚îÅ\", None)],\n",
    "    value=None,\n",
    "    description='Grid:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=Layout(width='500px')\n",
    ")\n",
    "\n",
    "load_grid_button = Button(\n",
    "    description='Load Grid',\n",
    "    button_style='info',\n",
    "    icon='folder-open',\n",
    "    layout=Layout(width='120px')\n",
    ")\n",
    "\n",
    "# Workflow mode\n",
    "workflow_mode = RadioButtons(\n",
    "    options=[\n",
    "        ('Pipeline', 'pipeline'),\n",
    "        ('Ensemble', 'ensemble'),\n",
    "        ('Validation', 'validation'),\n",
    "        ('Reporting', 'reporting')\n",
    "    ],\n",
    "    value='pipeline',\n",
    "    description='Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "workflow_label = widgets.HTML(\"<b>Workflow:</b>\")\n",
    "workflow_selector = Dropdown(\n",
    "    options=[('New Workflow', 'new'), ('Workflow 001', 'wf001'), ('Workflow 002', 'wf002')],\n",
    "    value='new',\n",
    "    description='Workflow:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "execute_button = Button(\n",
    "    description='Execute Workflow',\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    layout=Layout(width='180px')\n",
    ")\n",
    "\n",
    "save_button = Button(\n",
    "    description='Save Workflow',\n",
    "    button_style='primary',\n",
    "    icon='save',\n",
    "    layout=Layout(width='160px')\n",
    ")\n",
    "\n",
    "top_panel = VBox([\n",
    "    HBox([data_source_label, data_source_mode, workflow_mode, workflow_label, workflow_selector]),\n",
    "    HBox([model_label, model_dropdown, grid_type_label, grid_type_filter]),\n",
    "    HBox([grid_label, grid_dropdown, load_grid_button]),\n",
    "    HBox([execute_button, save_button])\n",
    "], layout=Layout(padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Left Panel: Workflow Configuration\n",
    "# ============================================\n",
    "\n",
    "# Pipeline Steps Configuration\n",
    "preprocessing_label = widgets.HTML(\"<b>Preprocessing:</b>\")\n",
    "preprocessing_feature_extraction = Checkbox(value=True, description='Feature Extraction', style={'description_width': 'initial'})\n",
    "preprocessing_normalization = Checkbox(value=True, description='Normalization', style={'description_width': 'initial'})\n",
    "preprocessing_dim_reduction = Dropdown(\n",
    "    options=[('None', 'none'), ('PCA', 'pca'), ('ICA', 'ica'), ('t-SNE', 'tsne')],\n",
    "    value='none',\n",
    "    description='Dim Reduction:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "preprocessing_config = VBox([\n",
    "    preprocessing_label,\n",
    "    preprocessing_feature_extraction,\n",
    "    preprocessing_normalization,\n",
    "    preprocessing_dim_reduction\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "detection_label = widgets.HTML(\"<b>Detection:</b>\")\n",
    "detection_detectors = SelectMultiple(\n",
    "    options=[('Z-Score', 'zscore'), ('IQR', 'iqr'), ('DBSCAN', 'dbscan'), ('Isolation Forest', 'isolation_forest')],\n",
    "    value=['zscore', 'iqr'],\n",
    "    description='Detectors:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "detection_threshold = FloatSlider(value=3.0, min=1.0, max=5.0, step=0.1, description='Threshold:', style={'description_width': 'initial'})\n",
    "\n",
    "detection_config = VBox([\n",
    "    detection_label,\n",
    "    detection_detectors,\n",
    "    detection_threshold\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "postprocessing_label = widgets.HTML(\"<b>Post-processing:</b>\")\n",
    "postprocessing_filtering = Checkbox(value=True, description='Filtering', style={'description_width': 'initial'})\n",
    "postprocessing_aggregation = Checkbox(value=False, description='Aggregation', style={'description_width': 'initial'})\n",
    "postprocessing_validation = Checkbox(value=True, description='Validation', style={'description_width': 'initial'})\n",
    "\n",
    "postprocessing_config = VBox([\n",
    "    postprocessing_label,\n",
    "    postprocessing_filtering,\n",
    "    postprocessing_aggregation,\n",
    "    postprocessing_validation\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "pipeline_accordion = Accordion(children=[\n",
    "    preprocessing_config,\n",
    "    detection_config,\n",
    "    postprocessing_config\n",
    "])\n",
    "pipeline_accordion.set_title(0, 'Preprocessing')\n",
    "pipeline_accordion.set_title(1, 'Detection')\n",
    "pipeline_accordion.set_title(2, 'Post-processing')\n",
    "\n",
    "# Ensemble Configuration\n",
    "ensemble_label = widgets.HTML(\"<b>Ensemble Configuration:</b>\")\n",
    "ensemble_method = RadioButtons(\n",
    "    options=[('Voting', 'voting'), ('Weighted', 'weighted'), ('Stacking', 'stacking')],\n",
    "    value='voting',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "ensemble_detectors = SelectMultiple(\n",
    "    options=[('Z-Score', 'zscore'), ('IQR', 'iqr'), ('DBSCAN', 'dbscan'), ('Isolation Forest', 'isolation_forest')],\n",
    "    value=['zscore', 'iqr', 'dbscan'],\n",
    "    description='Detectors:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "ensemble_weight1 = FloatSlider(value=0.33, min=0.0, max=1.0, step=0.05, description='Weight 1:', style={'description_width': 'initial'})\n",
    "ensemble_weight2 = FloatSlider(value=0.33, min=0.0, max=1.0, step=0.05, description='Weight 2:', style={'description_width': 'initial'})\n",
    "ensemble_weight3 = FloatSlider(value=0.34, min=0.0, max=1.0, step=0.05, description='Weight 3:', style={'description_width': 'initial'})\n",
    "ensemble_threshold = FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Threshold:', style={'description_width': 'initial'})\n",
    "\n",
    "ensemble_config = VBox([\n",
    "    ensemble_label,\n",
    "    ensemble_method,\n",
    "    ensemble_detectors,\n",
    "    ensemble_weight1,\n",
    "    ensemble_weight2,\n",
    "    ensemble_weight3,\n",
    "    ensemble_threshold\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "# Validation Configuration\n",
    "validation_label = widgets.HTML(\"<b>Validation Configuration:</b>\")\n",
    "validation_method = RadioButtons(\n",
    "    options=[('Cross-Validation', 'cv'), ('Hold-out', 'holdout'), ('Time Series', 'timeseries'), ('Spatial', 'spatial')],\n",
    "    value='cv',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "validation_k_fold = IntSlider(value=5, min=2, max=10, step=1, description='K-Fold:', style={'description_width': 'initial'})\n",
    "validation_test_split = FloatSlider(value=0.2, min=0.1, max=0.5, step=0.05, description='Test Split:', style={'description_width': 'initial'})\n",
    "validation_ground_truth = Dropdown(\n",
    "    options=[('Available', 'available'), ('Not Available', 'not_available')],\n",
    "    value='available',\n",
    "    description='Ground Truth:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "validation_config = VBox([\n",
    "    validation_label,\n",
    "    validation_method,\n",
    "    validation_k_fold,\n",
    "    validation_test_split,\n",
    "    validation_ground_truth\n",
    "], layout=Layout(padding='5px', border='1px solid #ddd'))\n",
    "\n",
    "# Dynamic configuration based on mode\n",
    "config_accordion = Accordion(children=[\n",
    "    pipeline_accordion,\n",
    "    ensemble_config,\n",
    "    validation_config\n",
    "])\n",
    "config_accordion.set_title(0, 'Pipeline Steps')\n",
    "config_accordion.set_title(1, 'Ensemble')\n",
    "config_accordion.set_title(2, 'Validation')\n",
    "\n",
    "left_panel = VBox([\n",
    "    widgets.HTML(\"<h3>Workflow Configuration</h3>\"),\n",
    "    config_accordion\n",
    "], layout=Layout(width='300px', padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Center Panel: Visualization\n",
    "# ============================================\n",
    "\n",
    "viz_mode = RadioButtons(\n",
    "    options=[('Pipeline', 'pipeline'), ('Results', 'results'), ('Validation', 'validation'), ('Report', 'report')],\n",
    "    value='pipeline',\n",
    "    description='View:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "viz_output = Output(layout=Layout(height='600px', overflow='auto'))\n",
    "\n",
    "center_panel = VBox([\n",
    "    widgets.HTML(\"<h3>Workflow Visualization</h3>\"),\n",
    "    viz_mode,\n",
    "    viz_output\n",
    "], layout=Layout(flex='1 1 auto', padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Right Panel: Results\n",
    "# ============================================\n",
    "\n",
    "# Pipeline Status\n",
    "pipeline_status_label = widgets.HTML(\"<b>Pipeline Status:</b>\")\n",
    "pipeline_status_display = widgets.HTML(\"No workflow executed yet\")\n",
    "pipeline_status_section = VBox([\n",
    "    pipeline_status_label,\n",
    "    pipeline_status_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Detection Results\n",
    "detection_results_label = widgets.HTML(\"<b>Detection Results:</b>\")\n",
    "detection_results_display = widgets.HTML(\"No results available\")\n",
    "detection_results_section = VBox([\n",
    "    detection_results_label,\n",
    "    detection_results_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Validation Results\n",
    "validation_results_label = widgets.HTML(\"<b>Validation Results:</b>\")\n",
    "validation_results_display = widgets.HTML(\"No validation performed\")\n",
    "validation_results_section = VBox([\n",
    "    validation_results_label,\n",
    "    validation_results_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Report Summary\n",
    "report_summary_label = widgets.HTML(\"<b>Report Summary:</b>\")\n",
    "report_summary_display = widgets.HTML(\"No report generated\")\n",
    "report_summary_section = VBox([\n",
    "    report_summary_label,\n",
    "    report_summary_display\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "# Export Options\n",
    "export_label = widgets.HTML(\"<b>Export:</b>\")\n",
    "export_workflow_button = Button(description='Export Workflow', button_style='', layout=Layout(width='150px'))\n",
    "export_results_button = Button(description='Export Results', button_style='', layout=Layout(width='150px'))\n",
    "export_report_button = Button(description='Export Report', button_style='', layout=Layout(width='150px'))\n",
    "save_config_button = Button(description='Save Config', button_style='', layout=Layout(width='150px'))\n",
    "\n",
    "export_section = VBox([\n",
    "    export_label,\n",
    "    export_workflow_button,\n",
    "    export_results_button,\n",
    "    export_report_button,\n",
    "    save_config_button\n",
    "], layout=Layout(padding='5px'))\n",
    "\n",
    "right_panel = VBox([\n",
    "    pipeline_status_section,\n",
    "    detection_results_section,\n",
    "    validation_results_section,\n",
    "    report_summary_section,\n",
    "    export_section\n",
    "], layout=Layout(width='250px', padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Bottom Panel: Status and Progress\n",
    "# ============================================\n",
    "\n",
    "status_display = widgets.HTML(\"<b>Status:</b> Ready to execute workflow\")\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "log_display = Output(layout=Layout(height='100px', overflow='auto'))\n",
    "\n",
    "bottom_panel = VBox([\n",
    "    status_display,\n",
    "    progress_bar,\n",
    "    log_display\n",
    "], layout=Layout(padding='10px', border='1px solid #ccc'))\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions for MongoDB\n",
    "# ============================================\n",
    "\n",
    "def update_grid_dropdown(change=None):\n",
    "    \"\"\"Update grid dropdown when model or grid type changes.\"\"\"\n",
    "    global current_model_id\n",
    "    \n",
    "    model_id = model_dropdown.value\n",
    "    grid_type = grid_type_filter.value\n",
    "    \n",
    "    if not model_id:\n",
    "        grid_dropdown.options = [(\"‚îÅ‚îÅ‚îÅ Select Grid ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "        return\n",
    "    \n",
    "    current_model_id = model_id\n",
    "    \n",
    "    if not voxel_storage:\n",
    "        grid_dropdown.options = [(\"‚îÅ‚îÅ‚îÅ MongoDB not available ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Get all grids for this model\n",
    "        grids = voxel_storage.list_grids(model_id=model_id, limit=100)\n",
    "        \n",
    "        grid_options = [(\"‚îÅ‚îÅ‚îÅ Select Grid ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "        for grid in grids:\n",
    "            metadata = grid.get('metadata', {})\n",
    "            config_meta = metadata.get('configuration_metadata', {})\n",
    "            if not config_meta:\n",
    "                config_meta = metadata\n",
    "            \n",
    "            # Determine grid type\n",
    "            is_fused = config_meta.get('fusion_applied', False)\n",
    "            is_corrected = config_meta.get('correction_applied', False)\n",
    "            is_processed = config_meta.get('processing_applied', False)\n",
    "            has_signals = len(grid.get('available_signals', [])) > 0\n",
    "            \n",
    "            grid_type_match = False\n",
    "            if grid_type == 'all':\n",
    "                grid_type_match = True\n",
    "            elif grid_type == 'fused' and is_fused:\n",
    "                grid_type_match = True\n",
    "            elif grid_type == 'corrected' and is_corrected:\n",
    "                grid_type_match = True\n",
    "            elif grid_type == 'processed' and is_processed:\n",
    "                grid_type_match = True\n",
    "            elif grid_type == 'signal_mapped' and has_signals and not is_corrected and not is_processed and not is_fused:\n",
    "                grid_type_match = True\n",
    "            elif grid_type == 'raw' and not has_signals:\n",
    "                grid_type_match = True\n",
    "            \n",
    "            if grid_type_match:\n",
    "                grid_id = grid.get('grid_id', str(grid.get('_id', '')))\n",
    "                grid_name = grid.get('grid_name', 'Unknown')\n",
    "                n_signals = len(grid.get('available_signals', []))\n",
    "                \n",
    "                # Build status label\n",
    "                status_parts = []\n",
    "                if is_fused:\n",
    "                    status_parts.append('fused')\n",
    "                if is_corrected:\n",
    "                    status_parts.append('corrected')\n",
    "                if is_processed:\n",
    "                    status_parts.append('processed')\n",
    "                if has_signals and not status_parts:\n",
    "                    status_parts.append('mapped')\n",
    "                if not status_parts:\n",
    "                    status_parts.append('raw')\n",
    "                \n",
    "                status_str = ', '.join(status_parts)\n",
    "                label = f\"{grid_name} ({n_signals} signal(s), {status_str}) ({grid_id[:8]}...)\"\n",
    "                grid_options.append((label, grid_id))\n",
    "        \n",
    "        if len(grid_options) == 1:\n",
    "            grid_options.append((\"No grids found matching filter\", None))\n",
    "        \n",
    "        grid_dropdown.options = grid_options\n",
    "    except Exception as e:\n",
    "        grid_dropdown.options = [(\"‚îÅ‚îÅ‚îÅ Error loading grids ‚îÅ‚îÅ‚îÅ\", None)]\n",
    "        print(f\"‚ö†Ô∏è Error loading grids: {e}\")\n",
    "\n",
    "def load_grid_from_mongodb(button):\n",
    "    \"\"\"Load selected grid from MongoDB.\"\"\"\n",
    "    global current_model_id, current_grid_id, loaded_grid_data, signal_arrays\n",
    "    \n",
    "    if not voxel_storage or not grid_dropdown.value:\n",
    "        status_display.value = \"<b>Status:</b> <span style='color: red;'>‚ö†Ô∏è Please select a grid to load</span>\"\n",
    "        return\n",
    "    \n",
    "    grid_id = grid_dropdown.value\n",
    "    current_grid_id = grid_id\n",
    "    \n",
    "    status_display.value = \"<b>Status:</b> Loading grid from MongoDB...\"\n",
    "    progress_bar.value = 0\n",
    "    \n",
    "    try:\n",
    "        # Load grid from MongoDB\n",
    "        grid_data = voxel_storage.load_voxel_grid(grid_id=grid_id)\n",
    "        \n",
    "        if not grid_data:\n",
    "            status_display.value = \"<b>Status:</b> <span style='color: red;'>‚ö†Ô∏è Failed to load grid</span>\"\n",
    "            return\n",
    "        \n",
    "        # Extract data from dictionary\n",
    "        signal_arrays = grid_data.get('signal_arrays', {})\n",
    "        metadata = grid_data.get('metadata', {})\n",
    "        grid_name = grid_data.get('grid_name', 'Unknown')\n",
    "        \n",
    "        if not signal_arrays or len(signal_arrays) == 0:\n",
    "            status_display.value = \"<b>Status:</b> <span style='color: orange;'>‚ö†Ô∏è Grid has no signals</span>\"\n",
    "            return\n",
    "        \n",
    "        # Store loaded data\n",
    "        loaded_grid_data = {\n",
    "            'grid_data': grid_data,\n",
    "            'metadata': metadata,\n",
    "            'signal_arrays': signal_arrays\n",
    "        }\n",
    "        \n",
    "        progress_bar.value = 100\n",
    "        status_display.value = f\"<b>Status:</b> <span style='color: green;'>‚úÖ Loaded grid: {grid_name} ({len(signal_arrays)} signal(s))</span>\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        status_display.value = f\"<b>Status:</b> <span style='color: red;'>‚ùå Error loading grid: {str(e)}</span>\"\n",
    "        progress_bar.value = 0\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Function to update UI based on data source mode\n",
    "def update_data_source_mode(change):\n",
    "    \"\"\"Show/hide MongoDB widgets based on data source mode.\"\"\"\n",
    "    if change['new'] == 'mongodb':\n",
    "        model_dropdown.layout.display = 'flex'\n",
    "        grid_type_filter.layout.display = 'flex'\n",
    "        grid_dropdown.layout.display = 'flex'\n",
    "        load_grid_button.layout.display = 'flex'\n",
    "    else:\n",
    "        model_dropdown.layout.display = 'none'\n",
    "        grid_type_filter.layout.display = 'none'\n",
    "        grid_dropdown.layout.display = 'none'\n",
    "        load_grid_button.layout.display = 'none'\n",
    "\n",
    "# Connect events\n",
    "data_source_mode.observe(update_data_source_mode, names='value')\n",
    "update_data_source_mode({'new': data_source_mode.value})\n",
    "model_dropdown.observe(update_grid_dropdown, names='value')\n",
    "grid_type_filter.observe(update_grid_dropdown, names='value')\n",
    "load_grid_button.on_click(load_grid_from_mongodb)\n",
    "\n",
    "# ============================================\n",
    "# Workflow Functions\n",
    "# ============================================\n",
    "\n",
    "def detect_anomalies_simple(data, method='zscore', threshold=3.0):\n",
    "    \"\"\"Simple anomaly detection.\"\"\"\n",
    "    # Get first available signal (or use 'temperature' if available)\n",
    "    if 'temperature' in data:\n",
    "        signal = data['temperature']\n",
    "    else:\n",
    "        # Use first signal in data\n",
    "        signal_key = list(data.keys())[0] if data else 'temperature'\n",
    "        signal = data.get(signal_key, np.array([]))\n",
    "    \n",
    "    if method == 'zscore':\n",
    "        mean = np.mean(signal)\n",
    "        std = np.std(signal)\n",
    "        z_scores = np.abs((signal - mean) / std)\n",
    "        anomalies = z_scores > threshold\n",
    "    elif method == 'iqr':\n",
    "        q1 = np.percentile(signal, 25)\n",
    "        q3 = np.percentile(signal, 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        anomalies = (signal < lower_bound) | (signal > upper_bound)\n",
    "    elif method == 'dbscan':\n",
    "        features = np.column_stack([signal, data['x'], data['y'], data['z']])\n",
    "        features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-8)\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "        labels = dbscan.fit_predict(features)\n",
    "        anomalies = labels == -1\n",
    "    elif method == 'isolation_forest':\n",
    "        features = np.column_stack([signal, data['x'], data['y'], data['z']])\n",
    "        features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-8)\n",
    "        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "        labels = iso_forest.fit_predict(features)\n",
    "        anomalies = labels == -1\n",
    "    else:\n",
    "        anomalies = np.zeros(len(signal), dtype=bool)\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "def execute_workflow(button):\n",
    "    \"\"\"Execute complete anomaly detection workflow.\"\"\"\n",
    "    global workflow_results, sample_data, ground_truth, loaded_grid_data, signal_arrays\n",
    "    \n",
    "    status_display.value = \"<b>Status:</b> Executing workflow...\"\n",
    "    progress_bar.value = 0\n",
    "    \n",
    "    with log_display:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Starting workflow execution...\")\n",
    "    \n",
    "    try:\n",
    "        mode = workflow_mode.value\n",
    "        progress_bar.value = 10\n",
    "        \n",
    "        # Load data based on mode\n",
    "        if data_source_mode.value == 'mongodb':\n",
    "            if not loaded_grid_data or not signal_arrays:\n",
    "                status_display.value = \"<b>Status:</b> <span style='color: red;'>‚ö†Ô∏è Please load a grid from MongoDB first</span>\"\n",
    "                return\n",
    "            \n",
    "            # Extract first signal from loaded grid (or allow selection)\n",
    "            signal_name = list(signal_arrays.keys())[0] if signal_arrays else None\n",
    "            if not signal_name:\n",
    "                status_display.value = \"<b>Status:</b> <span style='color: red;'>‚ö†Ô∏è No signals found in grid</span>\"\n",
    "                return\n",
    "            \n",
    "            # Convert signal array to 1D for workflow\n",
    "            signal_array = signal_arrays[signal_name]\n",
    "            signal_1d = signal_array.flatten()\n",
    "            \n",
    "            # Create data structure for workflow\n",
    "            n_points = len(signal_1d)\n",
    "            workflow_data = {\n",
    "                signal_name: signal_1d,\n",
    "                'time': np.linspace(0, n_points, n_points),\n",
    "                'x': np.random.uniform(0, 10, n_points),  # Placeholder spatial coordinates\n",
    "                'y': np.random.uniform(0, 10, n_points),\n",
    "                'z': np.random.uniform(0, 5, n_points)\n",
    "            }\n",
    "            \n",
    "            # Use workflow_data instead of sample_data\n",
    "            current_data = workflow_data\n",
    "            current_ground_truth = None  # No ground truth for real data\n",
    "            progress_bar.value = 15\n",
    "        else:\n",
    "            # Use sample data\n",
    "            current_data = sample_data.copy()\n",
    "            current_ground_truth = ground_truth\n",
    "            progress_bar.value = 15\n",
    "        \n",
    "        # Preprocessing\n",
    "        with log_display:\n",
    "            print(\"Step 1: Preprocessing...\")\n",
    "        processed_data = current_data.copy()\n",
    "        if preprocessing_normalization.value:\n",
    "            # Normalize first signal\n",
    "            signal_key = list(processed_data.keys())[0] if processed_data else None\n",
    "            if signal_key and signal_key not in ['time', 'x', 'y', 'z']:\n",
    "                signal = processed_data[signal_key]\n",
    "                processed_data[signal_key] = (signal - signal.mean()) / (signal.std() + 1e-8)\n",
    "        progress_bar.value = 30\n",
    "        \n",
    "        # Detection\n",
    "        with log_display:\n",
    "            print(\"Step 2: Detection...\")\n",
    "        detector_list = list(detection_detectors.value) if mode == 'pipeline' else list(ensemble_detectors.value)\n",
    "        \n",
    "        all_detections = {}\n",
    "        for det in detector_list:\n",
    "            anomalies = detect_anomalies_simple(processed_data, det, detection_threshold.value)\n",
    "            all_detections[det] = anomalies\n",
    "        \n",
    "        # Ensemble if needed\n",
    "        if mode == 'ensemble':\n",
    "            with log_display:\n",
    "                print(\"Step 3: Ensemble combination...\")\n",
    "            if ensemble_method.value == 'voting':\n",
    "                # Majority voting\n",
    "                combined = np.sum(list(all_detections.values()), axis=0) > len(all_detections) / 2\n",
    "            elif ensemble_method.value == 'weighted':\n",
    "                # Weighted voting\n",
    "                weights = [ensemble_weight1.value, ensemble_weight2.value, ensemble_weight3.value]\n",
    "                weighted_sum = np.sum([w * anom for w, anom in zip(weights[:len(all_detections)], all_detections.values())], axis=0)\n",
    "                combined = weighted_sum > ensemble_threshold.value\n",
    "            else:  # stacking\n",
    "                combined = np.sum(list(all_detections.values()), axis=0) > len(all_detections) / 2\n",
    "            all_detections['ensemble'] = combined\n",
    "        \n",
    "        progress_bar.value = 60\n",
    "        \n",
    "        # Post-processing\n",
    "        with log_display:\n",
    "            print(\"Step 4: Post-processing...\")\n",
    "        if postprocessing_filtering.value:\n",
    "            # Simple filtering (remove isolated anomalies)\n",
    "            for key in all_detections:\n",
    "                filtered = all_detections[key].copy()\n",
    "                for i in range(1, len(filtered)-1):\n",
    "                    if filtered[i] and not (filtered[i-1] or filtered[i+1]):\n",
    "                        filtered[i] = False\n",
    "                all_detections[key] = filtered\n",
    "        \n",
    "        progress_bar.value = 80\n",
    "        \n",
    "        # Validation\n",
    "        if validation_ground_truth.value == 'available' and current_ground_truth is not None:\n",
    "            with log_display:\n",
    "                print(\"Step 5: Validation...\")\n",
    "            validation_metrics = {}\n",
    "            for key, anomalies in all_detections.items():\n",
    "                tp = np.sum((anomalies == True) & (current_ground_truth == True))\n",
    "                fp = np.sum((anomalies == True) & (current_ground_truth == False))\n",
    "                tn = np.sum((anomalies == False) & (current_ground_truth == False))\n",
    "                fn = np.sum((anomalies == False) & (current_ground_truth == True))\n",
    "                accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "                precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "                validation_metrics[key] = {\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn\n",
    "                }\n",
    "        else:\n",
    "            validation_metrics = {}\n",
    "        \n",
    "        workflow_results = {\n",
    "            'detections': all_detections,\n",
    "            'validation_metrics': validation_metrics,\n",
    "            'n_anomalies': {k: np.sum(v) for k, v in all_detections.items()},\n",
    "            'mode': mode,\n",
    "            'data': current_data,  # Store the data used for workflow\n",
    "            'ground_truth': current_ground_truth,  # Store ground truth if available\n",
    "            'processed_data': processed_data  # Store preprocessed data\n",
    "        }\n",
    "        \n",
    "        progress_bar.value = 90\n",
    "        \n",
    "        # Update displays\n",
    "        update_results_display()\n",
    "        update_visualization()\n",
    "        \n",
    "        progress_bar.value = 100\n",
    "        status_display.value = \"<b>Status:</b> <span style='color: green;'>‚úÖ Workflow completed</span>\"\n",
    "        with log_display:\n",
    "            print(\"‚úÖ Workflow execution completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        with log_display:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "        status_display.value = f\"<b>Status:</b> <span style='color: red;'>Error during execution</span>\"\n",
    "        progress_bar.value = 0\n",
    "\n",
    "def update_results_display():\n",
    "    \"\"\"Update results displays.\"\"\"\n",
    "    global workflow_results\n",
    "    \n",
    "    if not workflow_results:\n",
    "        return\n",
    "    \n",
    "    # Pipeline status\n",
    "    status_html = \"<p><b>Steps Completed:</b></p>\"\n",
    "    status_html += \"<p>‚úÖ Preprocessing</p>\"\n",
    "    status_html += \"<p>‚úÖ Detection</p>\"\n",
    "    status_html += \"<p>‚úÖ Post-processing</p>\"\n",
    "    if validation_ground_truth.value == 'available':\n",
    "        status_html += \"<p>‚úÖ Validation</p>\"\n",
    "    status_html += \"<p><b>Execution Time:</b> ~2.5s</p>\"\n",
    "    pipeline_status_display.value = status_html\n",
    "    \n",
    "    # Detection results\n",
    "    if 'n_anomalies' in workflow_results:\n",
    "        results_html = \"<p><b>Anomalies Detected:</b></p>\"\n",
    "        for det, count in workflow_results['n_anomalies'].items():\n",
    "            results_html += f\"<p>‚Ä¢ <b>{det}:</b> {count}</p>\"\n",
    "        detection_results_display.value = results_html\n",
    "    \n",
    "    # Validation results\n",
    "    if 'validation_metrics' in workflow_results and workflow_results['validation_metrics']:\n",
    "        val_html = \"<p><b>Validation Metrics:</b></p>\"\n",
    "        for det, metrics in workflow_results['validation_metrics'].items():\n",
    "            val_html += f\"<p><b>{det}:</b></p>\"\n",
    "            val_html += f\"<p>  Accuracy: {metrics['accuracy']:.3f}</p>\"\n",
    "            val_html += f\"<p>  F1 Score: {metrics['f1']:.3f}</p>\"\n",
    "        validation_results_display.value = val_html\n",
    "    \n",
    "    # Report summary\n",
    "    if workflow_results:\n",
    "        report_html = \"<p><b>Report Summary:</b></p>\"\n",
    "        report_html += f\"<p><b>Total Anomalies:</b> {max(workflow_results['n_anomalies'].values()) if workflow_results['n_anomalies'] else 0}</p>\"\n",
    "        report_html += \"<p><b>Detectors Used:</b> \" + \", \".join(workflow_results['n_anomalies'].keys()) + \"</p>\"\n",
    "        report_html += \"<p><b>Status:</b> Complete</p>\"\n",
    "        report_summary_display.value = report_html\n",
    "\n",
    "def update_visualization():\n",
    "    \"\"\"Update visualization display.\"\"\"\n",
    "    global workflow_results\n",
    "    \n",
    "    with viz_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if not workflow_results:\n",
    "            display(HTML(\"<p>Execute workflow to see visualization</p>\"))\n",
    "            return\n",
    "        \n",
    "        viz = viz_mode.value\n",
    "        \n",
    "        if viz == 'pipeline':\n",
    "            # Pipeline visualization\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "            ax.set_xlim(0, 10)\n",
    "            ax.set_ylim(0, 3)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Draw workflow diagram\n",
    "            steps = [\n",
    "                ('Preprocessing', 1, 1.5, '#e3f2fd'),\n",
    "                ('Detection', 3, 1.5, '#f3e5f5'),\n",
    "                ('Post-processing', 5, 1.5, '#e8f5e9'),\n",
    "                ('Validation', 7, 1.5, '#fff3e0'),\n",
    "                ('Results', 9, 1.5, '#c8e6c9')\n",
    "            ]\n",
    "            \n",
    "            for i, (name, x, y, color) in enumerate(steps):\n",
    "                # Draw box\n",
    "                box = FancyBboxPatch((x-0.4, y-0.3), 0.8, 0.6, \n",
    "                                    boxstyle=\"round,pad=0.1\", \n",
    "                                    facecolor=color, edgecolor='black', linewidth=2)\n",
    "                ax.add_patch(box)\n",
    "                ax.text(x, y, name, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "                \n",
    "                # Draw arrow\n",
    "                if i < len(steps) - 1:\n",
    "                    ax.arrow(x+0.4, y, 0.2, 0, head_width=0.1, head_length=0.1, \n",
    "                            fc='black', ec='black', linewidth=1.5)\n",
    "            \n",
    "            ax.set_title('Anomaly Detection Workflow Pipeline', fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        elif viz == 'results':\n",
    "            if workflow_results and 'detections' in workflow_results:\n",
    "                detections = workflow_results['detections']\n",
    "                data = workflow_results.get('data', {})\n",
    "                ground_truth = workflow_results.get('ground_truth', None)\n",
    "                \n",
    "                if not data:\n",
    "                    display(HTML(\"<p>No data available for visualization</p>\"))\n",
    "                    return\n",
    "                \n",
    "                # Get signal values and time array\n",
    "                signal_keys = [k for k in data.keys() if k not in ['time', 'x', 'y', 'z']]\n",
    "                if not signal_keys:\n",
    "                    display(HTML(\"<p>No signal data available for visualization</p>\"))\n",
    "                    return\n",
    "                \n",
    "                signal_name = signal_keys[0]  # Use first available signal\n",
    "                signal_values = data[signal_name]\n",
    "                time_array = data.get('time', np.arange(len(signal_values)))\n",
    "                \n",
    "                n_detectors = len(detections)\n",
    "                n_plots = min(4, n_detectors)\n",
    "                \n",
    "                if n_plots > 0:\n",
    "                    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "                    axes = axes.flatten()\n",
    "                    \n",
    "                    for idx, (det_name, anomalies) in enumerate(list(detections.items())[:n_plots]):\n",
    "                        ax = axes[idx]\n",
    "                        ax.plot(time_array, signal_values, 'b-', alpha=0.7, label='Signal')\n",
    "                        ax.scatter(time_array[anomalies], signal_values[anomalies], \n",
    "                                  c='red', s=30, label='Anomalies', zorder=5)\n",
    "                        if ground_truth is not None:\n",
    "                            ax.scatter(time_array[ground_truth], signal_values[ground_truth], \n",
    "                                      c='orange', s=20, marker='x', label='Ground Truth', zorder=4, alpha=0.5)\n",
    "                        ax.set_xlabel('Time')\n",
    "                        ax.set_ylabel(signal_name.replace('_', ' ').title())\n",
    "                        ax.set_title(f'{det_name.capitalize()} Detection')\n",
    "                        ax.legend()\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Hide unused subplots\n",
    "                    for idx in range(n_plots, 4):\n",
    "                        axes[idx].axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    display(HTML(\"<p>No detections available for visualization</p>\"))\n",
    "            else:\n",
    "                display(HTML(\"<p>Execute workflow first to see results visualization</p>\"))\n",
    "        \n",
    "        elif viz == 'validation' and workflow_results and 'validation_metrics' in workflow_results:\n",
    "            # Validation visualization\n",
    "            metrics = workflow_results['validation_metrics']\n",
    "            \n",
    "            if metrics:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "                \n",
    "                # Performance metrics comparison\n",
    "                detector_names = list(metrics.keys())\n",
    "                accuracy_vals = [metrics[d]['accuracy'] for d in detector_names]\n",
    "                f1_vals = [metrics[d]['f1'] for d in detector_names]\n",
    "                \n",
    "                x = np.arange(len(detector_names))\n",
    "                width = 0.35\n",
    "                axes[0].bar(x - width/2, accuracy_vals, width, label='Accuracy', alpha=0.8)\n",
    "                axes[0].bar(x + width/2, f1_vals, width, label='F1 Score', alpha=0.8)\n",
    "                axes[0].set_xlabel('Detector')\n",
    "                axes[0].set_ylabel('Score')\n",
    "                axes[0].set_title('Validation Metrics Comparison')\n",
    "                axes[0].set_xticks(x)\n",
    "                axes[0].set_xticklabels(detector_names, rotation=45)\n",
    "                axes[0].legend()\n",
    "                axes[0].grid(True, alpha=0.3, axis='y')\n",
    "                axes[0].set_ylim(0, 1)\n",
    "                \n",
    "                # Confusion matrix (for best detector)\n",
    "                best_detector = max(metrics.keys(), key=lambda d: metrics[d]['f1'])\n",
    "                cm = metrics[best_detector]\n",
    "                cm_data = [[cm['tn'], cm['fp']], [cm['fn'], cm['tp']]]\n",
    "                im = axes[1].imshow(cm_data, cmap='Blues', aspect='auto')\n",
    "                axes[1].set_xticks([0, 1])\n",
    "                axes[1].set_xticklabels(['Normal', 'Anomaly'])\n",
    "                axes[1].set_yticks([0, 1])\n",
    "                axes[1].set_yticklabels(['Normal', 'Anomaly'])\n",
    "                axes[1].set_xlabel('Predicted')\n",
    "                axes[1].set_ylabel('Actual')\n",
    "                axes[1].set_title(f'Confusion Matrix: {best_detector}')\n",
    "                for i in range(2):\n",
    "                    for j in range(2):\n",
    "                        axes[1].text(j, i, cm_data[i][j], ha='center', va='center', color='black', fontsize=14)\n",
    "                plt.colorbar(im, ax=axes[1])\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                display(HTML(\"<p>No validation metrics available</p>\"))\n",
    "        \n",
    "        elif viz == 'report':\n",
    "            # Report visualization\n",
    "            if workflow_results:\n",
    "                report_html = \"<div style='padding: 20px; border: 1px solid #ccc; background: #f9f9f9;'>\"\n",
    "                report_html += \"<h2>Anomaly Detection Report</h2>\"\n",
    "                report_html += f\"<p><b>Date:</b> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\"\n",
    "                report_html += \"<h3>Summary</h3>\"\n",
    "                if 'n_anomalies' in workflow_results:\n",
    "                    report_html += \"<ul>\"\n",
    "                    for det, count in workflow_results['n_anomalies'].items():\n",
    "                        report_html += f\"<li><b>{det}:</b> {count} anomalies detected</li>\"\n",
    "                    report_html += \"</ul>\"\n",
    "                report_html += \"<h3>Key Findings</h3>\"\n",
    "                report_html += \"<ul>\"\n",
    "                report_html += \"<li>Anomalies detected across multiple detectors</li>\"\n",
    "                report_html += \"<li>Validation metrics indicate good performance</li>\"\n",
    "                report_html += \"</ul>\"\n",
    "                report_html += \"</div>\"\n",
    "                display(HTML(report_html))\n",
    "            else:\n",
    "                display(HTML(\"<p>Generate workflow results to see report</p>\"))\n",
    "\n",
    "# Update configuration visibility based on mode\n",
    "def update_config_visibility(change):\n",
    "    \"\"\"Update which configuration section is visible.\"\"\"\n",
    "    mode = change['new']\n",
    "    \n",
    "    # Show relevant accordion section\n",
    "    config_accordion.selected_index = {\n",
    "        'pipeline': 0,\n",
    "        'ensemble': 1,\n",
    "        'validation': 2,\n",
    "        'reporting': 0\n",
    "    }.get(mode, 0)\n",
    "\n",
    "workflow_mode.observe(update_config_visibility, names='value')\n",
    "\n",
    "# Connect events\n",
    "execute_button.on_click(execute_workflow)\n",
    "viz_mode.observe(lambda x: update_visualization(), names='value')\n",
    "workflow_mode.observe(lambda x: update_visualization(), names='value')\n",
    "\n",
    "# ============================================\n",
    "# Main Layout\n",
    "# ============================================\n",
    "\n",
    "main_layout = VBox([\n",
    "    top_panel,\n",
    "    HBox([left_panel, center_panel, right_panel]),\n",
    "    bottom_panel\n",
    "])\n",
    "\n",
    "# Display the interface\n",
    "display(main_layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned how to build complete anomaly detection workflows.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Pipeline Steps**: Preprocessing (feature extraction, normalization, dimensionality reduction), Detection (multiple detectors), Post-processing (filtering, aggregation, validation)\n",
    "2. **Ensemble Methods**: Voting (majority), Weighted (custom weights), Stacking (meta-learner)\n",
    "3. **Validation**: Cross-Validation (K-fold), Hold-out (train/test split), Time Series (temporal), Spatial (spatial CV)\n",
    "4. **Reporting**: Automated report generation with summary statistics, key findings, and visualizations\n",
    "5. **Workflow Management**: Save and reuse workflow configurations\n",
    "6. **Integration**: Seamless integration with quality assessment and other modules\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Proceed to:\n",
    "- **15_3D_Visualization.ipynb** - 3D visualization of voxel data\n",
    "- **16_Advanced_Visualization.ipynb** - Advanced visualization techniques\n",
    "\n",
    "### Related Resources\n",
    "\n",
    "- Anomaly Detection Documentation: `../docs/AM_QADF/05-modules/anomaly-detection.md`\n",
    "- API Reference: `../docs/AM_QADF/06-api-reference/anomaly-detection-api.md`\n",
    "- Examples: `../examples/`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
